{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import dataframe_image as dfi # NOTE: YOU MUST HAVE GOOGLE CHROME INSTALLED FOR THIS TO WORK CORRECTLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Classifier Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name = 'XGBoost'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Rating Models and Most Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['rating_model_1', 'rating_model_2', 'rating_model_3']\n",
    "clean_model_names = [\"Altman's Z\", 'Financial Variables and Sector', 'Financial Variables, Sector, and NLP Features']\n",
    "# set most_complex_model \n",
    "most_complex_model = 'rating_model_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>Clean Column Name</th>\n",
       "      <th>Variable Type</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Ratio?</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Rating Model 1</th>\n",
       "      <th>Rating Model 2</th>\n",
       "      <th>Rating Model 3</th>\n",
       "      <th>Change Model 1</th>\n",
       "      <th>Change Model 2</th>\n",
       "      <th>Change Model 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Altman_Z</td>\n",
       "      <td>Altman's Z Score</td>\n",
       "      <td>Altman's Z Score</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBIT</td>\n",
       "      <td>EBIT</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_plus_preferred_stock</td>\n",
       "      <td>Common Plus Preferred Stock</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>workingCapital</td>\n",
       "      <td>Working Capital</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ratio_A</td>\n",
       "      <td>Ratio A</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>operatingCashFlowPerShare_diff</td>\n",
       "      <td>Difference in Operating Cash Flow Per Share fr...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>freeCashFlowPerShare_diff</td>\n",
       "      <td>Difference in Free Cash Flow Per Share from pr...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>cashPerShare_diff</td>\n",
       "      <td>Difference in Cash Per Share from prior fixed ...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>operatingCashFlowToSales_diff</td>\n",
       "      <td>Difference in Operating Cash Flow to Sales fro...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>freeCashFlowToOperatingCashFlow_diff</td>\n",
       "      <td>Difference in Free Cash Flow to Operating Cash...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              column_name  \\\n",
       "0                                Altman_Z   \n",
       "1                                    EBIT   \n",
       "2             common_plus_preferred_stock   \n",
       "3                          workingCapital   \n",
       "4                                 Ratio_A   \n",
       "..                                    ...   \n",
       "200        operatingCashFlowPerShare_diff   \n",
       "201             freeCashFlowPerShare_diff   \n",
       "202                     cashPerShare_diff   \n",
       "203         operatingCashFlowToSales_diff   \n",
       "204  freeCashFlowToOperatingCashFlow_diff   \n",
       "\n",
       "                                     Clean Column Name  \\\n",
       "0                                     Altman's Z Score   \n",
       "1                                                 EBIT   \n",
       "2                          Common Plus Preferred Stock   \n",
       "3                                      Working Capital   \n",
       "4                                              Ratio A   \n",
       "..                                                 ...   \n",
       "200  Difference in Operating Cash Flow Per Share fr...   \n",
       "201  Difference in Free Cash Flow Per Share from pr...   \n",
       "202  Difference in Cash Per Share from prior fixed ...   \n",
       "203  Difference in Operating Cash Flow to Sales fro...   \n",
       "204  Difference in Free Cash Flow to Operating Cash...   \n",
       "\n",
       "                  Variable Type Data Type Ratio?  \\\n",
       "0              Altman's Z Score   Numeric      Y   \n",
       "1    Constructed for Altman's Z   Numeric    NaN   \n",
       "2    Constructed for Altman's Z   Numeric    NaN   \n",
       "3    Constructed for Altman's Z   Numeric    NaN   \n",
       "4    Constructed for Altman's Z   Numeric      Y   \n",
       "..                          ...       ...    ...   \n",
       "200    Additional Change Ratios   Numeric    NaN   \n",
       "201    Additional Change Ratios   Numeric    NaN   \n",
       "202    Additional Change Ratios   Numeric    NaN   \n",
       "203    Additional Change Ratios   Numeric    NaN   \n",
       "204    Additional Change Ratios   Numeric    NaN   \n",
       "\n",
       "                                                 Notes Rating Model 1  \\\n",
       "0                                                  NaN              X   \n",
       "1                                                  NaN            NaN   \n",
       "2                                                  NaN            NaN   \n",
       "3                                                  NaN            NaN   \n",
       "4                                                  NaN            NaN   \n",
       "..                                                 ...            ...   \n",
       "200  Primarily for changes models, but can be used ...            NaN   \n",
       "201  Primarily for changes models, but can be used ...            NaN   \n",
       "202  Primarily for changes models, but can be used ...            NaN   \n",
       "203  Primarily for changes models, but can be used ...            NaN   \n",
       "204  Primarily for changes models, but can be used ...            NaN   \n",
       "\n",
       "    Rating Model 2 Rating Model 3 Change Model 1 Change Model 2 Change Model 3  \n",
       "0              NaN            NaN              X            NaN            NaN  \n",
       "1                X              X            NaN              X              X  \n",
       "2                X              X            NaN              X              X  \n",
       "3                X              X            NaN              X              X  \n",
       "4                X              X            NaN              X              X  \n",
       "..             ...            ...            ...            ...            ...  \n",
       "200            NaN            NaN            NaN              X              X  \n",
       "201            NaN            NaN            NaN              X              X  \n",
       "202            NaN            NaN            NaN              X              X  \n",
       "203            NaN            NaN            NaN              X              X  \n",
       "204            NaN            NaN            NaN              X              X  \n",
       "\n",
       "[205 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load variable index\n",
    "variable_index = pd.read_excel('../../../../Variable Index.xlsx')\n",
    "variable_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_comparison_row(model_name, clean_model_name):\n",
    "    '''\n",
    "    Given the model name and clean model name, this function returns the model comparison row.\n",
    "    '''\n",
    "\n",
    "    # Load close_exact_dict\n",
    "    close_exact_dict = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_close_exact_dict.pkl')\n",
    "    # Version with each item rounded to 4 decimal places\n",
    "    close_exact_dict_rounded = {k: round(v, 4) for k, v in close_exact_dict.items()}\n",
    "    # Unpack\n",
    "    exact_predictions_share = close_exact_dict_rounded['exact_predictions_share']\n",
    "    close_predictions_share = close_exact_dict_rounded['close_predictions_share']\n",
    "\n",
    "    # Load acc_f1_majority\n",
    "    acc_f1_majority = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_acc_f1_majority.pkl')\n",
    "    # Version with each item rounded to 2 decimal places\n",
    "    acc_f1_majority_rounded = {k: round(v, 4) for k, v in acc_f1_majority.items()}\n",
    "    # Unpack\n",
    "    accuracy = acc_f1_majority_rounded['accuracy']\n",
    "    f1 = acc_f1_majority_rounded['f1_score']\n",
    "    majority_baseline = acc_f1_majority_rounded['majority_baseline']\n",
    "\n",
    "    # Check exact_predictions_share == accuracy\n",
    "    print('exact predictions share == accuracy:', exact_predictions_share == accuracy)\n",
    "\n",
    "    # Get weighted average precision and recall from classification report\n",
    "    classification_report = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_classification_report.pkl')\n",
    "    # Convert classification report string to dataframe\n",
    "    classification_report_lines = classification_report.split('\\n')\n",
    "    # split on spaces within and drop blanks\n",
    "    classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "    # drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "    classification_report_data = [line for line in classification_report_data if line[0] in ['weighted']]\n",
    "    # Unpack\n",
    "    weighted_avg_precision = classification_report_data[0][2]\n",
    "    weighted_avg_recall = classification_report_data[0][3]\n",
    "\n",
    "    # Create dataframe row\n",
    "    model_comparison_row = pd.DataFrame({\n",
    "        'Model/Baseline': [clean_model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Weighted Average Precision': [weighted_avg_precision],\n",
    "        'Weighted Average Recall': [weighted_avg_recall],\n",
    "        'F1 Score': [f1],\n",
    "        'Share 1 Rating Or Less From Actual': [close_predictions_share]\n",
    "    })\n",
    "\n",
    "    # Return row\n",
    "    return model_comparison_row, majority_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Table - Include and Exclude Previous Rating Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.3855   \n",
      "0                 Financial Variables and Sector   0.7630   \n",
      "0  Financial Variables, Sector, and NLP Features   0.9034   \n",
      "0                     Most Common Class Baseline   0.3247   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
      "0                     0.3468                  0.3855   0.3408   \n",
      "0                     0.7679                  0.7630   0.7575   \n",
      "0                     0.9040                  0.9034   0.9017   \n",
      "0                                                               \n",
      "\n",
      "  Share $\\le$ 1 Rating From Actual  \n",
      "0                           0.7657  \n",
      "0                           0.9597  \n",
      "0                           0.9857  \n",
      "0                                   \n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.9517   \n",
      "0                 Financial Variables and Sector   0.9535   \n",
      "0  Financial Variables, Sector, and NLP Features   0.9535   \n",
      "0                     Most Common Class Baseline   0.3247   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
      "0                     0.9504                  0.9517   0.9509   \n",
      "0                     0.9539                  0.9535   0.9536   \n",
      "0                     0.9539                  0.9535   0.9536   \n",
      "0                                                               \n",
      "\n",
      "  Share $\\le$ 1 Rating From Actual  \n",
      "0                           0.9946  \n",
      "0                           0.9964  \n",
      "0                           0.9964  \n",
      "0                                   \n",
      "     ticker fixed_quarter_date Change Direction Since Last Fixed Quarter Date  \\\n",
      "0      AAPL         2016-07-01                Same As Last Fixed Quarter Date   \n",
      "1      ABBV         2015-04-01                Same As Last Fixed Quarter Date   \n",
      "2      ABBV         2016-04-01                Same As Last Fixed Quarter Date   \n",
      "3       ABC         2012-04-01                Same As Last Fixed Quarter Date   \n",
      "4       ABC         2013-01-01                Same As Last Fixed Quarter Date   \n",
      "...     ...                ...                                            ...   \n",
      "1113    XOM         2016-01-01                Same As Last Fixed Quarter Date   \n",
      "1114    YUM         2015-04-01                Same As Last Fixed Quarter Date   \n",
      "1115   ZBRA         2016-10-01                Same As Last Fixed Quarter Date   \n",
      "1116    ZTS         2013-10-01                Same As Last Fixed Quarter Date   \n",
      "1117    ZTS         2014-04-01                Same As Last Fixed Quarter Date   \n",
      "\n",
      "     rating_change_model_1_predictions  \n",
      "0      Same As Last Fixed Quarter Date  \n",
      "1      Same As Last Fixed Quarter Date  \n",
      "2      Same As Last Fixed Quarter Date  \n",
      "3      Same As Last Fixed Quarter Date  \n",
      "4      Same As Last Fixed Quarter Date  \n",
      "...                                ...  \n",
      "1113   Same As Last Fixed Quarter Date  \n",
      "1114   Same As Last Fixed Quarter Date  \n",
      "1115   Same As Last Fixed Quarter Date  \n",
      "1116   Same As Last Fixed Quarter Date  \n",
      "1117   Same As Last Fixed Quarter Date  \n",
      "\n",
      "[1118 rows x 4 columns]\n",
      "same share\n",
      "0.9535\n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Create list of df rows\n",
    "    model_comparison_rows = []\n",
    "    majority_baselines = []\n",
    "    for model_name, clean_model_name in zip(model_names, clean_model_names):\n",
    "        model_comparison_row, majority_baseline = get_model_comparison_row(include_exclude_previous + model_name, clean_model_name)\n",
    "        model_comparison_rows.append(model_comparison_row)\n",
    "        majority_baselines.append(majority_baseline)\n",
    "\n",
    "    # Concatenate rows\n",
    "    model_comparison_df = pd.concat(model_comparison_rows)\n",
    "\n",
    "    # Check majority baselines are the same\n",
    "    print('Majority baselines are the same:', all([majority_baseline == majority_baselines[0] for majority_baseline in majority_baselines]))\n",
    "    # Add row with Model/Baseline = 'Most Common Class Baseline' and Accuracy = majority_baseline[0]\n",
    "    model_comparison_df = pd.concat([model_comparison_df, pd.DataFrame({\n",
    "        'Model/Baseline': ['Most Common Class Baseline'],\n",
    "        'Accuracy': [majority_baselines[0]],\n",
    "        'Weighted Average Precision': [''],\n",
    "        'Weighted Average Recall': [''],\n",
    "        'F1 Score': [''],\n",
    "        'Share 1 Rating Or Less From Actual': ['']\n",
    "    })])\n",
    "\n",
    "    # if include set include_exclude_previous_model_comparison_df\n",
    "    if include_exclude_previous == 'include_previous_':\n",
    "        include_previous_model_comparison_df = model_comparison_df\n",
    "    else:\n",
    "        exclude_previous_model_comparison_df = model_comparison_df\n",
    "\n",
    "    # Export to Excel\n",
    "    model_comparison_df.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df.xlsx', index = False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in model_comparison_df.columns:\n",
    "        model_comparison_df[col] = model_comparison_df[col].apply(lambda x: f'{x:.4f}' if isinstance(x, float) else x)\n",
    "    # Rename 'Share 1 Rating Or Less From Actual' to 'Share $le$ Rating From Actual'\n",
    "    model_comparison_df.rename(columns={'Share 1 Rating Or Less From Actual': 'Share $\\\\le$ 1 Rating From Actual'}, inplace=True)\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df.to_latex(index=False, column_format='c' * len(model_comparison_df.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    # Middle version latex - keep only columns 'Model/Baseline', 'Accuracy', 'Share $\\\\le$ 1 Rating From Actual'\n",
    "    model_comparison_df_middle = model_comparison_df[['Model/Baseline', 'Accuracy', 'Share $\\\\le$ 1 Rating From Actual']]\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df_middle.to_latex(index=False, column_format='c' * len(model_comparison_df_middle.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df_middle.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    # Smaller version latex - keep only columns 'Model/Baseline', 'Accuracy'\n",
    "    model_comparison_df_smaller = model_comparison_df[['Model/Baseline', 'Accuracy']]\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df_smaller.to_latex(index=False, column_format='c' * len(model_comparison_df_smaller.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df_smaller.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(model_comparison_df)\n",
    "\n",
    "    # If include_previous, add a row that is the share of items with \"Same\" in test data\n",
    "    if include_exclude_previous == 'include_previous_':\n",
    "        test_data_example = pd.read_excel('../../../../Data/Predictions/Logistic Regression/rating_change_model_1/rating_change_model_1_predictions.xlsx')\n",
    "        print(test_data_example)\n",
    "        same_share = test_data_example[test_data_example['Change Direction Since Last Fixed Quarter Date'] == 'Same As Last Fixed Quarter Date'].shape[0] / test_data_example.shape[0]\n",
    "        # round to 4 decimal places\n",
    "        same_share = round(same_share, 4)\n",
    "        print('same share')\n",
    "        print(same_share)\n",
    "        # Create dataframe row\n",
    "        same_share_row = pd.DataFrame({\n",
    "            'Model/Baseline': ['Previous Rating'],\n",
    "            'Accuracy': [same_share],\n",
    "            'Weighted Average Precision': [''],\n",
    "            'Weighted Average Recall': [''],\n",
    "            'F1 Score': [''],\n",
    "        })\n",
    "        # Concatenate rows\n",
    "        model_comparison_df_ss = pd.concat([model_comparison_df, same_share_row])\n",
    "        # Export to Excel\n",
    "        model_comparison_df_ss.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df_ss.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "#print(exclude_previous_model_comparison_df)\n",
    "exclude_previous_model_comparison_sty = (exclude_previous_model_comparison_df.reset_index(drop=True)[['Model/Baseline', 'Accuracy']]\n",
    "                            .style\n",
    "                            .format(precision=2, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(exclude_previous_model_comparison_sty, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'exclude_previous_' + 'model_comparison_df.png')\n",
    "#exclude_previous_model_comparison_sty\n",
    "\n",
    "include_previous_model_comparison_sty = (include_previous_model_comparison_df.reset_index(drop=True)[['Model/Baseline', 'Accuracy']]\n",
    "                            .style\n",
    "                            .format(precision=2, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(include_previous_model_comparison_sty, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'include_previous_' + 'model_comparison_df.png')\n",
    "#include_previous_model_comparison_sty\n",
    "\n",
    "model_comparison_df_ss = (model_comparison_df_ss.reset_index(drop=True)[['Model/Baseline', 'Accuracy']]\n",
    "                            .style\n",
    "                            .format(precision=4, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(model_comparison_df_ss, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'include_previous_' + 'model_comparison_df_ss.png')\n",
    "#model_comparison_df_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Classification Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.8447    0.8894    0.8665       208\n",
      "          AA     0.8824    0.5769    0.6977        52\n",
      "         AAA     0.9048    0.7917    0.8444        24\n",
      "           B     0.9272    0.9091    0.9180       154\n",
      "          BB     0.9357    0.9225    0.9291       284\n",
      "         BBB     0.9129    0.9532    0.9326       363\n",
      "           C     1.0000    1.0000    1.0000         4\n",
      "          CC     1.0000    0.5000    0.6667         2\n",
      "         CCC     0.7857    0.8462    0.8148        26\n",
      "           D     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9034      1118\n",
      "   macro avg     0.9193    0.8389    0.8670      1118\n",
      "weighted avg     0.9040    0.9034    0.9017      1118\n",
      "\n",
      "  Rating Precision  Recall F1-Score Support\n",
      "2    AAA    0.9048  0.7917   0.8444      24\n",
      "1     AA    0.8824  0.5769   0.6977      52\n",
      "0      A    0.8447  0.8894   0.8665     208\n",
      "5    BBB    0.9129  0.9532   0.9326     363\n",
      "4     BB    0.9357  0.9225   0.9291     284\n",
      "3      B    0.9272  0.9091   0.9180     154\n",
      "8    CCC    0.7857  0.8462   0.8148      26\n",
      "7     CC    1.0000  0.5000   0.6667       2\n",
      "6      C    1.0000  1.0000   1.0000       4\n",
      "9      D    1.0000  1.0000   1.0000       1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.9604    0.9327    0.9463       208\n",
      "          AA     0.9423    0.9423    0.9423        52\n",
      "         AAA     0.8846    0.9583    0.9200        24\n",
      "           B     0.9359    0.9481    0.9419       154\n",
      "          BB     0.9576    0.9542    0.9559       284\n",
      "         BBB     0.9669    0.9669    0.9669       363\n",
      "           C     1.0000    1.0000    1.0000         4\n",
      "          CC     1.0000    1.0000    1.0000         2\n",
      "         CCC     0.8621    0.9615    0.9091        26\n",
      "           D     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9535      1118\n",
      "   macro avg     0.9510    0.9664    0.9583      1118\n",
      "weighted avg     0.9539    0.9535    0.9536      1118\n",
      "\n",
      "  Rating Precision  Recall F1-Score Support\n",
      "2    AAA    0.8846  0.9583   0.9200      24\n",
      "1     AA    0.9423  0.9423   0.9423      52\n",
      "0      A    0.9604  0.9327   0.9463     208\n",
      "5    BBB    0.9669  0.9669   0.9669     363\n",
      "4     BB    0.9576  0.9542   0.9559     284\n",
      "3      B    0.9359  0.9481   0.9419     154\n",
      "8    CCC    0.8621  0.9615   0.9091      26\n",
      "7     CC    1.0000  1.0000   1.0000       2\n",
      "6      C    1.0000  1.0000   1.0000       4\n",
      "9      D    1.0000  1.0000   1.0000       1\n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load classificiation report from pickle\n",
    "    classification_report = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_classification_report.pkl')\n",
    "    print(classification_report)\n",
    "\n",
    "    # Convert classification report string to dataframe\n",
    "    classification_report_lines = classification_report.split('\\n')\n",
    "    # split on spaces within and drop blanks\n",
    "    classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "    # drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "    classification_report_data = [line for line in classification_report_data if line[0] not in ['precision', 'accuracy', 'macro', 'weighted']]\n",
    "    # Stack list of rows into dataframe\n",
    "    classification_report_data = pd.DataFrame(classification_report_data)\n",
    "    # Set columns to \"Rating\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"\n",
    "    classification_report_data.columns = ['Rating', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "    # Sort by Rating in correct order: AAA, AA, A, BBB, BB, B, CCC, CC, C, D\n",
    "    rating_map = {'AAA': 0, 'AA': 1, 'A': 2, 'BBB': 3, 'BB': 4, 'B': 5, 'CCC': 6, 'CC': 7, 'C': 8, 'D': 9}\n",
    "    classification_report_data['Rating Num'] = classification_report_data['Rating'].map(rating_map)\n",
    "    classification_report_data = classification_report_data.sort_values(by='Rating Num').drop(columns='Rating Num')\n",
    "    print(classification_report_data)\n",
    "\n",
    "    # Export to Excel\n",
    "    classification_report_data.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Classification_Report.xlsx', index=False)\n",
    "\n",
    "    # Export to Latex\n",
    "    #classification_report_data.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Classification_Report.tex', index=False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in classification_report_data.columns:\n",
    "        classification_report_data[col] = classification_report_data[col].apply(lambda x: f'{x:.2f}' if isinstance(x, float) else x)\n",
    "    # Center all columns\n",
    "    lt_string = classification_report_data.to_latex(index=False, column_format='c' * 5, escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Classification_Report.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'gbtree', 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 20, 'min_child_weight': 5, 'n_estimators': 1000, 'objective': 'multi:softprob'}\n",
      "XGBoost\n",
      "   Previous Ratings booster  gamma  learning_rate  max_depth  \\\n",
      "0  Exclude Previous  gbtree    0.1            0.1         20   \n",
      "\n",
      "   min_child_weight  n_estimators       objective  \n",
      "0                 5          1000  multi:softprob  \n",
      "Index(['Previous Ratings', 'booster', 'gamma', 'learning_rate', 'max_depth',\n",
      "       'min_child_weight', 'n_estimators', 'objective'],\n",
      "      dtype='object')\n",
      "Index(['Gamma', 'Learning Rate', 'Max Depth', 'Min Child Weight',\n",
      "       'Number of Estimators'],\n",
      "      dtype='object')\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
      "XGBoost\n",
      "   Previous Ratings booster  learning_rate  max_depth  min_child_weight  \\\n",
      "0  Include Previous  gbtree           0.01          3                 3   \n",
      "\n",
      "   n_estimators       objective  \n",
      "0           100  multi:softprob  \n",
      "Index(['Previous Ratings', 'booster', 'learning_rate', 'max_depth',\n",
      "       'min_child_weight', 'n_estimators', 'objective'],\n",
      "      dtype='object')\n",
      "Index(['Learning Rate', 'Max Depth', 'Min Child Weight',\n",
      "       'Number of Estimators'],\n",
      "      dtype='object')\n",
      "   Previous Ratings Booster  Gamma  Learning Rate  Max Depth  \\\n",
      "0  Exclude Previous  gbtree    0.1           0.10         20   \n",
      "0  Include Previous  gbtree    NaN           0.01          3   \n",
      "\n",
      "   Min Child Weight  Number of Estimators       Objective  \n",
      "0                 5                  1000  multi:softprob  \n",
      "0                 3                   100  multi:softprob  \n"
     ]
    }
   ],
   "source": [
    "# List to store best parameters dfs\n",
    "best_params_dfs = []\n",
    "\n",
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load pickle\n",
    "    best_params = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_best_params.pkl')\n",
    "    print(best_params)\n",
    "\n",
    "    # Convert to dataframe\n",
    "    best_params = pd.DataFrame(best_params, index=[0])\n",
    "\n",
    "    # Set columns\n",
    "    print(classifier_name)\n",
    "    if \"include_previous_\" in include_exclude_previous:\n",
    "        best_params.columns = ['booster', 'learning_rate', 'max_depth', 'min_child_weight', 'n_estimators', 'objective']\n",
    "    else:\n",
    "        best_params.columns = ['booster', 'gamma','learning_rate', 'max_depth', 'min_child_weight', 'n_estimators', 'objective']\n",
    "    # Replace 'Multi-Class Strategy' values\n",
    "    #best_params['Multi-Class Strategy'] = best_params['Multi-Class Strategy'].replace({'ovr': 'One vs Rest', 'multinomial': 'Multinomial'})\n",
    "    # Replace 'Penalty' values\n",
    "    #best_params['Penalty'] = best_params['Penalty'].replace({'l1': 'L1', 'l2': 'L2', 'elasticnet': 'Elastic Net', 'none': 'None'})\n",
    "    # Replace 'Solver' values\n",
    "   # best_params['Solver'] = best_params['Solver'].replace({'newton-cg': 'Newton Conjugate Gradient', 'lbfgs': 'Limited Memory Broyden–Fletcher–Goldfarb–Shanno', 'liblinear': 'Library for Large Linear Classification', 'sag': 'Stochastic Average Gradient', 'saga': 'SAGA'})\n",
    "    # Replace Class Weighting Strategy values\n",
    "    #best_params['Class Weighting Strategy'] = best_params['Class Weighting Strategy'].replace({'balanced': 'Balanced', None: 'None'})\n",
    "    \n",
    "    # Column at the front for whether previous ratings are included or excluded\n",
    "    best_params.insert(0, 'Previous Ratings', include_exclude_previous[:-1].replace('_', ' ').title())\n",
    "\n",
    "    print(best_params)\n",
    "\n",
    "    #best_params = best_params.reset_index(drop=True)\n",
    "\n",
    "    # Rename booster to Booster, gamma to Gamma, learning_rate to Learning Rate, max_depth to Max Depth, min_child_weight to Min Child Weight, n_estimators to Number of Estimators, objective to Objective\n",
    "    print(best_params.columns)\n",
    "    best_params.rename(columns={'booster': 'Booster', 'gamma': 'Gamma', 'learning_rate': 'Learning Rate', 'max_depth': 'Max Depth', 'min_child_weight': 'Min Child Weight', 'n_estimators': 'Number of Estimators', 'objective': 'Objective'}, inplace=True)\n",
    "\n",
    "    # Export smaller version to Excel\n",
    "    # drop first col, Booster, Objective\n",
    "    bp_small = best_params.drop(columns=['Booster', 'Objective', 'Previous Ratings'])\n",
    "    bp_small.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Best_Params.xlsx', index=False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    print(bp_small.columns)\n",
    "    for col in ['Learning Rate']:\n",
    "        bp_small[col] = bp_small[col].apply(lambda x: '{:,.2f}'.format(x))\n",
    "    if 'Gamma' in bp_small.columns:\n",
    "        bp_small['Gamma'] = bp_small['Gamma'].apply(lambda x: '{:,.2f}'.format(x))\n",
    "    for col in ['Max Depth', 'Min Child Weight', 'Number of Estimators']:\n",
    "        bp_small[col] = bp_small[col].apply(lambda x: '{:,.0f}'.format(x))\n",
    "    # Center all columns\n",
    "    lt_string = bp_small.to_latex(index=False, column_format='c' * len(bp_small.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Models_Best_Params.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size) \n",
    "\n",
    "    # Append to best_params_dfs\n",
    "    best_params_dfs.append(best_params)\n",
    "\n",
    "# Concatenate best_params_dfs\n",
    "best_params = pd.concat(best_params_dfs)\n",
    "print(best_params)\n",
    "\n",
    "# Export to Excel\n",
    "best_params.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/Most_Complex_Models_Best_Params.xlsx', index=False)\n",
    "\n",
    "# Export to Latex\n",
    "#best_params.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Best_Params.tex', index=False)\n",
    "\n",
    "# Export to LaTeX\n",
    "for col in ['Gamma', 'Learning Rate']:\n",
    "    best_params[col] = best_params[col].apply(lambda x: '{:,.2f}'.format(x))\n",
    "for col in ['Max Depth', 'Min Child Weight', 'Number of Estimators']:\n",
    "    best_params[col] = best_params[col].apply(lambda x: '{:,.0f}'.format(x))\n",
    "# Center all columns\n",
    "lt_string = best_params.to_latex(index=False, column_format='c' * len(best_params.columns), escape=False)\n",
    "latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "with open('../../../../Output/Modelling/' + classifier_name + '/Tables/Most_Complex_Models_Best_Params.tex', 'w') as f:\n",
    "    f.write(latex_with_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Permuted Feature  Mean Accuracy Drop  \\\n",
      "0                             Retained Earnings            0.043819   \n",
      "1                         Market Capitalization            0.035169   \n",
      "2                                Dividends Paid            0.021455   \n",
      "3                                    Debt Ratio            0.009987   \n",
      "4                                  Common Stock            0.009693   \n",
      "5                                       Ratio E            0.009535   \n",
      "6              Other Total Stockholders' Equity            0.009288   \n",
      "7                     Total Current Liabilities            0.006888   \n",
      "8                     Inventory (Balance Sheet)            0.006802   \n",
      "9                          Total Current Assets            0.006684   \n",
      "10  Selling General and Administrative Expenses            0.006031   \n",
      "11                             Interest Expense            0.005973   \n",
      "12                 Net Property Plant Equipment            0.005729   \n",
      "13                                      Ratio C            0.005677   \n",
      "14                     Total Non-Current Assets            0.005589   \n",
      "\n",
      "    Standard Deviation  \n",
      "0             0.005761  \n",
      "1             0.005735  \n",
      "2             0.004481  \n",
      "3             0.003413  \n",
      "4             0.002248  \n",
      "5             0.003463  \n",
      "6             0.003028  \n",
      "7             0.002785  \n",
      "8             0.002994  \n",
      "9             0.003243  \n",
      "10            0.002395  \n",
      "11            0.002740  \n",
      "12            0.001915  \n",
      "13            0.002476  \n",
      "14            0.003420  \n",
      "                             Permuted Feature  Mean Accuracy Drop  \\\n",
      "0    Rating on Previous Fixed Quarter Date BB            0.276554   \n",
      "1   Rating on Previous Fixed Quarter Date BBB            0.257352   \n",
      "2     Rating on Previous Fixed Quarter Date B            0.080826   \n",
      "3     Rating on Previous Fixed Quarter Date A            0.047979   \n",
      "4    Rating on Previous Fixed Quarter Date AA            0.036817   \n",
      "5   Rating on Previous Fixed Quarter Date CCC            0.025477   \n",
      "6   Rating on Previous Fixed Quarter Date AAA            0.021269   \n",
      "7                Net Property Plant Equipment            0.001779   \n",
      "8     Rating on Previous Fixed Quarter Date C            0.000900   \n",
      "9                              Cash Per Share            0.000834   \n",
      "10                 Return on Capital Employed            0.000024   \n",
      "11                      Market Capitalization            0.000022   \n",
      "12               Operating Cash Flow to Sales            0.000020   \n",
      "13                Cash at Beginning of Period            0.000000   \n",
      "14                            Interest Income            0.000000   \n",
      "\n",
      "    Standard Deviation  \n",
      "0             0.010192  \n",
      "1             0.010267  \n",
      "2             0.004940  \n",
      "3             0.004233  \n",
      "4             0.001890  \n",
      "5             0.002348  \n",
      "6             0.002349  \n",
      "7             0.000093  \n",
      "8             0.000098  \n",
      "9             0.000225  \n",
      "10            0.000150  \n",
      "11            0.000140  \n",
      "12            0.000131  \n",
      "13            0.000000  \n",
      "14            0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load data\n",
    "    permutation_importance = pd.read_parquet('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_permutation_importance.parquet')\n",
    "    permutation_importance = permutation_importance.sort_values('mean',ascending=False)\n",
    "    # Set columns to \"Feature\", \"Mean\", \"Standard Deviation\"\n",
    "    permutation_importance.columns = ['Feature', 'Mean', 'Standard Deviation']\n",
    "     # Strip 'cat__' and 'num__' from Feature\n",
    "    permutation_importance['Feature'] = permutation_importance['Feature'].str.replace('cat__', '').str.replace('num__', '')\n",
    "    # Use variable_index to get feature names\n",
    "    permutation_importance = permutation_importance.merge(variable_index[['column_name', 'Clean Column Name']], left_on='Feature', right_on='column_name', how='left')\n",
    "    # Set Clean_Column_Name to Feature if no match\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].fillna(permutation_importance['Feature'])\n",
    "    # Drop Feature and column_name\n",
    "    permutation_importance = permutation_importance.drop(columns=['Feature', 'column_name'])\n",
    "    # Clean up names for categorical columns\n",
    "    previous_rating_mapping = {'rating_on_previous_fixed_quarter_date_AAA': 'Rating on Previous Fixed Quarter Date AAA',\n",
    "                                'rating_on_previous_fixed_quarter_date_AA': 'Rating on Previous Fixed Quarter Date AA',\n",
    "                                'rating_on_previous_fixed_quarter_date_A': 'Rating on Previous Fixed Quarter Date A',\n",
    "                                'rating_on_previous_fixed_quarter_date_BBB': 'Rating on Previous Fixed Quarter Date BBB',\n",
    "                                'rating_on_previous_fixed_quarter_date_BB': 'Rating on Previous Fixed Quarter Date BB',\n",
    "                                'rating_on_previous_fixed_quarter_date_B': 'Rating on Previous Fixed Quarter Date B',\n",
    "                                'rating_on_previous_fixed_quarter_date_CCC': 'Rating on Previous Fixed Quarter Date CCC',\n",
    "                                'rating_on_previous_fixed_quarter_date_CC': 'Rating on Previous Fixed Quarter Date CC',\n",
    "                                'rating_on_previous_fixed_quarter_date_C': 'Rating on Previous Fixed Quarter Date C',\n",
    "                                'rating_on_previous_fixed_quarter_date_D': 'Rating on Previous Fixed Quarter Date D'}\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].replace(previous_rating_mapping)\n",
    "    # Replace 'Sector_' with 'Sector: '\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].str.replace('Sector_', 'Sector: ')\n",
    "    # Rename Clean Column Name to Feature\n",
    "    permutation_importance = permutation_importance.rename(columns={'Clean Column Name': 'Feature'})\n",
    "    # Reorder columns to put Feature first\n",
    "    permutation_importance = permutation_importance[['Feature', 'Mean', 'Standard Deviation']]\n",
    "    # Rename Mean to 'Mean Accuracy Drop'\n",
    "    permutation_importance = permutation_importance.rename(columns={'Mean': 'Mean Accuracy Drop'})\n",
    "    # Rename Feature to 'Permuted Feature'\n",
    "    permutation_importance = permutation_importance.rename(columns={'Feature': 'Permuted Feature'})\n",
    "    # Get top 15\n",
    "    pi_top_15 = permutation_importance.head(15)\n",
    "\n",
    "    # If includ_previous set to include_previous_pi_top_15\n",
    "    if include_exclude_previous == 'include_previous_':\n",
    "        include_previous_pi_top_15 = pi_top_15\n",
    "    else:\n",
    "        exclude_previous_pi_top_15 = pi_top_15\n",
    "\n",
    "    # Export to Excel\n",
    "    pi_top_15.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Permutation_Importance_Top_15.xlsx', index=False)\n",
    "\n",
    "    # Export to Latex\n",
    "    #pi_top_15.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Permutation_Importance_Top_15.tex', index=False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Center all columns\n",
    "    lt_string = pi_top_15.to_latex(index=False, column_format='c' * len(pi_top_15.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\tiny\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Permutation_Importance_Top_15.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(pi_top_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_previous_pi_top_15 = (include_previous_pi_top_15.reset_index(drop=True)\n",
    "                            .style\n",
    "                            .format(precision=6, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(include_previous_pi_top_15, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'include_previous_' + 'Most_Complex_Model_Permutation_Importance_Top_15.png')\n",
    "#include_previous_pi_top_15\n",
    "\n",
    "exclude_previous_pi_top_15 = (exclude_previous_pi_top_15.reset_index(drop=True)\n",
    "                            .style\n",
    "                            .format(precision=6, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(exclude_previous_pi_top_15, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'exclude_previous_' + 'Most_Complex_Model_Permutation_Importance_Top_15.png')\n",
    "#exclude_previous_pi_top_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Model Comparison Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.9186   \n",
      "0                 Financial Variables and Sector   0.9517   \n",
      "0  Financial Variables, Sector, and NLP Features   0.9535   \n",
      "0                     Most Common Class Baseline   0.9535   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \n",
      "0                     0.9111                  0.9186   0.9148  \n",
      "0                     0.9091                  0.9517   0.9299  \n",
      "0                     0.9091                  0.9535   0.9308  \n",
      "0                                                              \n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.7415   \n",
      "0                 Financial Variables and Sector   0.9436   \n",
      "0  Financial Variables, Sector, and NLP Features   0.9490   \n",
      "0                     Most Common Class Baseline   0.9535   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \n",
      "0                     0.9118                  0.7415   0.8150  \n",
      "0                     0.9120                  0.9436   0.9276  \n",
      "0                     0.9089                  0.9490   0.9285  \n",
      "0                                                              \n"
     ]
    }
   ],
   "source": [
    "# Iterate over just models '_' versus _smote_\n",
    "for spec in ['', 'smote_']:\n",
    "\n",
    "    # Create list of df rows\n",
    "    model_comparison_rows = []\n",
    "    majority_baselines = []\n",
    "    for mn, clean_model_name in zip(['rating_change_model_1', 'rating_change_model_2', 'rating_change_model_3'], [\"Altman's Z\", 'Financial Variables and Sector', 'Financial Variables, Sector, and NLP Features']):\n",
    "        model_comparison_row, majority_baseline = get_model_comparison_row(spec + mn, clean_model_name)\n",
    "        model_comparison_rows.append(model_comparison_row)\n",
    "        majority_baselines.append(majority_baseline)\n",
    "\n",
    "    # Concatenate rows\n",
    "    model_comparison_df = pd.concat(model_comparison_rows)\n",
    "\n",
    "    # Check majority baselines are the same\n",
    "    print('Majority baselines are the same:', all([majority_baseline == majority_baselines[0] for majority_baseline in majority_baselines]))\n",
    "    # Add row with Model/Baseline = 'Most Common Class Baseline' and Accuracy = majority_baseline[0]\n",
    "    model_comparison_df = pd.concat([model_comparison_df, pd.DataFrame({\n",
    "        'Model/Baseline': ['Most Common Class Baseline'],\n",
    "        'Accuracy': [majority_baselines[0]],\n",
    "        'Weighted Average Precision': [''],\n",
    "        'Weighted Average Recall': [''],\n",
    "        'F1 Score': [''],\n",
    "        'Share 1 Rating Or Less From Actual': ['']\n",
    "    })])\n",
    "    # Drop 'Share 1 Rating Or Less From Actual' column\n",
    "    model_comparison_df = model_comparison_df.drop(columns=['Share 1 Rating Or Less From Actual'])\n",
    "\n",
    "    # if smote set as change_smote_model_comparison_df\n",
    "    if spec == 'smote_':\n",
    "        change_smote_model_comparison_df = model_comparison_df\n",
    "    else:\n",
    "        change_model_comparison_df = model_comparison_df\n",
    "\n",
    "    # Export to Excel\n",
    "    model_comparison_df.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/change_' + spec + 'model_comparison_df.xlsx', index = False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in model_comparison_df.columns:\n",
    "        model_comparison_df[col] = model_comparison_df[col].apply(lambda x: f'{x:.4f}' if isinstance(x, float) else x)\n",
    "    # Rename 'Share 1 Rating Or Less From Actual' to 'Share $le$ Rating From Actual'\n",
    "    #model_comparison_df.rename(columns={'Share 1 Rating Or Less From Actual': 'Share $\\\\le$ 1 Rating From Actual'}, inplace=True)\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df.to_latex(index=False, column_format='c' * len(model_comparison_df.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/change_' + spec + 'model_comparison_df.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    # Smaller version latex - keep only columns 'Model/Baseline', 'Accuracy'\n",
    "    model_comparison_df_smaller = model_comparison_df[['Model/Baseline', 'Accuracy']]\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df_smaller.to_latex(index=False, column_format='c' * len(model_comparison_df_smaller.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/change_' + spec + 'model_comparison_df_smaller.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(model_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "#print(exclude_previous_model_comparison_df)\n",
    "change_model_comparison_df = (change_model_comparison_df.reset_index(drop=True)[['Model/Baseline', 'Accuracy']]\n",
    "                            .style\n",
    "                            .format(precision=2, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(change_model_comparison_df, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'change_model_comparison_df.png')\n",
    "#change_model_comparison_df\n",
    "\n",
    "change_smote_model_comparison_df = (change_smote_model_comparison_df.reset_index(drop=True)[['Model/Baseline', 'Accuracy']]\n",
    "                            .style\n",
    "                            .format(precision=2, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(change_smote_model_comparison_df, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'change_smote_model_comparison_df.png')\n",
    "#change_smote_model_comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Model Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "Downgrade Since Last Fixed Quarter Date     0.0000    0.0000    0.0000        20\n",
      "        Same As Last Fixed Quarter Date     0.9533    0.9953    0.9738      1066\n",
      "  Upgrade Since Last Fixed Quarter Date     0.0000    0.0000    0.0000        32\n",
      "\n",
      "                               accuracy                         0.9490      1118\n",
      "                              macro avg     0.3178    0.3318    0.3246      1118\n",
      "                           weighted avg     0.9089    0.9490    0.9285      1118\n",
      "\n",
      "                                         0       6       7       8     9\n",
      "0  Downgrade Since Last Fixed Quarter Date  0.0000  0.0000  0.0000    20\n",
      "1          Same As Last Fixed Quarter Date  0.9533  0.9953  0.9738  1066\n",
      "2    Upgrade Since Last Fixed Quarter Date  0.0000  0.0000  0.0000    32\n",
      "      Change Precision  Recall F1-Score Support\n",
      "0  Downgrade    0.0000  0.0000   0.0000      20\n",
      "1       Same    0.9533  0.9953   0.9738   1,066\n",
      "2    Upgrade    0.0000  0.0000   0.0000      32\n"
     ]
    }
   ],
   "source": [
    "# Load classificiation report from pickle\n",
    "classification_report = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/smote_rating_change_model_3/smote_rating_change_model_3_classification_report.pkl')\n",
    "print(classification_report)\n",
    "\n",
    "# Convert classification report string to dataframe\n",
    "classification_report_lines = classification_report.split('\\n')\n",
    "# split on spaces within and drop blanks\n",
    "classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "# drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "classification_report_data = [line for line in classification_report_data if line[0] not in ['precision', 'accuracy', 'macro', 'weighted']]\n",
    "# Stack list of rows into dataframe\n",
    "classification_report_data = pd.DataFrame(classification_report_data)\n",
    "# Merge columns 0 to 5 into one column on spaces\n",
    "classification_report_data[0] = classification_report_data[[0, 1, 2, 3, 4, 5]].apply(lambda x: ' '.join(x), axis=1)\n",
    "# Drop columns 1 to 4\n",
    "classification_report_data = classification_report_data.drop(columns=[1, 2, 3, 4, 5])\n",
    "print(classification_report_data)\n",
    "# Set columns to \"Change\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"\n",
    "classification_report_data.columns = ['Change', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "# Recode change: 'Downgrade Since Last Fixed Quarter Date' as 'Downgrade', 'Same As Last Fixed Quarter Date' as 'Same', 'Upgrade Since Last Fixed Quarter Date' as 'Upgrade'\n",
    "change_mapping = {'Downgrade Since Last Fixed Quarter Date': 'Downgrade', 'Same As Last Fixed Quarter Date': 'Same', 'Upgrade Since Last Fixed Quarter Date': 'Upgrade'}\n",
    "classification_report_data['Change'] = classification_report_data['Change'].map(change_mapping)\n",
    "# Sort by Change in correct order: Downgrade, Same, Upgrade\n",
    "rating_map = {'Downgrade': 0, 'Same': 1, 'Upgrade': 2}\n",
    "classification_report_data['Change Num'] = classification_report_data['Change'].map(rating_map)\n",
    "classification_report_data = classification_report_data.sort_values(by='Change Num').drop(columns='Change Num')\n",
    "# Add commas in Support\n",
    "classification_report_data['Support'] = classification_report_data['Support'].apply(lambda x: '{:,}'.format(int(x)))\n",
    "print(classification_report_data)\n",
    "\n",
    "# Export to Excel\n",
    "classification_report_data.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/SMOTE_Most_Complex_Model_Classification_Report.xlsx', index=False)\n",
    "\n",
    "# Export to LaTeX\n",
    "# Format columns\n",
    "for col in classification_report_data.columns:\n",
    "    classification_report_data[col] = classification_report_data[col].apply(lambda x: f'{x:.2f}' if isinstance(x, float) else x)\n",
    "# Center all columns\n",
    "lt_string = classification_report_data.to_latex(index=False, column_format='c' * 5, escape=False)\n",
    "latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "with open('../../../../Output/Modelling/' + classifier_name + '/Tables/SMOTE_Most_Complex_Model_Classification_Report.tex', 'w') as f:\n",
    "    f.write(latex_with_font_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
