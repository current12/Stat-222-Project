{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Classifier Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name = 'XGBoost'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Rating Models and Most Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['rating_model_1', 'rating_model_2', 'rating_model_3']\n",
    "clean_model_names = [\"Altman's Z\", 'Financial Variables and Sector', 'Financial Variables, Sector, and NLP Features']\n",
    "# set most_complex_model \n",
    "most_complex_model = 'rating_model_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>Clean Column Name</th>\n",
       "      <th>Variable Type</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Ratio?</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Rating Model 1</th>\n",
       "      <th>Rating Model 2</th>\n",
       "      <th>Rating Model 3</th>\n",
       "      <th>Change Model 1</th>\n",
       "      <th>Change Model 2</th>\n",
       "      <th>Change Model 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Altman_Z</td>\n",
       "      <td>Altman's Z Score</td>\n",
       "      <td>Altman's Z Score</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBIT</td>\n",
       "      <td>EBIT</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_plus_preferred_stock</td>\n",
       "      <td>Common Plus Preferred Stock</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>workingCapital</td>\n",
       "      <td>Working Capital</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ratio_A</td>\n",
       "      <td>Ratio A</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>operatingCashFlowPerShare_diff</td>\n",
       "      <td>Difference in Operating Cash Flow Per Share fr...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>freeCashFlowPerShare_diff</td>\n",
       "      <td>Difference in Free Cash Flow Per Share from pr...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>cashPerShare_diff</td>\n",
       "      <td>Difference in Cash Per Share from prior fixed ...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>operatingCashFlowToSales_diff</td>\n",
       "      <td>Difference in Operating Cash Flow to Sales fro...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>freeCashFlowToOperatingCashFlow_diff</td>\n",
       "      <td>Difference in Free Cash Flow to Operating Cash...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              column_name  \\\n",
       "0                                Altman_Z   \n",
       "1                                    EBIT   \n",
       "2             common_plus_preferred_stock   \n",
       "3                          workingCapital   \n",
       "4                                 Ratio_A   \n",
       "..                                    ...   \n",
       "200        operatingCashFlowPerShare_diff   \n",
       "201             freeCashFlowPerShare_diff   \n",
       "202                     cashPerShare_diff   \n",
       "203         operatingCashFlowToSales_diff   \n",
       "204  freeCashFlowToOperatingCashFlow_diff   \n",
       "\n",
       "                                     Clean Column Name  \\\n",
       "0                                     Altman's Z Score   \n",
       "1                                                 EBIT   \n",
       "2                          Common Plus Preferred Stock   \n",
       "3                                      Working Capital   \n",
       "4                                              Ratio A   \n",
       "..                                                 ...   \n",
       "200  Difference in Operating Cash Flow Per Share fr...   \n",
       "201  Difference in Free Cash Flow Per Share from pr...   \n",
       "202  Difference in Cash Per Share from prior fixed ...   \n",
       "203  Difference in Operating Cash Flow to Sales fro...   \n",
       "204  Difference in Free Cash Flow to Operating Cash...   \n",
       "\n",
       "                  Variable Type Data Type Ratio?  \\\n",
       "0              Altman's Z Score   Numeric      Y   \n",
       "1    Constructed for Altman's Z   Numeric    NaN   \n",
       "2    Constructed for Altman's Z   Numeric    NaN   \n",
       "3    Constructed for Altman's Z   Numeric    NaN   \n",
       "4    Constructed for Altman's Z   Numeric      Y   \n",
       "..                          ...       ...    ...   \n",
       "200    Additional Change Ratios   Numeric    NaN   \n",
       "201    Additional Change Ratios   Numeric    NaN   \n",
       "202    Additional Change Ratios   Numeric    NaN   \n",
       "203    Additional Change Ratios   Numeric    NaN   \n",
       "204    Additional Change Ratios   Numeric    NaN   \n",
       "\n",
       "                                                 Notes Rating Model 1  \\\n",
       "0                                                  NaN              X   \n",
       "1                                                  NaN            NaN   \n",
       "2                                                  NaN            NaN   \n",
       "3                                                  NaN            NaN   \n",
       "4                                                  NaN            NaN   \n",
       "..                                                 ...            ...   \n",
       "200  Primarily for changes models, but can be used ...            NaN   \n",
       "201  Primarily for changes models, but can be used ...            NaN   \n",
       "202  Primarily for changes models, but can be used ...            NaN   \n",
       "203  Primarily for changes models, but can be used ...            NaN   \n",
       "204  Primarily for changes models, but can be used ...            NaN   \n",
       "\n",
       "    Rating Model 2 Rating Model 3 Change Model 1 Change Model 2 Change Model 3  \n",
       "0              NaN            NaN              X            NaN            NaN  \n",
       "1                X              X            NaN              X              X  \n",
       "2                X              X            NaN              X              X  \n",
       "3                X              X            NaN              X              X  \n",
       "4                X              X            NaN              X              X  \n",
       "..             ...            ...            ...            ...            ...  \n",
       "200            NaN            NaN            NaN              X              X  \n",
       "201            NaN            NaN            NaN              X              X  \n",
       "202            NaN            NaN            NaN              X              X  \n",
       "203            NaN            NaN            NaN              X              X  \n",
       "204            NaN            NaN            NaN              X              X  \n",
       "\n",
       "[205 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load variable index\n",
    "variable_index = pd.read_excel('../../../../Variable Index.xlsx')\n",
    "variable_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_comparison_row(model_name, clean_model_name):\n",
    "    '''\n",
    "    Given the model name and clean model name, this function returns the model comparison row.\n",
    "    '''\n",
    "\n",
    "    # Load close_exact_dict\n",
    "    close_exact_dict = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_close_exact_dict.pkl')\n",
    "    # Version with each item rounded to 4 decimal places\n",
    "    close_exact_dict_rounded = {k: round(v, 4) for k, v in close_exact_dict.items()}\n",
    "    # Unpack\n",
    "    exact_predictions_share = close_exact_dict_rounded['exact_predictions_share']\n",
    "    close_predictions_share = close_exact_dict_rounded['close_predictions_share']\n",
    "\n",
    "    # Load acc_f1_majority\n",
    "    acc_f1_majority = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_acc_f1_majority.pkl')\n",
    "    # Version with each item rounded to 2 decimal places\n",
    "    acc_f1_majority_rounded = {k: round(v, 4) for k, v in acc_f1_majority.items()}\n",
    "    # Unpack\n",
    "    accuracy = acc_f1_majority_rounded['accuracy']\n",
    "    f1 = acc_f1_majority_rounded['f1_score']\n",
    "    majority_baseline = acc_f1_majority_rounded['majority_baseline']\n",
    "\n",
    "    # Check exact_predictions_share == accuracy\n",
    "    print('exact predictions share == accuracy:', exact_predictions_share == accuracy)\n",
    "\n",
    "    # Get weighted average precision and recall from classification report\n",
    "    classification_report = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_classification_report.pkl')\n",
    "    # Convert classification report string to dataframe\n",
    "    classification_report_lines = classification_report.split('\\n')\n",
    "    # split on spaces within and drop blanks\n",
    "    classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "    # drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "    classification_report_data = [line for line in classification_report_data if line[0] in ['weighted']]\n",
    "    # Unpack\n",
    "    weighted_avg_precision = classification_report_data[0][2]\n",
    "    weighted_avg_recall = classification_report_data[0][3]\n",
    "\n",
    "    # Create dataframe row\n",
    "    model_comparison_row = pd.DataFrame({\n",
    "        'Model/Baseline': [clean_model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Weighted Average Precision': [weighted_avg_precision],\n",
    "        'Weighted Average Recall': [weighted_avg_recall],\n",
    "        'F1 Score': [f1],\n",
    "        'Share 1 Rating Or Less From Actual': [close_predictions_share]\n",
    "    })\n",
    "\n",
    "    # Return row\n",
    "    return model_comparison_row, majority_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Table - Include and Exclude Previous Rating Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.3855   \n",
      "0                 Financial Variables and Sector   0.8980   \n",
      "0  Financial Variables, Sector, and NLP Features   0.8157   \n",
      "0                              Majority Baseline   0.3247   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
      "0                     0.3468                  0.3855   0.3408   \n",
      "0                     0.8975                  0.8980   0.8962   \n",
      "0                     0.8167                  0.8157   0.8131   \n",
      "0                                                               \n",
      "\n",
      "  Share $\\le$ 1 Rating From Actual  \n",
      "0                           0.7657  \n",
      "0                           0.9848  \n",
      "0                           0.9705  \n",
      "0                                   \n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.9517   \n",
      "0                 Financial Variables and Sector   0.9535   \n",
      "0  Financial Variables, Sector, and NLP Features   0.9535   \n",
      "0                              Majority Baseline   0.3247   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
      "0                     0.9504                  0.9517   0.9509   \n",
      "0                     0.9539                  0.9535   0.9536   \n",
      "0                     0.9539                  0.9535   0.9536   \n",
      "0                                                               \n",
      "\n",
      "  Share $\\le$ 1 Rating From Actual  \n",
      "0                           0.9946  \n",
      "0                           0.9964  \n",
      "0                           0.9964  \n",
      "0                                   \n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Create list of df rows\n",
    "    model_comparison_rows = []\n",
    "    majority_baselines = []\n",
    "    for model_name, clean_model_name in zip(model_names, clean_model_names):\n",
    "        model_comparison_row, majority_baseline = get_model_comparison_row(include_exclude_previous + model_name, clean_model_name)\n",
    "        model_comparison_rows.append(model_comparison_row)\n",
    "        majority_baselines.append(majority_baseline)\n",
    "\n",
    "    # Concatenate rows\n",
    "    model_comparison_df = pd.concat(model_comparison_rows)\n",
    "\n",
    "    # Check majority baselines are the same\n",
    "    print('Majority baselines are the same:', all([majority_baseline == majority_baselines[0] for majority_baseline in majority_baselines]))\n",
    "    # Add row with Model/Baseline = 'Majority Baseline' and Accuracy = majority_baseline[0]\n",
    "    model_comparison_df = pd.concat([model_comparison_df, pd.DataFrame({\n",
    "        'Model/Baseline': ['Majority Baseline'],\n",
    "        'Accuracy': [majority_baselines[0]],\n",
    "        'Weighted Average Precision': [''],\n",
    "        'Weighted Average Recall': [''],\n",
    "        'F1 Score': [''],\n",
    "        'Share 1 Rating Or Less From Actual': ['']\n",
    "    })])\n",
    "\n",
    "    # Export to Excel\n",
    "    model_comparison_df.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df.xlsx', index = False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in model_comparison_df.columns:\n",
    "        model_comparison_df[col] = model_comparison_df[col].apply(lambda x: f'{x:.4f}' if isinstance(x, float) else x)\n",
    "    # Rename 'Share 1 Rating Or Less From Actual' to 'Share $le$ Rating From Actual'\n",
    "    model_comparison_df.rename(columns={'Share 1 Rating Or Less From Actual': 'Share $\\\\le$ 1 Rating From Actual'}, inplace=True)\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df.to_latex(index=False, column_format='c' * len(model_comparison_df.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(model_comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Classification Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.7905    0.7981    0.7943       208\n",
      "          AA     0.8182    0.5192    0.6353        52\n",
      "         AAA     0.8571    0.7500    0.8000        24\n",
      "           B     0.8923    0.7532    0.8169       154\n",
      "          BB     0.8219    0.8451    0.8333       284\n",
      "         BBB     0.8000    0.8815    0.8388       363\n",
      "           C     1.0000    1.0000    1.0000         4\n",
      "          CC     0.0000    0.0000    0.0000         2\n",
      "         CCC     0.7407    0.7692    0.7547        26\n",
      "           D     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.8157      1118\n",
      "   macro avg     0.7721    0.7316    0.7473      1118\n",
      "weighted avg     0.8167    0.8157    0.8131      1118\n",
      "\n",
      "  Rating Precision  Recall F1-Score Support\n",
      "0      A    0.7905  0.7981   0.7943     208\n",
      "1     AA    0.8182  0.5192   0.6353      52\n",
      "2    AAA    0.8571  0.7500   0.8000      24\n",
      "3      B    0.8923  0.7532   0.8169     154\n",
      "4     BB    0.8219  0.8451   0.8333     284\n",
      "5    BBB    0.8000  0.8815   0.8388     363\n",
      "6      C    1.0000  1.0000   1.0000       4\n",
      "7     CC    0.0000  0.0000   0.0000       2\n",
      "8    CCC    0.7407  0.7692   0.7547      26\n",
      "9      D    1.0000  1.0000   1.0000       1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.9604    0.9327    0.9463       208\n",
      "          AA     0.9423    0.9423    0.9423        52\n",
      "         AAA     0.8846    0.9583    0.9200        24\n",
      "           B     0.9359    0.9481    0.9419       154\n",
      "          BB     0.9576    0.9542    0.9559       284\n",
      "         BBB     0.9669    0.9669    0.9669       363\n",
      "           C     1.0000    1.0000    1.0000         4\n",
      "          CC     1.0000    1.0000    1.0000         2\n",
      "         CCC     0.8621    0.9615    0.9091        26\n",
      "           D     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9535      1118\n",
      "   macro avg     0.9510    0.9664    0.9583      1118\n",
      "weighted avg     0.9539    0.9535    0.9536      1118\n",
      "\n",
      "  Rating Precision  Recall F1-Score Support\n",
      "0      A    0.9604  0.9327   0.9463     208\n",
      "1     AA    0.9423  0.9423   0.9423      52\n",
      "2    AAA    0.8846  0.9583   0.9200      24\n",
      "3      B    0.9359  0.9481   0.9419     154\n",
      "4     BB    0.9576  0.9542   0.9559     284\n",
      "5    BBB    0.9669  0.9669   0.9669     363\n",
      "6      C    1.0000  1.0000   1.0000       4\n",
      "7     CC    1.0000  1.0000   1.0000       2\n",
      "8    CCC    0.8621  0.9615   0.9091      26\n",
      "9      D    1.0000  1.0000   1.0000       1\n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load classificiation report from pickle\n",
    "    classification_report = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_classification_report.pkl')\n",
    "    print(classification_report)\n",
    "\n",
    "    # Convert classification report string to dataframe\n",
    "    classification_report_lines = classification_report.split('\\n')\n",
    "    # split on spaces within and drop blanks\n",
    "    classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "    # drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "    classification_report_data = [line for line in classification_report_data if line[0] not in ['precision', 'accuracy', 'macro', 'weighted']]\n",
    "    # Stack list of rows into dataframe\n",
    "    classification_report_data = pd.DataFrame(classification_report_data)\n",
    "    # Set columns to \"Rating\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"\n",
    "    classification_report_data.columns = ['Rating', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "    print(classification_report_data)\n",
    "\n",
    "    # Export to Excel\n",
    "    classification_report_data.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Classification_Report.xlsx', index=False)\n",
    "\n",
    "    # Export to Latex\n",
    "    #classification_report_data.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Classification_Report.tex', index=False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in classification_report_data.columns:\n",
    "        classification_report_data[col] = classification_report_data[col].apply(lambda x: f'{x:.2f}' if isinstance(x, float) else x)\n",
    "    # Center all columns\n",
    "    lt_string = classification_report_data.to_latex(index=False, column_format='c' * 5, escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Classification_Report.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'objective': 'multi:softprob'}\n",
      "   Previous Ratings booster  learning_rate  max_depth  min_child_weight  \\\n",
      "0  Exclude Previous  gbtree           0.10          3                 5   \n",
      "0  Include Previous  gbtree           0.01          3                 3   \n",
      "\n",
      "   n_estimators       objective  \n",
      "0           100  multi:softprob  \n",
      "0           100  multi:softprob  \n"
     ]
    }
   ],
   "source": [
    "# List to store best parameters dfs\n",
    "best_params_dfs = []\n",
    "\n",
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load pickle\n",
    "    best_params = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_best_params.pkl')\n",
    "    print(best_params)\n",
    "\n",
    "    # Convert to dataframe\n",
    "    best_params = pd.DataFrame(best_params, index=[0])\n",
    "\n",
    "    # Set columns\n",
    "    best_params.columns = ['booster', 'learning_rate', 'max_depth', 'min_child_weight', 'n_estimators', 'objective']\n",
    "    # Replace 'Multi-Class Strategy' values\n",
    "    #best_params['Multi-Class Strategy'] = best_params['Multi-Class Strategy'].replace({'ovr': 'One vs Rest', 'multinomial': 'Multinomial'})\n",
    "    # Replace 'Penalty' values\n",
    "    #best_params['Penalty'] = best_params['Penalty'].replace({'l1': 'L1', 'l2': 'L2', 'elasticnet': 'Elastic Net', 'none': 'None'})\n",
    "    # Replace 'Solver' values\n",
    "   # best_params['Solver'] = best_params['Solver'].replace({'newton-cg': 'Newton Conjugate Gradient', 'lbfgs': 'Limited Memory Broyden–Fletcher–Goldfarb–Shanno', 'liblinear': 'Library for Large Linear Classification', 'sag': 'Stochastic Average Gradient', 'saga': 'SAGA'})\n",
    "    # Replace Class Weighting Strategy values\n",
    "    #best_params['Class Weighting Strategy'] = best_params['Class Weighting Strategy'].replace({'balanced': 'Balanced', None: 'None'})\n",
    "    \n",
    "    # Column at the front for whether previous ratings are included or excluded\n",
    "    best_params.insert(0, 'Previous Ratings', include_exclude_previous[:-1].replace('_', ' ').title())\n",
    "\n",
    "    # Append to best_params_dfs\n",
    "    best_params_dfs.append(best_params)\n",
    "\n",
    "# Concatenate best_params_dfs\n",
    "best_params = pd.concat(best_params_dfs)\n",
    "print(best_params)\n",
    "\n",
    "# Export to Excel\n",
    "best_params.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/Most_Complex_Models_Best_Params.xlsx', index=False)\n",
    "\n",
    "# Export to Latex\n",
    "#best_params.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Best_Params.tex', index=False)\n",
    "\n",
    "# Export to LaTeX\n",
    "for col in ['learning_rate', 'max_depth', 'min_child_weight', 'n_estimators']:\n",
    "    best_params[col] = best_params[col].apply(lambda x: '{:,.2f}'.format(x))\n",
    "# Center all columns\n",
    "lt_string = best_params.to_latex(index=False, column_format='c' * len(best_params.columns), escape=False)\n",
    "latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "with open('../../../../Output/Modelling/' + classifier_name + '/Tables/Most_Complex_Models_Best_Params.tex', 'w') as f:\n",
    "    f.write(latex_with_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Permuted Feature  Mean Accuracy Drop  \\\n",
      "0                               Retained Earnings            0.035817   \n",
      "1                           Market Capitalization            0.030038   \n",
      "2                       Inventory (Balance Sheet)            0.027679   \n",
      "3                               Sector: Utilities            0.024965   \n",
      "4                                      Debt Ratio            0.024124   \n",
      "5                                  Dividends Paid            0.022094   \n",
      "6                Other Total Stockholders' Equity            0.018515   \n",
      "7                                    Common Stock            0.017421   \n",
      "8                        Total Non-Current Assets            0.014897   \n",
      "9               Research and Development Expenses            0.012906   \n",
      "10                                        Ratio E            0.012905   \n",
      "11                           Total Current Assets            0.011080   \n",
      "12                      Other Current Liabilities            0.010883   \n",
      "13            Debt Ratio (Alternative Definition)            0.009271   \n",
      "14  Weighted Average Shares Outstanding (Diluted)            0.008568   \n",
      "\n",
      "    Standard Deviation  \n",
      "0             0.007043  \n",
      "1             0.006781  \n",
      "2             0.004675  \n",
      "3             0.003304  \n",
      "4             0.004996  \n",
      "5             0.005007  \n",
      "6             0.004804  \n",
      "7             0.003463  \n",
      "8             0.003718  \n",
      "9             0.002746  \n",
      "10            0.003910  \n",
      "11            0.003805  \n",
      "12            0.003305  \n",
      "13            0.003599  \n",
      "14            0.003388  \n",
      "                             Permuted Feature  Mean Accuracy Drop  \\\n",
      "0    Rating on Previous Fixed Quarter Date BB            0.276554   \n",
      "1   Rating on Previous Fixed Quarter Date BBB            0.257352   \n",
      "2     Rating on Previous Fixed Quarter Date B            0.080826   \n",
      "3     Rating on Previous Fixed Quarter Date A            0.047979   \n",
      "4    Rating on Previous Fixed Quarter Date AA            0.036817   \n",
      "5   Rating on Previous Fixed Quarter Date CCC            0.025477   \n",
      "6   Rating on Previous Fixed Quarter Date AAA            0.021269   \n",
      "7                Net Property Plant Equipment            0.001779   \n",
      "8     Rating on Previous Fixed Quarter Date C            0.000900   \n",
      "9                              Cash Per Share            0.000834   \n",
      "10                 Return on Capital Employed            0.000024   \n",
      "11                      Market Capitalization            0.000022   \n",
      "12               Operating Cash Flow to Sales            0.000020   \n",
      "13                Cash at Beginning of Period            0.000000   \n",
      "14                            Interest Income            0.000000   \n",
      "\n",
      "    Standard Deviation  \n",
      "0             0.010192  \n",
      "1             0.010267  \n",
      "2             0.004940  \n",
      "3             0.004233  \n",
      "4             0.001890  \n",
      "5             0.002348  \n",
      "6             0.002349  \n",
      "7             0.000093  \n",
      "8             0.000098  \n",
      "9             0.000225  \n",
      "10            0.000150  \n",
      "11            0.000140  \n",
      "12            0.000131  \n",
      "13            0.000000  \n",
      "14            0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load data\n",
    "    permutation_importance = pd.read_parquet('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_permutation_importance.parquet')\n",
    "    permutation_importance = permutation_importance.sort_values('mean',ascending=False)\n",
    "    # Set columns to \"Feature\", \"Mean\", \"Standard Deviation\"\n",
    "    permutation_importance.columns = ['Feature', 'Mean', 'Standard Deviation']\n",
    "     # Strip 'cat__' and 'num__' from Feature\n",
    "    permutation_importance['Feature'] = permutation_importance['Feature'].str.replace('cat__', '').str.replace('num__', '')\n",
    "    # Use variable_index to get feature names\n",
    "    permutation_importance = permutation_importance.merge(variable_index[['column_name', 'Clean Column Name']], left_on='Feature', right_on='column_name', how='left')\n",
    "    # Set Clean_Column_Name to Feature if no match\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].fillna(permutation_importance['Feature'])\n",
    "    # Drop Feature and column_name\n",
    "    permutation_importance = permutation_importance.drop(columns=['Feature', 'column_name'])\n",
    "    # Clean up names for categorical columns\n",
    "    previous_rating_mapping = {'rating_on_previous_fixed_quarter_date_AAA': 'Rating on Previous Fixed Quarter Date AAA',\n",
    "                                'rating_on_previous_fixed_quarter_date_AA': 'Rating on Previous Fixed Quarter Date AA',\n",
    "                                'rating_on_previous_fixed_quarter_date_A': 'Rating on Previous Fixed Quarter Date A',\n",
    "                                'rating_on_previous_fixed_quarter_date_BBB': 'Rating on Previous Fixed Quarter Date BBB',\n",
    "                                'rating_on_previous_fixed_quarter_date_BB': 'Rating on Previous Fixed Quarter Date BB',\n",
    "                                'rating_on_previous_fixed_quarter_date_B': 'Rating on Previous Fixed Quarter Date B',\n",
    "                                'rating_on_previous_fixed_quarter_date_CCC': 'Rating on Previous Fixed Quarter Date CCC',\n",
    "                                'rating_on_previous_fixed_quarter_date_CC': 'Rating on Previous Fixed Quarter Date CC',\n",
    "                                'rating_on_previous_fixed_quarter_date_C': 'Rating on Previous Fixed Quarter Date C',\n",
    "                                'rating_on_previous_fixed_quarter_date_D': 'Rating on Previous Fixed Quarter Date D'}\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].replace(previous_rating_mapping)\n",
    "    # Replace 'Sector_' with 'Sector: '\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].str.replace('Sector_', 'Sector: ')\n",
    "    # Rename Clean Column Name to Feature\n",
    "    permutation_importance = permutation_importance.rename(columns={'Clean Column Name': 'Feature'})\n",
    "    # Reorder columns to put Feature first\n",
    "    permutation_importance = permutation_importance[['Feature', 'Mean', 'Standard Deviation']]\n",
    "    # Rename Mean to 'Mean Accuracy Drop'\n",
    "    permutation_importance = permutation_importance.rename(columns={'Mean': 'Mean Accuracy Drop'})\n",
    "    # Rename Feature to 'Permuted Feature'\n",
    "    permutation_importance = permutation_importance.rename(columns={'Feature': 'Permuted Feature'})\n",
    "    # Get top 15\n",
    "    pi_top_15 = permutation_importance.head(15)\n",
    "\n",
    "    # Export to Excel\n",
    "    pi_top_15.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Permutation_Importance_Top_15.xlsx', index=False)\n",
    "\n",
    "    # Export to Latex\n",
    "    #pi_top_15.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Permutation_Importance_Top_15.tex', index=False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Center all columns\n",
    "    lt_string = pi_top_15.to_latex(index=False, column_format='c' * len(pi_top_15.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\tiny\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Permutation_Importance_Top_15.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(pi_top_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Model Comparison Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.9186   \n",
      "0                 Financial Variables and Sector   0.9517   \n",
      "0  Financial Variables, Sector, and NLP Features   0.9535   \n",
      "0                              Majority Baseline   0.9535   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \n",
      "0                     0.9111                  0.9186   0.9148  \n",
      "0                     0.9091                  0.9517   0.9299  \n",
      "0                     0.9091                  0.9535   0.9308  \n",
      "0                                                              \n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.8488   \n",
      "0                 Financial Variables and Sector   0.9454   \n",
      "0  Financial Variables, Sector, and NLP Features   0.9472   \n",
      "0                              Majority Baseline   0.9535   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \n",
      "0                     0.9117                  0.8488   0.8787  \n",
      "0                     0.9112                  0.9454   0.9280  \n",
      "0                     0.9097                  0.9472   0.9281  \n",
      "0                                                              \n"
     ]
    }
   ],
   "source": [
    "# Iterate over just models '_' versus _smote_\n",
    "for spec in ['', 'smote_']:\n",
    "\n",
    "    # Create list of df rows\n",
    "    model_comparison_rows = []\n",
    "    majority_baselines = []\n",
    "    for mn, clean_model_name in zip(['rating_change_model_1', 'rating_change_model_2', 'rating_change_model_3'], [\"Altman's Z\", 'Financial Variables and Sector', 'Financial Variables, Sector, and NLP Features']):\n",
    "        model_comparison_row, majority_baseline = get_model_comparison_row(spec + mn, clean_model_name)\n",
    "        model_comparison_rows.append(model_comparison_row)\n",
    "        majority_baselines.append(majority_baseline)\n",
    "\n",
    "    # Concatenate rows\n",
    "    model_comparison_df = pd.concat(model_comparison_rows)\n",
    "\n",
    "    # Check majority baselines are the same\n",
    "    print('Majority baselines are the same:', all([majority_baseline == majority_baselines[0] for majority_baseline in majority_baselines]))\n",
    "    # Add row with Model/Baseline = 'Majority Baseline' and Accuracy = majority_baseline[0]\n",
    "    model_comparison_df = pd.concat([model_comparison_df, pd.DataFrame({\n",
    "        'Model/Baseline': ['Majority Baseline'],\n",
    "        'Accuracy': [majority_baselines[0]],\n",
    "        'Weighted Average Precision': [''],\n",
    "        'Weighted Average Recall': [''],\n",
    "        'F1 Score': [''],\n",
    "        'Share 1 Rating Or Less From Actual': ['']\n",
    "    })])\n",
    "    # Drop 'Share 1 Rating Or Less From Actual' column\n",
    "    model_comparison_df = model_comparison_df.drop(columns=['Share 1 Rating Or Less From Actual'])\n",
    "\n",
    "    # Export to Excel\n",
    "    model_comparison_df.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/change_' + spec + 'model_comparison_df.xlsx', index = False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in model_comparison_df.columns:\n",
    "        model_comparison_df[col] = model_comparison_df[col].apply(lambda x: f'{x:.4f}' if isinstance(x, float) else x)\n",
    "    # Rename 'Share 1 Rating Or Less From Actual' to 'Share $le$ Rating From Actual'\n",
    "    #model_comparison_df.rename(columns={'Share 1 Rating Or Less From Actual': 'Share $\\\\le$ 1 Rating From Actual'}, inplace=True)\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df.to_latex(index=False, column_format='c' * len(model_comparison_df.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/change_' + spec + 'model_comparison_df.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(model_comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
