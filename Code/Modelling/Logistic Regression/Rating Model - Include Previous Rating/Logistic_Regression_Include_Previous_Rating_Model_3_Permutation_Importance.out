Starting Job
[NbConvertApp] Converting notebook Logistic_Regression_Include_Previous_Rating_Model_3_Permutation_Importance.ipynb to notebook
0.00s - Debugger warning: It seems that frozen modules are being used, which may
0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
0.00s - to python to disable frozen modules.
0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
Traceback (most recent call last):
  File "/scratch/users/ijyliu/conda/envs/scf_general/bin/jupyter-nbconvert", line 10, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/jupyter_core/application.py", line 283, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/traitlets/config/application.py", line 1075, in launch_instance
    app.start()
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/asyncio/base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# Perform permutation importance
result = permutation_importance(model, X_test_scaled.toarray(), y_test, n_repeats=1000, random_state=222, n_jobs=-1)

# Check lengths
print('shape X: ', X_test_scaled.shape)
print('num + cat: ', len(numeric_feature_columns + cat_feature_columns))
print('importances: ', len(result.importances_mean))
print('stds: ', len(result.importances_std))

# Expanded feature column names
# Version for include previous rating
if 'include_previous_rating' in model_name:
    expanded_cat_cols = ['cat__rating_on_previous_fixed_quarter_date_A',
    'cat__rating_on_previous_fixed_quarter_date_AA',
    'cat__rating_on_previous_fixed_quarter_date_AAA',
    'cat__rating_on_previous_fixed_quarter_date_B',
    'cat__rating_on_previous_fixed_quarter_date_BB',
    'cat__rating_on_previous_fixed_quarter_date_BBB',
    'cat__rating_on_previous_fixed_quarter_date_C',
    'cat__rating_on_previous_fixed_quarter_date_CC',
    'cat__rating_on_previous_fixed_quarter_date_CCC',
    'cat__rating_on_previous_fixed_quarter_date_D',
    'cat__Sector_Communication Services',
    'cat__Sector_Consumer Discretionary',
    'cat__Sector_Consumer Staples',
    'cat__Sector_Energy',
    'cat__Sector_Financials', 
    'cat__Sector_Health Care',
    'cat__Sector_Industrials', 
    'cat__Sector_Information Technology',
    'cat__Sector_Materials',
    'cat__Sector_Real Estate',
    'cat__Sector_Utilities']
# Version for exclude previous rating
if 'exclude_previous_rating' in model_name:
    expanded_cat_cols = ['cat__rating_on_previous_fixed_quarter_date_A',
    'cat__rating_on_previous_fixed_quarter_date_AA',
    'cat__rating_on_previous_fixed_quarter_date_AAA',
    'cat__rating_on_previous_fixed_quarter_date_B',
    'cat__rating_on_previous_fixed_quarter_date_BB',
    'cat__rating_on_previous_fixed_quarter_date_BBB',
    'cat__rating_on_previous_fixed_quarter_date_C',
    'cat__rating_on_previous_fixed_quarter_date_CC',
    'cat__rating_on_previous_fixed_quarter_date_CCC',
    'cat__rating_on_previous_fixed_quarter_date_D']

print('with expanded')
print(len(numeric_feature_columns + expanded_cat_cols))

print('importances mean')
print(result.importances_mean)

print('imp std')
print(result.importances_std)

# Put column name, mean and std in a dataframe
result = pd.DataFrame({'feature': numeric_feature_columns + expanded_cat_cols, 'mean': result.importances_mean, 'std': result.importances_std})

# Output to disk
result.to_parquet('../../../../Output/Modelling/Logistic Regression/' + model_name + '/' + model_name + '_permutation_importance.parquet', index=False)

result
------------------

----- stdout -----
shape X:  (1127, 14846)
num + cat:  133
importances:  14846
stds:  14846
with expanded
146
importances mean
[0.00000000e+00 0.00000000e+00 2.66193434e-06 ... 0.00000000e+00
 2.17941437e-02 0.00000000e+00]
imp std
[0.00000000e+00 0.00000000e+00 4.85270946e-05 ... 0.00000000e+00
 7.40336854e-04 0.00000000e+00]
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
Cell [0;32mIn[6], line 57[0m
[1;32m     54[0m [38;5;28mprint[39m(result[38;5;241m.[39mimportances_std)
[1;32m     56[0m [38;5;66;03m# Put column name, mean and std in a dataframe[39;00m
[0;32m---> 57[0m result [38;5;241m=[39m [43mpd[49m[38;5;241;43m.[39;49m[43mDataFrame[49m[43m([49m[43m{[49m[38;5;124;43m'[39;49m[38;5;124;43mfeature[39;49m[38;5;124;43m'[39;49m[43m:[49m[43m [49m[43mnumeric_feature_columns[49m[43m [49m[38;5;241;43m+[39;49m[43m [49m[43mexpanded_cat_cols[49m[43m,[49m[43m [49m[38;5;124;43m'[39;49m[38;5;124;43mmean[39;49m[38;5;124;43m'[39;49m[43m:[49m[43m [49m[43mresult[49m[38;5;241;43m.[39;49m[43mimportances_mean[49m[43m,[49m[43m [49m[38;5;124;43m'[39;49m[38;5;124;43mstd[39;49m[38;5;124;43m'[39;49m[43m:[49m[43m [49m[43mresult[49m[38;5;241;43m.[39;49m[43mimportances_std[49m[43m}[49m[43m)[49m
[1;32m     59[0m [38;5;66;03m# Output to disk[39;00m
[1;32m     60[0m result[38;5;241m.[39mto_parquet([38;5;124m'[39m[38;5;124m../../../../Output/Modelling/Logistic Regression/[39m[38;5;124m'[39m [38;5;241m+[39m model_name [38;5;241m+[39m [38;5;124m'[39m[38;5;124m/[39m[38;5;124m'[39m [38;5;241m+[39m model_name [38;5;241m+[39m [38;5;124m'[39m[38;5;124m_permutation_importance.parquet[39m[38;5;124m'[39m, index[38;5;241m=[39m[38;5;28;01mFalse[39;00m)

File [0;32m/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/pandas/core/frame.py:767[0m, in [0;36mDataFrame.__init__[0;34m(self, data, index, columns, dtype, copy)[0m
[1;32m    761[0m     mgr [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_init_mgr(
[1;32m    762[0m         data, axes[38;5;241m=[39m{[38;5;124m"[39m[38;5;124mindex[39m[38;5;124m"[39m: index, [38;5;124m"[39m[38;5;124mcolumns[39m[38;5;124m"[39m: columns}, dtype[38;5;241m=[39mdtype, copy[38;5;241m=[39mcopy
[1;32m    763[0m     )
[1;32m    765[0m [38;5;28;01melif[39;00m [38;5;28misinstance[39m(data, [38;5;28mdict[39m):
[1;32m    766[0m     [38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases[39;00m
[0;32m--> 767[0m     mgr [38;5;241m=[39m [43mdict_to_mgr[49m[43m([49m[43mdata[49m[43m,[49m[43m [49m[43mindex[49m[43m,[49m[43m [49m[43mcolumns[49m[43m,[49m[43m [49m[43mdtype[49m[38;5;241;43m=[39;49m[43mdtype[49m[43m,[49m[43m [49m[43mcopy[49m[38;5;241;43m=[39;49m[43mcopy[49m[43m,[49m[43m [49m[43mtyp[49m[38;5;241;43m=[39;49m[43mmanager[49m[43m)[49m
[1;32m    768[0m [38;5;28;01melif[39;00m [38;5;28misinstance[39m(data, ma[38;5;241m.[39mMaskedArray):
[1;32m    769[0m     [38;5;28;01mfrom[39;00m [38;5;21;01mnumpy[39;00m[38;5;21;01m.[39;00m[38;5;21;01mma[39;00m [38;5;28;01mimport[39;00m mrecords

File [0;32m/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/pandas/core/internals/construction.py:503[0m, in [0;36mdict_to_mgr[0;34m(data, index, columns, dtype, typ, copy)[0m
[1;32m    499[0m     [38;5;28;01melse[39;00m:
[1;32m    500[0m         [38;5;66;03m# dtype check to exclude e.g. range objects, scalars[39;00m
[1;32m    501[0m         arrays [38;5;241m=[39m [x[38;5;241m.[39mcopy() [38;5;28;01mif[39;00m [38;5;28mhasattr[39m(x, [38;5;124m"[39m[38;5;124mdtype[39m[38;5;124m"[39m) [38;5;28;01melse[39;00m x [38;5;28;01mfor[39;00m x [38;5;129;01min[39;00m arrays]
[0;32m--> 503[0m [38;5;28;01mreturn[39;00m [43marrays_to_mgr[49m[43m([49m[43marrays[49m[43m,[49m[43m [49m[43mcolumns[49m[43m,[49m[43m [49m[43mindex[49m[43m,[49m[43m [49m[43mdtype[49m[38;5;241;43m=[39;49m[43mdtype[49m[43m,[49m[43m [49m[43mtyp[49m[38;5;241;43m=[39;49m[43mtyp[49m[43m,[49m[43m [49m[43mconsolidate[49m[38;5;241;43m=[39;49m[43mcopy[49m[43m)[49m

File [0;32m/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/pandas/core/internals/construction.py:114[0m, in [0;36marrays_to_mgr[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)[0m
[1;32m    111[0m [38;5;28;01mif[39;00m verify_integrity:
[1;32m    112[0m     [38;5;66;03m# figure out the index, if necessary[39;00m
[1;32m    113[0m     [38;5;28;01mif[39;00m index [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[0;32m--> 114[0m         index [38;5;241m=[39m [43m_extract_index[49m[43m([49m[43marrays[49m[43m)[49m
[1;32m    115[0m     [38;5;28;01melse[39;00m:
[1;32m    116[0m         index [38;5;241m=[39m ensure_index(index)

File [0;32m/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/pandas/core/internals/construction.py:677[0m, in [0;36m_extract_index[0;34m(data)[0m
[1;32m    675[0m lengths [38;5;241m=[39m [38;5;28mlist[39m([38;5;28mset[39m(raw_lengths))
[1;32m    676[0m [38;5;28;01mif[39;00m [38;5;28mlen[39m(lengths) [38;5;241m>[39m [38;5;241m1[39m:
[0;32m--> 677[0m     [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m([38;5;124m"[39m[38;5;124mAll arrays must be of the same length[39m[38;5;124m"[39m)
[1;32m    679[0m [38;5;28;01mif[39;00m have_dicts:
[1;32m    680[0m     [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m(
[1;32m    681[0m         [38;5;124m"[39m[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.[39m[38;5;124m"[39m
[1;32m    682[0m     )

[0;31mValueError[0m: All arrays must be of the same length

Completed Job
Time elapsed: 1274 minute(s).
