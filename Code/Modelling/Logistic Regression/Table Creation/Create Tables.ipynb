{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>Clean Column Name</th>\n",
       "      <th>Variable Type</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Rating Model 1</th>\n",
       "      <th>Rating Model 2</th>\n",
       "      <th>Rating Model 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Altman_Z</td>\n",
       "      <td>Altman's Z Score</td>\n",
       "      <td>Altman's Z Score</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBIT</td>\n",
       "      <td>EBIT</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_plus_preferred_stock</td>\n",
       "      <td>Common Plus Preferred Stock</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>workingCapital</td>\n",
       "      <td>Working Capital</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ratio_A</td>\n",
       "      <td>Ratio A</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Investment_Grade</td>\n",
       "      <td>Investment Grade</td>\n",
       "      <td>Predicted - Rating</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Whether rating is BBB or above</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>rating_on_previous_fixed_quarter_date</td>\n",
       "      <td>Rating on Previous Fixed Quarter Date</td>\n",
       "      <td>Previous Rating</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Useful as a predictor</td>\n",
       "      <td>X (Previous Rating Models)</td>\n",
       "      <td>X (Previous Rating Models)</td>\n",
       "      <td>X (Previous Rating Models)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Sector</td>\n",
       "      <td>Sector</td>\n",
       "      <td>Sector</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>train_test_80_20</td>\n",
       "      <td>80-20% Train Test Split</td>\n",
       "      <td>Train-Test Split</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>transcript</td>\n",
       "      <td>Transcript</td>\n",
       "      <td>Transcript Text</td>\n",
       "      <td>Text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               column_name  \\\n",
       "0                                 Altman_Z   \n",
       "1                                     EBIT   \n",
       "2              common_plus_preferred_stock   \n",
       "3                           workingCapital   \n",
       "4                                  Ratio_A   \n",
       "..                                     ...   \n",
       "154                       Investment_Grade   \n",
       "155  rating_on_previous_fixed_quarter_date   \n",
       "156                                 Sector   \n",
       "157                       train_test_80_20   \n",
       "158                             transcript   \n",
       "\n",
       "                         Clean Column Name               Variable Type  \\\n",
       "0                         Altman's Z Score            Altman's Z Score   \n",
       "1                                     EBIT  Constructed for Altman's Z   \n",
       "2              Common Plus Preferred Stock  Constructed for Altman's Z   \n",
       "3                          Working Capital  Constructed for Altman's Z   \n",
       "4                                  Ratio A  Constructed for Altman's Z   \n",
       "..                                     ...                         ...   \n",
       "154                       Investment Grade          Predicted - Rating   \n",
       "155  Rating on Previous Fixed Quarter Date             Previous Rating   \n",
       "156                                 Sector                      Sector   \n",
       "157                80-20% Train Test Split            Train-Test Split   \n",
       "158                             Transcript             Transcript Text   \n",
       "\n",
       "       Data Type                           Notes              Rating Model 1  \\\n",
       "0        Numeric                             NaN                           X   \n",
       "1        Numeric                             NaN                         NaN   \n",
       "2        Numeric                             NaN                         NaN   \n",
       "3        Numeric                             NaN                         NaN   \n",
       "4        Numeric                             NaN                         NaN   \n",
       "..           ...                             ...                         ...   \n",
       "154  Categorical  Whether rating is BBB or above                         NaN   \n",
       "155  Categorical           Useful as a predictor  X (Previous Rating Models)   \n",
       "156  Categorical                             NaN                         NaN   \n",
       "157  Categorical                             NaN                         NaN   \n",
       "158         Text                             NaN                         NaN   \n",
       "\n",
       "                 Rating Model 2              Rating Model 3  \n",
       "0                           NaN                         NaN  \n",
       "1                             X                           X  \n",
       "2                             X                           X  \n",
       "3                             X                           X  \n",
       "4                             X                           X  \n",
       "..                          ...                         ...  \n",
       "154                         NaN                         NaN  \n",
       "155  X (Previous Rating Models)  X (Previous Rating Models)  \n",
       "156                           X                           X  \n",
       "157                         NaN                         NaN  \n",
       "158                         NaN                         NaN  \n",
       "\n",
       "[159 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load variable index\n",
    "variable_index = pd.read_excel('../../../../Variable Index.xlsx')\n",
    "variable_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Rating Models and Most Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['rating_model_1', 'rating_model_2', 'rating_model_3']\n",
    "clean_model_names = [\"Altman's Z\", 'Financial Variables and Sector', 'Financial Variables, Sector, and NLP Features']\n",
    "# set most_complex_model \n",
    "most_complex_model = 'rating_model_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_comparison_row(model_name, clean_model_name):\n",
    "    '''\n",
    "    Given the model name and clean model name, this function returns the model comparison row.\n",
    "    '''\n",
    "\n",
    "    # Load close_exact_dict\n",
    "    close_exact_dict = pd.read_pickle('../../../../Output/Modelling/Logistic Regression/' + model_name + '/' + model_name + '_close_exact_dict.pkl')\n",
    "    # Version with each item rounded to 4 decimal places\n",
    "    close_exact_dict_rounded = {k: round(v, 4) for k, v in close_exact_dict.items()}\n",
    "    # Unpack\n",
    "    exact_predictions_share = close_exact_dict_rounded['exact_predictions_share']\n",
    "    close_predictions_share = close_exact_dict_rounded['close_predictions_share']\n",
    "\n",
    "    # Load acc_f1_majority\n",
    "    acc_f1_majority = pd.read_pickle('../../../../Output/Modelling/Logistic Regression/' + model_name + '/' + model_name + '_acc_f1_majority.pkl')\n",
    "    # Version with each item rounded to 2 decimal places\n",
    "    acc_f1_majority_rounded = {k: round(v, 4) for k, v in acc_f1_majority.items()}\n",
    "    # Unpack\n",
    "    accuracy = acc_f1_majority_rounded['accuracy']\n",
    "    f1 = acc_f1_majority_rounded['f1_score']\n",
    "    majority_baseline = acc_f1_majority_rounded['majority_baseline']\n",
    "\n",
    "    # Check exact_predictions_share == accuracy\n",
    "    print('exact predictions share == accuracy:', exact_predictions_share == accuracy)\n",
    "\n",
    "    # Get weighted average precision and recall from classification report\n",
    "    classification_report = pd.read_pickle('../../../../Output/Modelling/Logistic Regression/' + model_name + '/' + model_name + '_classification_report.pkl')\n",
    "    # Convert classification report string to dataframe\n",
    "    classification_report_lines = classification_report.split('\\n')\n",
    "    # split on spaces within and drop blanks\n",
    "    classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "    # drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "    classification_report_data = [line for line in classification_report_data if line[0] in ['weighted']]\n",
    "    # Unpack\n",
    "    weighted_avg_precision = classification_report_data[0][2]\n",
    "    weighted_avg_recall = classification_report_data[0][3]\n",
    "\n",
    "    # Create dataframe row\n",
    "    model_comparison_row = pd.DataFrame({\n",
    "        'Model/Baseline': [clean_model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Weighted Average Precision': [weighted_avg_precision],\n",
    "        'Weighted Average Recall': [weighted_avg_recall],\n",
    "        'F1 Score': [f1],\n",
    "        'Share 1 Rating Or Less From Actual': [close_predictions_share]\n",
    "    })\n",
    "\n",
    "    # Return row\n",
    "    return model_comparison_row, majority_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Table - Include and Exclude Previous Rating Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.3585   \n",
      "0                 Financial Variables and Sector   0.6105   \n",
      "0  Financial Variables, Sector, and NLP Features   0.6122   \n",
      "0                              Majority Baseline   0.3159   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
      "0                       0.25                    0.36   0.2891   \n",
      "0                       0.60                    0.61   0.6002   \n",
      "0                       0.61                    0.61   0.6034   \n",
      "0                                                               \n",
      "\n",
      "  Share $\\le$ 1 Rating From Actual  \n",
      "0                           0.8119  \n",
      "0                           0.9379  \n",
      "0                           0.9388  \n",
      "0                                   \n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.9556   \n",
      "0                 Financial Variables and Sector   0.9530   \n",
      "0  Financial Variables, Sector, and NLP Features   0.9530   \n",
      "0                              Majority Baseline   0.3159   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
      "0                       0.96                    0.96   0.9556   \n",
      "0                       0.95                    0.95   0.9517   \n",
      "0                       0.95                    0.95   0.9517   \n",
      "0                                                               \n",
      "\n",
      "  Share $\\le$ 1 Rating From Actual  \n",
      "0                           0.9947  \n",
      "0                           0.9920  \n",
      "0                           0.9920  \n",
      "0                                   \n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Create list of df rows\n",
    "    model_comparison_rows = []\n",
    "    majority_baselines = []\n",
    "    for model_name, clean_model_name in zip(model_names, clean_model_names):\n",
    "        model_comparison_row, majority_baseline = get_model_comparison_row(include_exclude_previous + model_name, clean_model_name)\n",
    "        model_comparison_rows.append(model_comparison_row)\n",
    "        majority_baselines.append(majority_baseline)\n",
    "\n",
    "    # Concatenate rows\n",
    "    model_comparison_df = pd.concat(model_comparison_rows)\n",
    "\n",
    "    # Check majority baselines are the same\n",
    "    print('Majority baselines are the same:', all([majority_baseline == majority_baselines[0] for majority_baseline in majority_baselines]))\n",
    "    # Add row with Model/Baseline = 'Majority Baseline' and Accuracy = majority_baseline[0]\n",
    "    model_comparison_df = pd.concat([model_comparison_df, pd.DataFrame({\n",
    "        'Model/Baseline': ['Majority Baseline'],\n",
    "        'Accuracy': [majority_baselines[0]],\n",
    "        'Weighted Average Precision': [''],\n",
    "        'Weighted Average Recall': [''],\n",
    "        'F1 Score': [''],\n",
    "        'Share 1 Rating Or Less From Actual': ['']\n",
    "    })])\n",
    "\n",
    "    # Export to Excel\n",
    "    model_comparison_df.to_excel('../../../../Output/Modelling/Logistic Regression/Tables/' + include_exclude_previous + 'model_comparison_df.xlsx', index = False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in model_comparison_df.columns:\n",
    "        model_comparison_df[col] = model_comparison_df[col].apply(lambda x: f'{x:.4f}' if isinstance(x, float) else x)\n",
    "    # Rename 'Share 1 Rating Or Less From Actual' to 'Share $le$ Rating From Actual'\n",
    "    model_comparison_df.rename(columns={'Share 1 Rating Or Less From Actual': 'Share $\\\\le$ 1 Rating From Actual'}, inplace=True)\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df.to_latex(index=False, column_format='c' * len(model_comparison_df.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/Logistic Regression/Tables/' + include_exclude_previous + 'model_comparison_df.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(model_comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Classification Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../../Output/Modelling/Logistic Regression/rating_model_3/rating_model_3_classification_report.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load classificiation report from pickle\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m classification_report \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../../../Output/Modelling/Logistic Regression/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmost_complex_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmost_complex_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_classification_report.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Convert classification report string to dataframe\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\miniforge3\\envs\\capstone\\Lib\\site-packages\\pandas\\io\\pickle.py:189\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\miniforge3\\envs\\capstone\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../../Output/Modelling/Logistic Regression/rating_model_3/rating_model_3_classification_report.pkl'"
     ]
    }
   ],
   "source": [
    "# Load classificiation report from pickle\n",
    "classification_report = pd.read_pickle('../../../../Output/Modelling/Logistic Regression/' + most_complex_model + '/' + most_complex_model + '_classification_report.pkl')\n",
    "print(classification_report)\n",
    "\n",
    "# Convert classification report string to dataframe\n",
    "classification_report_lines = classification_report.split('\\n')\n",
    "# split on spaces within and drop blanks\n",
    "classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "# drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "classification_report_data = [line for line in classification_report_data if line[0] not in ['precision', 'accuracy', 'macro', 'weighted']]\n",
    "# Stack list of rows into dataframe\n",
    "classification_report_data = pd.DataFrame(classification_report_data)\n",
    "# Set columns to \"Rating\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"\n",
    "classification_report_data.columns = ['Rating', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "print(classification_report_data)\n",
    "\n",
    "# Export to Excel\n",
    "classification_report_data.to_excel('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Classification_Report.xlsx', index=False)\n",
    "\n",
    "# Export to Latex\n",
    "#classification_report_data.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Classification_Report.tex', index=False)\n",
    "\n",
    "# Export to LaTeX\n",
    "# Format columns\n",
    "for col in classification_report_data.columns:\n",
    "    classification_report_data[col] = classification_report_data[col].apply(lambda x: f'{x:.2f}' if isinstance(x, float) else x)\n",
    "# Center all columns\n",
    "lt_string = classification_report_data.to_latex(index=False, column_format='c' * 5, escape=False)\n",
    "latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "with open('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Classification_Report.tex', 'w') as f:\n",
    "    f.write(latex_with_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'class_weight': 'balanced', 'l1_ratio': 1.0, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "     C Class Weighting Strategy  L1 Ratio Multi-Class Strategy      Penalty  \\\n",
      "0  0.1                 Balanced       1.0          One vs Rest  Elastic Net   \n",
      "\n",
      "  Solver  \n",
      "0   SAGA  \n"
     ]
    }
   ],
   "source": [
    "# Load pickle '../../../../Output/Modelling/Logistic Regression/' + most_complex_model + '/' + most_complex_model + '_best_params.pkl'\n",
    "best_params = pd.read_pickle('../../../../Output/Modelling/Logistic Regression/' + most_complex_model + '/' + most_complex_model + '_best_params.pkl')\n",
    "print(best_params)\n",
    "\n",
    "# Convert to dataframe\n",
    "best_params = pd.DataFrame(best_params, index=[0])\n",
    "# Set columns to \"C\", \"Class Weighting Strategy\", \"L1 Ratio\", \"Multi-Class Strategy\", \"Penalty\", \"Solver\"\n",
    "best_params.columns = ['C', 'Class Weighting Strategy', 'L1 Ratio', 'Multi-Class Strategy', 'Penalty', 'Solver']\n",
    "# Replace 'Multi-Class Strategy' values\n",
    "best_params['Multi-Class Strategy'] = best_params['Multi-Class Strategy'].replace({'ovr': 'One vs Rest', 'multinomial': 'Multinomial'})\n",
    "# Replace 'Penalty' values\n",
    "best_params['Penalty'] = best_params['Penalty'].replace({'l1': 'L1', 'l2': 'L2', 'elasticnet': 'Elastic Net', 'none': 'None'})\n",
    "# Replace 'Solver' values\n",
    "best_params['Solver'] = best_params['Solver'].replace({'newton-cg': 'Newton Conjugate Gradient', 'lbfgs': 'Limited Memory Broyden–Fletcher–Goldfarb–Shanno', 'liblinear': 'Library for Large Linear Classification', 'sag': 'Stochastic Average Gradient', 'saga': 'SAGA'})\n",
    "# Replace Class Weighting Strategy values\n",
    "best_params['Class Weighting Strategy'] = best_params['Class Weighting Strategy'].replace({'balanced': 'Balanced', None: 'None'})\n",
    "print(best_params)\n",
    "\n",
    "# Export to Excel\n",
    "best_params.to_excel('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Best_Params.xlsx', index=False)\n",
    "\n",
    "# Export to Latex\n",
    "#best_params.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Best_Params.tex', index=False)\n",
    "\n",
    "# Export to LaTeX\n",
    "for col in ['C', 'L1 Ratio']:\n",
    "    best_params[col] = best_params[col].apply(lambda x: '{:,.2f}'.format(x))\n",
    "# Center all columns\n",
    "lt_string = best_params.to_latex(index=False, column_format='c' * len(best_params.columns), escape=False)\n",
    "latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "with open('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Best_Params.tex', 'w') as f:\n",
    "    f.write(latex_with_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permuted Feature</th>\n",
       "      <th>Mean Accuracy Drop</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rating on Previous Fixed Quarter Date BBB</td>\n",
       "      <td>0.281622</td>\n",
       "      <td>0.010257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rating on Previous Fixed Quarter Date BB</td>\n",
       "      <td>0.230148</td>\n",
       "      <td>0.009061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rating on Previous Fixed Quarter Date A</td>\n",
       "      <td>0.107111</td>\n",
       "      <td>0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rating on Previous Fixed Quarter Date B</td>\n",
       "      <td>0.079304</td>\n",
       "      <td>0.004862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rating on Previous Fixed Quarter Date AA</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.002093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rating on Previous Fixed Quarter Date CCC</td>\n",
       "      <td>0.012949</td>\n",
       "      <td>0.001282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total Non-Current Liabilities</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total Stockholders' Equity</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Research and Development Expenses</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Net Receivables</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gunning-Fog Score</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dividends Paid</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Other Current Liabilities</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Debt Repayment</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Numeric Transparency</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Permuted Feature  Mean Accuracy Drop  \\\n",
       "0   Rating on Previous Fixed Quarter Date BBB            0.281622   \n",
       "1    Rating on Previous Fixed Quarter Date BB            0.230148   \n",
       "2     Rating on Previous Fixed Quarter Date A            0.107111   \n",
       "3     Rating on Previous Fixed Quarter Date B            0.079304   \n",
       "4    Rating on Previous Fixed Quarter Date AA            0.013898   \n",
       "5   Rating on Previous Fixed Quarter Date CCC            0.012949   \n",
       "6               Total Non-Current Liabilities            0.000867   \n",
       "7                  Total Stockholders' Equity            0.000809   \n",
       "8           Research and Development Expenses            0.000789   \n",
       "9                             Net Receivables            0.000779   \n",
       "10                          Gunning-Fog Score            0.000764   \n",
       "11                             Dividends Paid            0.000663   \n",
       "12                  Other Current Liabilities            0.000659   \n",
       "13                             Debt Repayment            0.000631   \n",
       "14                       Numeric Transparency            0.000543   \n",
       "\n",
       "    Standard Deviation  \n",
       "0             0.010257  \n",
       "1             0.009061  \n",
       "2             0.005848  \n",
       "3             0.004862  \n",
       "4             0.002093  \n",
       "5             0.001282  \n",
       "6             0.000612  \n",
       "7             0.000366  \n",
       "8             0.000284  \n",
       "9             0.000314  \n",
       "10            0.000307  \n",
       "11            0.000504  \n",
       "12            0.000388  \n",
       "13            0.000402  \n",
       "14            0.000469  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load '../../../../Output/Modelling/Logistic Regression/rating_model_4/rating_model_4_permutation_importance.parquet'\n",
    "permutation_importance = pd.read_parquet('../../../../Output/Modelling/Logistic Regression/rating_model_4/rating_model_4_permutation_importance.parquet')\n",
    "permutation_importance = permutation_importance.sort_values('mean',ascending=False)\n",
    "# Set columns to \"Feature\", \"Mean\", \"Standard Deviation\"\n",
    "permutation_importance.columns = ['Feature', 'Mean', 'Standard Deviation']\n",
    "# Use variable_index to get feature names\n",
    "permutation_importance = permutation_importance.merge(variable_index[['column_name', 'Clean Column Name']], left_on='Feature', right_on='column_name', how='left')\n",
    "# Set Clean_Column_Name to Feature if no match\n",
    "permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].fillna(permutation_importance['Feature'])\n",
    "# Drop Feature and column_name\n",
    "permutation_importance = permutation_importance.drop(columns=['Feature', 'column_name'])\n",
    "# Clean up names for categorical columns\n",
    "previous_rating_mapping = {'cat__rating_on_previous_fixed_quarter_date_AAA': 'Rating on Previous Fixed Quarter Date AAA',\n",
    "                            'cat__rating_on_previous_fixed_quarter_date_AA': 'Rating on Previous Fixed Quarter Date AA',\n",
    "                            'cat__rating_on_previous_fixed_quarter_date_A': 'Rating on Previous Fixed Quarter Date A',\n",
    "                            'cat__rating_on_previous_fixed_quarter_date_BBB': 'Rating on Previous Fixed Quarter Date BBB',\n",
    "                            'cat__rating_on_previous_fixed_quarter_date_BB': 'Rating on Previous Fixed Quarter Date BB',\n",
    "                            'cat__rating_on_previous_fixed_quarter_date_B': 'Rating on Previous Fixed Quarter Date B',\n",
    "                            'cat__rating_on_previous_fixed_quarter_date_CCC': 'Rating on Previous Fixed Quarter Date CCC',\n",
    "                            'cat__rating_on_previous_fixed_quarter_date_CC': 'Rating on Previous Fixed Quarter Date CC',\n",
    "                            'cat__rating_on_previous_fixed_quarter_date_C': 'Rating on Previous Fixed Quarter Date C',\n",
    "                            'cat__rating_on_previous_fixed_quarter_date_D': 'Rating on Previous Fixed Quarter Date D'}\n",
    "permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].replace(previous_rating_mapping)\n",
    "# Rename Clean Column Name to Feature\n",
    "permutation_importance = permutation_importance.rename(columns={'Clean Column Name': 'Feature'})\n",
    "# Reorder columns to put Feature first\n",
    "permutation_importance = permutation_importance[['Feature', 'Mean', 'Standard Deviation']]\n",
    "# Rename Mean to 'Mean Accuracy Drop'\n",
    "permutation_importance = permutation_importance.rename(columns={'Mean': 'Mean Accuracy Drop'})\n",
    "# Rename Feature to 'Permuted Feature'\n",
    "permutation_importance = permutation_importance.rename(columns={'Feature': 'Permuted Feature'})\n",
    "# Get top 15\n",
    "pi_top_15 = permutation_importance.head(15)\n",
    "\n",
    "# Export to Excel\n",
    "pi_top_15.to_excel('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Permutation_Importance_Top_15.xlsx', index=False)\n",
    "\n",
    "# Export to Latex\n",
    "#pi_top_15.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Permutation_Importance_Top_15.tex', index=False)\n",
    "\n",
    "# Export to LaTeX\n",
    "# Center all columns\n",
    "lt_string = pi_top_15.to_latex(index=False, column_format='c' * len(pi_top_15.columns), escape=False)\n",
    "latex_with_font_size = \"\\\\tiny\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "with open('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Permutation_Importance_Top_15.tex', 'w') as f:\n",
    "    f.write(latex_with_font_size)\n",
    "\n",
    "pi_top_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact predictions share == accuracy: True\n",
      "  Model/Baseline  Accuracy Weighted Average Precision Weighted Average Recall  \\\n",
      "0   Change Model      0.96                       0.91                    0.96   \n",
      "\n",
      "   F1 Score  Share 1 Rating Or Less From Actual  \n",
      "0      0.93                                 1.0  \n",
      "0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Weighted Average Precision</th>\n",
       "      <th>Weighted Average Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Majority Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accuracy Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
       "0     0.96                       0.91                    0.96     0.93   \n",
       "\n",
       "  Majority Baseline  \n",
       "0              0.96  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can start with output of get_model_comparison_row\n",
    "starter_row, maj_baseline = get_model_comparison_row('change_model', 'Change Model')\n",
    "print(starter_row)\n",
    "print(maj_baseline)\n",
    "\n",
    "# Drop Model/Baseline, Share Less Than 1 Rating From Actual\n",
    "changes_table = starter_row.drop(columns=['Model/Baseline', 'Share 1 Rating Or Less From Actual'])\n",
    "# Add column for maj_baseline\n",
    "changes_table['Majority Baseline'] = maj_baseline\n",
    "\n",
    "# Output to Excel\n",
    "changes_table.to_excel('../../../../Output/Modelling/Logistic Regression/Tables/changes_table.xlsx', index=False)\n",
    "\n",
    "# Output to Latex\n",
    "#changes_table.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/changes_table.tex', index=False)\n",
    "\n",
    "# Export to LaTeX\n",
    "for col in ['Accuracy', 'F1 Score', 'Majority Baseline']:\n",
    "    changes_table[col] = changes_table[col].apply(lambda x: '{:,.2f}'.format(x))\n",
    "# Center all columns\n",
    "lt_string = changes_table.to_latex(index=False, column_format='c' * len(changes_table.columns), escape=False)\n",
    "latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "with open('../../../../Output/Modelling/Logistic Regression/Tables/changes_table.tex', 'w') as f:\n",
    "    f.write(latex_with_font_size)\n",
    "\n",
    "changes_table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
