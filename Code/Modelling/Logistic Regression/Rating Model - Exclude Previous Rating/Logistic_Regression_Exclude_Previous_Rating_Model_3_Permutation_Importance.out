Starting Job
[NbConvertApp] Converting notebook Logistic_Regression_Exclude_Previous_Rating_Model_3_Permutation_Importance.ipynb to notebook
0.00s - Debugger warning: It seems that frozen modules are being used, which may
0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
0.00s - to python to disable frozen modules.
0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
Traceback (most recent call last):
  File "/scratch/users/ijyliu/conda/envs/scf_general/bin/jupyter-nbconvert", line 10, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/jupyter_core/application.py", line 283, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/traitlets/config/application.py", line 1075, in launch_instance
    app.start()
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/preprocessors/execute.py", line 102, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbconvert/preprocessors/execute.py", line 123, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/asyncio/base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# Perform permutation importance
result = permutation_importance(model, X_test_scaled, y_test, n_repeats=1000, random_state=222, n_jobs=-1)

# Check lengths
print('shape X: ', X_test_scaled.shape)
print('num + cat: ', len(numeric_feature_columns + cat_feature_columns))
print('importances: ', len(result.importances_mean))
print('stds: ', len(result.importances_std))

# Expanded feature column names
# Version for include previous rating
if 'include_previous_rating' in model_name:
    expanded_cat_cols = ['cat__rating_on_previous_fixed_quarter_date_A',
    'cat__rating_on_previous_fixed_quarter_date_AA',
    'cat__rating_on_previous_fixed_quarter_date_AAA',
    'cat__rating_on_previous_fixed_quarter_date_B',
    'cat__rating_on_previous_fixed_quarter_date_BB',
    'cat__rating_on_previous_fixed_quarter_date_BBB',
    'cat__rating_on_previous_fixed_quarter_date_C',
    'cat__rating_on_previous_fixed_quarter_date_CC',
    'cat__rating_on_previous_fixed_quarter_date_CCC',
    'cat__rating_on_previous_fixed_quarter_date_D',
    'cat__Sector_Communication Services',
    'cat__Sector_Consumer Discretionary',
    'cat__Sector_Consumer Staples',
    'cat__Sector_Energy',
    'cat__Sector_Financials', 
    'cat__Sector_Health Care',
    'cat__Sector_Industrials', 
    'cat__Sector_Information Technology',
    'cat__Sector_Materials',
    'cat__Sector_Real Estate',
    'cat__Sector_Utilities']
# Version for exclude previous rating
if 'exclude_previous_rating' in model_name:
    expanded_cat_cols = ['cat__rating_on_previous_fixed_quarter_date_A',
    'cat__rating_on_previous_fixed_quarter_date_AA',
    'cat__rating_on_previous_fixed_quarter_date_AAA',
    'cat__rating_on_previous_fixed_quarter_date_B',
    'cat__rating_on_previous_fixed_quarter_date_BB',
    'cat__rating_on_previous_fixed_quarter_date_BBB',
    'cat__rating_on_previous_fixed_quarter_date_C',
    'cat__rating_on_previous_fixed_quarter_date_CC',
    'cat__rating_on_previous_fixed_quarter_date_CCC',
    'cat__rating_on_previous_fixed_quarter_date_D']

print('with expanded')
print(len(numeric_feature_columns + expanded_cat_cols))

print('importances mean')
print(result.importances_mean)

print('imp std')
print(result.importances_std)

# Put column name, mean and std in a dataframe
result = pd.DataFrame({'feature': numeric_feature_columns + expanded_cat_cols, 'mean': result.importances_mean, 'std': result.importances_std})

# Output to disk
result.to_parquet('../../../../Output/Modelling/Logistic Regression/' + model_name + '/' + model_name + '_permutation_importance.parquet', index=False)

result
------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
Cell [0;32mIn[6], line 2[0m
[1;32m      1[0m [38;5;66;03m# Perform permutation importance[39;00m
[0;32m----> 2[0m result [38;5;241m=[39m [43mpermutation_importance[49m[43m([49m[43mmodel[49m[43m,[49m[43m [49m[43mX_test_scaled[49m[43m,[49m[43m [49m[43my_test[49m[43m,[49m[43m [49m[43mn_repeats[49m[38;5;241;43m=[39;49m[38;5;241;43m1000[39;49m[43m,[49m[43m [49m[43mrandom_state[49m[38;5;241;43m=[39;49m[38;5;241;43m222[39;49m[43m,[49m[43m [49m[43mn_jobs[49m[38;5;241;43m=[39;49m[38;5;241;43m-[39;49m[38;5;241;43m1[39;49m[43m)[49m
[1;32m      4[0m [38;5;66;03m# Check lengths[39;00m
[1;32m      5[0m [38;5;28mprint[39m([38;5;124m'[39m[38;5;124mshape X: [39m[38;5;124m'[39m, X_test_scaled[38;5;241m.[39mshape)

File [0;32m/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213[0m, in [0;36mvalidate_params.<locals>.decorator.<locals>.wrapper[0;34m(*args, **kwargs)[0m
[1;32m    207[0m [38;5;28;01mtry[39;00m:
[1;32m    208[0m     [38;5;28;01mwith[39;00m config_context(
[1;32m    209[0m         skip_parameter_validation[38;5;241m=[39m(
[1;32m    210[0m             prefer_skip_nested_validation [38;5;129;01mor[39;00m global_skip_validation
[1;32m    211[0m         )
[1;32m    212[0m     ):
[0;32m--> 213[0m         [38;5;28;01mreturn[39;00m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m    214[0m [38;5;28;01mexcept[39;00m InvalidParameterError [38;5;28;01mas[39;00m e:
[1;32m    215[0m     [38;5;66;03m# When the function is just a wrapper around an estimator, we allow[39;00m
[1;32m    216[0m     [38;5;66;03m# the function to delegate validation to the estimator, but we replace[39;00m
[1;32m    217[0m     [38;5;66;03m# the name of the estimator by the name of the function in the error[39;00m
[1;32m    218[0m     [38;5;66;03m# message to avoid confusion.[39;00m
[1;32m    219[0m     msg [38;5;241m=[39m re[38;5;241m.[39msub(
[1;32m    220[0m         [38;5;124mr[39m[38;5;124m"[39m[38;5;124mparameter of [39m[38;5;124m\[39m[38;5;124mw+ must be[39m[38;5;124m"[39m,
[1;32m    221[0m         [38;5;124mf[39m[38;5;124m"[39m[38;5;124mparameter of [39m[38;5;132;01m{[39;00mfunc[38;5;241m.[39m[38;5;18m__qualname__[39m[38;5;132;01m}[39;00m[38;5;124m must be[39m[38;5;124m"[39m,
[1;32m    222[0m         [38;5;28mstr[39m(e),
[1;32m    223[0m     )

File [0;32m/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/sklearn/inspection/_permutation_importance.py:267[0m, in [0;36mpermutation_importance[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)[0m
[1;32m    148[0m [38;5;250m[39m[38;5;124;03m"""Permutation importance for feature evaluation [BRE]_.[39;00m
[1;32m    149[0m 
[1;32m    150[0m [38;5;124;03mThe :term:`estimator` is required to be a fitted estimator. `X` can be the[39;00m
[0;32m   (...)[0m
[1;32m    264[0m [38;5;124;03marray([0.2211..., 0.       , 0.       ])[39;00m
[1;32m    265[0m [38;5;124;03m"""[39;00m
[1;32m    266[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m [38;5;28mhasattr[39m(X, [38;5;124m"[39m[38;5;124miloc[39m[38;5;124m"[39m):
[0;32m--> 267[0m     X [38;5;241m=[39m [43mcheck_array[49m[43m([49m[43mX[49m[43m,[49m[43m [49m[43mforce_all_finite[49m[38;5;241;43m=[39;49m[38;5;124;43m"[39;49m[38;5;124;43mallow-nan[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m [49m[43mdtype[49m[38;5;241;43m=[39;49m[38;5;28;43;01mNone[39;49;00m[43m)[49m
[1;32m    269[0m [38;5;66;03m# Precompute random seed from the random state to be used[39;00m
[1;32m    270[0m [38;5;66;03m# to get a fresh independent RandomState instance for each[39;00m
[1;32m    271[0m [38;5;66;03m# parallel call to _calculate_permutation_scores, irrespective of[39;00m
[1;32m    272[0m [38;5;66;03m# the fact that variables are shared or not depending on the active[39;00m
[1;32m    273[0m [38;5;66;03m# joblib backend (sequential, thread-based or process-based).[39;00m
[1;32m    274[0m random_state [38;5;241m=[39m check_random_state(random_state)

File [0;32m/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/sklearn/utils/validation.py:963[0m, in [0;36mcheck_array[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)[0m
[1;32m    961[0m [38;5;28;01mif[39;00m sp[38;5;241m.[39missparse(array):
[1;32m    962[0m     _ensure_no_complex_data(array)
[0;32m--> 963[0m     array [38;5;241m=[39m [43m_ensure_sparse_format[49m[43m([49m
[1;32m    964[0m [43m        [49m[43marray[49m[43m,[49m
[1;32m    965[0m [43m        [49m[43maccept_sparse[49m[38;5;241;43m=[39;49m[43maccept_sparse[49m[43m,[49m
[1;32m    966[0m [43m        [49m[43mdtype[49m[38;5;241;43m=[39;49m[43mdtype[49m[43m,[49m
[1;32m    967[0m [43m        [49m[43mcopy[49m[38;5;241;43m=[39;49m[43mcopy[49m[43m,[49m
[1;32m    968[0m [43m        [49m[43mforce_all_finite[49m[38;5;241;43m=[39;49m[43mforce_all_finite[49m[43m,[49m
[1;32m    969[0m [43m        [49m[43maccept_large_sparse[49m[38;5;241;43m=[39;49m[43maccept_large_sparse[49m[43m,[49m
[1;32m    970[0m [43m        [49m[43mestimator_name[49m[38;5;241;43m=[39;49m[43mestimator_name[49m[43m,[49m
[1;32m    971[0m [43m        [49m[43minput_name[49m[38;5;241;43m=[39;49m[43minput_name[49m[43m,[49m
[1;32m    972[0m [43m    [49m[43m)[49m
[1;32m    973[0m [38;5;28;01melse[39;00m:
[1;32m    974[0m     [38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning[39;00m
[1;32m    975[0m     [38;5;66;03m# to an error. This is needed because specifying a non complex[39;00m
[1;32m    976[0m     [38;5;66;03m# dtype to the function converts complex to real dtype,[39;00m
[1;32m    977[0m     [38;5;66;03m# thereby passing the test made in the lines following the scope[39;00m
[1;32m    978[0m     [38;5;66;03m# of warnings context manager.[39;00m
[1;32m    979[0m     [38;5;28;01mwith[39;00m warnings[38;5;241m.[39mcatch_warnings():

File [0;32m/scratch/users/ijyliu/conda/envs/scf_general/lib/python3.11/site-packages/sklearn/utils/validation.py:595[0m, in [0;36m_ensure_sparse_format[0;34m(sparse_container, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)[0m
[1;32m    593[0m [38;5;28;01mif[39;00m accept_sparse [38;5;129;01mis[39;00m [38;5;28;01mFalse[39;00m:
[1;32m    594[0m     padded_input [38;5;241m=[39m [38;5;124m"[39m[38;5;124m for [39m[38;5;124m"[39m [38;5;241m+[39m input_name [38;5;28;01mif[39;00m input_name [38;5;28;01melse[39;00m [38;5;124m"[39m[38;5;124m"[39m
[0;32m--> 595[0m     [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(
[1;32m    596[0m         [38;5;124mf[39m[38;5;124m"[39m[38;5;124mSparse data was passed[39m[38;5;132;01m{[39;00mpadded_input[38;5;132;01m}[39;00m[38;5;124m, but dense data is required. [39m[38;5;124m"[39m
[1;32m    597[0m         [38;5;124m"[39m[38;5;124mUse [39m[38;5;124m'[39m[38;5;124m.toarray()[39m[38;5;124m'[39m[38;5;124m to convert to a dense numpy array.[39m[38;5;124m"[39m
[1;32m    598[0m     )
[1;32m    599[0m [38;5;28;01melif[39;00m [38;5;28misinstance[39m(accept_sparse, ([38;5;28mlist[39m, [38;5;28mtuple[39m)):
[1;32m    600[0m     [38;5;28;01mif[39;00m [38;5;28mlen[39m(accept_sparse) [38;5;241m==[39m [38;5;241m0[39m:

[0;31mTypeError[0m: Sparse data was passed, but dense data is required. Use '.toarray()' to convert to a dense numpy array.

Completed Job
Time elapsed: 0 minute(s).
