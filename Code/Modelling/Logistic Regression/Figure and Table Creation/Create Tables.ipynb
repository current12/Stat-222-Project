{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Classifier Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name = 'Logistic Regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Rating Models and Most Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['rating_model_1', 'rating_model_2', 'rating_model_3']\n",
    "clean_model_names = [\"Altman's Z\", 'Financial Variables and Sector', 'Financial Variables, Sector, and NLP Features']\n",
    "# set most_complex_model \n",
    "most_complex_model = 'rating_model_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>Clean Column Name</th>\n",
       "      <th>Variable Type</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Ratio?</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Rating Model 1</th>\n",
       "      <th>Rating Model 2</th>\n",
       "      <th>Rating Model 3</th>\n",
       "      <th>Change Model 1</th>\n",
       "      <th>Change Model 2</th>\n",
       "      <th>Change Model 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Altman_Z</td>\n",
       "      <td>Altman's Z Score</td>\n",
       "      <td>Altman's Z Score</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBIT</td>\n",
       "      <td>EBIT</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_plus_preferred_stock</td>\n",
       "      <td>Common Plus Preferred Stock</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>workingCapital</td>\n",
       "      <td>Working Capital</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ratio_A</td>\n",
       "      <td>Ratio A</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>grossProfitRatio_diff</td>\n",
       "      <td>Difference in Gross Profit Ratio from prior fi...</td>\n",
       "      <td>Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>ebitdaratio_diff</td>\n",
       "      <td>Difference in EBITDA Ratio from prior fixed qu...</td>\n",
       "      <td>Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>operatingIncomeRatio_diff</td>\n",
       "      <td>Difference in Operating Income Ratio from prio...</td>\n",
       "      <td>Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>incomeBeforeTaxRatio_diff</td>\n",
       "      <td>Difference in Income Before Tax Ratio from pri...</td>\n",
       "      <td>Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>netIncomeRatio_diff</td>\n",
       "      <td>Difference in Net Income Ratio from prior fixe...</td>\n",
       "      <td>Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column_name  \\\n",
       "0                       Altman_Z   \n",
       "1                           EBIT   \n",
       "2    common_plus_preferred_stock   \n",
       "3                 workingCapital   \n",
       "4                        Ratio_A   \n",
       "..                           ...   \n",
       "167        grossProfitRatio_diff   \n",
       "168             ebitdaratio_diff   \n",
       "169    operatingIncomeRatio_diff   \n",
       "170    incomeBeforeTaxRatio_diff   \n",
       "171          netIncomeRatio_diff   \n",
       "\n",
       "                                     Clean Column Name  \\\n",
       "0                                     Altman's Z Score   \n",
       "1                                                 EBIT   \n",
       "2                          Common Plus Preferred Stock   \n",
       "3                                      Working Capital   \n",
       "4                                              Ratio A   \n",
       "..                                                 ...   \n",
       "167  Difference in Gross Profit Ratio from prior fi...   \n",
       "168  Difference in EBITDA Ratio from prior fixed qu...   \n",
       "169  Difference in Operating Income Ratio from prio...   \n",
       "170  Difference in Income Before Tax Ratio from pri...   \n",
       "171  Difference in Net Income Ratio from prior fixe...   \n",
       "\n",
       "                  Variable Type Data Type Ratio?  \\\n",
       "0              Altman's Z Score   Numeric      Y   \n",
       "1    Constructed for Altman's Z   Numeric    NaN   \n",
       "2    Constructed for Altman's Z   Numeric    NaN   \n",
       "3    Constructed for Altman's Z   Numeric    NaN   \n",
       "4    Constructed for Altman's Z   Numeric      Y   \n",
       "..                          ...       ...    ...   \n",
       "167               Change Ratios   Numeric    NaN   \n",
       "168               Change Ratios   Numeric    NaN   \n",
       "169               Change Ratios   Numeric    NaN   \n",
       "170               Change Ratios   Numeric    NaN   \n",
       "171               Change Ratios   Numeric    NaN   \n",
       "\n",
       "                                                 Notes Rating Model 1  \\\n",
       "0                                                  NaN              X   \n",
       "1                                                  NaN            NaN   \n",
       "2                                                  NaN            NaN   \n",
       "3                                                  NaN            NaN   \n",
       "4                                                  NaN            NaN   \n",
       "..                                                 ...            ...   \n",
       "167  Primarily for changes models, but can be used ...            NaN   \n",
       "168  Primarily for changes models, but can be used ...            NaN   \n",
       "169  Primarily for changes models, but can be used ...            NaN   \n",
       "170  Primarily for changes models, but can be used ...            NaN   \n",
       "171  Primarily for changes models, but can be used ...            NaN   \n",
       "\n",
       "    Rating Model 2 Rating Model 3 Change Model 1 Change Model 2 Change Model 3  \n",
       "0              NaN            NaN              X            NaN            NaN  \n",
       "1                X              X            NaN              X              X  \n",
       "2                X              X            NaN              X              X  \n",
       "3                X              X            NaN              X              X  \n",
       "4                X              X            NaN              X              X  \n",
       "..             ...            ...            ...            ...            ...  \n",
       "167            NaN            NaN            NaN              X              X  \n",
       "168            NaN            NaN            NaN              X              X  \n",
       "169            NaN            NaN            NaN              X              X  \n",
       "170            NaN            NaN            NaN              X              X  \n",
       "171            NaN            NaN            NaN              X              X  \n",
       "\n",
       "[172 rows x 12 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load variable index\n",
    "variable_index = pd.read_excel('../../../../Variable Index.xlsx')\n",
    "variable_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_comparison_row(model_name, clean_model_name):\n",
    "    '''\n",
    "    Given the model name and clean model name, this function returns the model comparison row.\n",
    "    '''\n",
    "\n",
    "    # Load close_exact_dict\n",
    "    close_exact_dict = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_close_exact_dict.pkl')\n",
    "    # Version with each item rounded to 4 decimal places\n",
    "    close_exact_dict_rounded = {k: round(v, 4) for k, v in close_exact_dict.items()}\n",
    "    # Unpack\n",
    "    exact_predictions_share = close_exact_dict_rounded['exact_predictions_share']\n",
    "    close_predictions_share = close_exact_dict_rounded['close_predictions_share']\n",
    "\n",
    "    # Load acc_f1_majority\n",
    "    acc_f1_majority = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_acc_f1_majority.pkl')\n",
    "    # Version with each item rounded to 2 decimal places\n",
    "    acc_f1_majority_rounded = {k: round(v, 4) for k, v in acc_f1_majority.items()}\n",
    "    # Unpack\n",
    "    accuracy = acc_f1_majority_rounded['accuracy']\n",
    "    f1 = acc_f1_majority_rounded['f1_score']\n",
    "    majority_baseline = acc_f1_majority_rounded['majority_baseline']\n",
    "\n",
    "    # Check exact_predictions_share == accuracy\n",
    "    print('exact predictions share == accuracy:', exact_predictions_share == accuracy)\n",
    "\n",
    "    # Get weighted average precision and recall from classification report\n",
    "    classification_report = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_classification_report.pkl')\n",
    "    # Convert classification report string to dataframe\n",
    "    classification_report_lines = classification_report.split('\\n')\n",
    "    # split on spaces within and drop blanks\n",
    "    classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "    # drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "    classification_report_data = [line for line in classification_report_data if line[0] in ['weighted']]\n",
    "    # Unpack\n",
    "    weighted_avg_precision = classification_report_data[0][2]\n",
    "    weighted_avg_recall = classification_report_data[0][3]\n",
    "\n",
    "    # Create dataframe row\n",
    "    model_comparison_row = pd.DataFrame({\n",
    "        'Model/Baseline': [clean_model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Weighted Average Precision': [weighted_avg_precision],\n",
    "        'Weighted Average Recall': [weighted_avg_recall],\n",
    "        'F1 Score': [f1],\n",
    "        'Share 1 Rating Or Less From Actual': [close_predictions_share]\n",
    "    })\n",
    "\n",
    "    # Return row\n",
    "    return model_comparison_row, majority_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Table - Include and Exclude Previous Rating Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.3507   \n",
      "0                 Financial Variables and Sector   0.6484   \n",
      "0  Financial Variables, Sector, and NLP Features   0.6557   \n",
      "0                              Majority Baseline   0.3013   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
      "0                     0.2435                  0.3507   0.2751   \n",
      "0                     0.6464                  0.6484   0.6457   \n",
      "0                     0.6573                  0.6557   0.6537   \n",
      "0                                                               \n",
      "\n",
      "  Share $\\le$ 1 Rating From Actual  \n",
      "0                           0.8022  \n",
      "0                           0.9432  \n",
      "0                           0.9460  \n",
      "0                                   \n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.9496   \n",
      "0                 Financial Variables and Sector   0.9469   \n",
      "0  Financial Variables, Sector, and NLP Features   0.9478   \n",
      "0                              Majority Baseline   0.3013   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
      "0                     0.9495                  0.9496   0.9494   \n",
      "0                     0.9484                  0.9469   0.9475   \n",
      "0                     0.9484                  0.9478   0.9479   \n",
      "0                                                               \n",
      "\n",
      "  Share $\\le$ 1 Rating From Actual  \n",
      "0                           0.9954  \n",
      "0                           0.9927  \n",
      "0                           0.9936  \n",
      "0                                   \n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Create list of df rows\n",
    "    model_comparison_rows = []\n",
    "    majority_baselines = []\n",
    "    for model_name, clean_model_name in zip(model_names, clean_model_names):\n",
    "        model_comparison_row, majority_baseline = get_model_comparison_row(include_exclude_previous + model_name, clean_model_name)\n",
    "        model_comparison_rows.append(model_comparison_row)\n",
    "        majority_baselines.append(majority_baseline)\n",
    "\n",
    "    # Concatenate rows\n",
    "    model_comparison_df = pd.concat(model_comparison_rows)\n",
    "\n",
    "    # Check majority baselines are the same\n",
    "    print('Majority baselines are the same:', all([majority_baseline == majority_baselines[0] for majority_baseline in majority_baselines]))\n",
    "    # Add row with Model/Baseline = 'Majority Baseline' and Accuracy = majority_baseline[0]\n",
    "    model_comparison_df = pd.concat([model_comparison_df, pd.DataFrame({\n",
    "        'Model/Baseline': ['Majority Baseline'],\n",
    "        'Accuracy': [majority_baselines[0]],\n",
    "        'Weighted Average Precision': [''],\n",
    "        'Weighted Average Recall': [''],\n",
    "        'F1 Score': [''],\n",
    "        'Share 1 Rating Or Less From Actual': ['']\n",
    "    })])\n",
    "\n",
    "    # Export to Excel\n",
    "    model_comparison_df.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df.xlsx', index = False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in model_comparison_df.columns:\n",
    "        model_comparison_df[col] = model_comparison_df[col].apply(lambda x: f'{x:.4f}' if isinstance(x, float) else x)\n",
    "    # Rename 'Share 1 Rating Or Less From Actual' to 'Share $le$ Rating From Actual'\n",
    "    model_comparison_df.rename(columns={'Share 1 Rating Or Less From Actual': 'Share $\\\\le$ 1 Rating From Actual'}, inplace=True)\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df.to_latex(index=False, column_format='c' * len(model_comparison_df.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(model_comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Classification Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.6793    0.5841    0.6281       214\n",
      "          AA     0.5882    0.4762    0.5263        42\n",
      "         AAA     0.7917    0.7037    0.7451        27\n",
      "           B     0.5822    0.6159    0.5986       138\n",
      "          BB     0.6399    0.6678    0.6535       298\n",
      "         BBB     0.6759    0.7416    0.7072       329\n",
      "           C     0.7778    1.0000    0.8750         7\n",
      "          CC     0.0000    0.0000    0.0000         0\n",
      "         CCC     0.8095    0.5000    0.6182        34\n",
      "           D     0.0000    0.0000    0.0000         3\n",
      "\n",
      "    accuracy                         0.6557      1092\n",
      "   macro avg     0.5545    0.5289    0.5352      1092\n",
      "weighted avg     0.6573    0.6557    0.6537      1092\n",
      "\n",
      "  Rating Precision  Recall F1-Score Support\n",
      "0      A    0.6793  0.5841   0.6281     214\n",
      "1     AA    0.5882  0.4762   0.5263      42\n",
      "2    AAA    0.7917  0.7037   0.7451      27\n",
      "3      B    0.5822  0.6159   0.5986     138\n",
      "4     BB    0.6399  0.6678   0.6535     298\n",
      "5    BBB    0.6759  0.7416   0.7072     329\n",
      "6      C    0.7778  1.0000   0.8750       7\n",
      "7     CC    0.0000  0.0000   0.0000       0\n",
      "8    CCC    0.8095  0.5000   0.6182      34\n",
      "9      D    0.0000  0.0000   0.0000       3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.9242    0.9112    0.9176       214\n",
      "          AA     0.8947    0.8095    0.8500        42\n",
      "         AAA     0.9231    0.8889    0.9057        27\n",
      "           B     0.9362    0.9565    0.9462       138\n",
      "          BB     0.9701    0.9799    0.9750       298\n",
      "         BBB     0.9548    0.9635    0.9592       329\n",
      "           C     1.0000    1.0000    1.0000         7\n",
      "          CC     0.0000    0.0000    0.0000         0\n",
      "         CCC     0.9688    0.9118    0.9394        34\n",
      "           D     1.0000    1.0000    1.0000         3\n",
      "\n",
      "    accuracy                         0.9478      1092\n",
      "   macro avg     0.8572    0.8421    0.8493      1092\n",
      "weighted avg     0.9484    0.9478    0.9479      1092\n",
      "\n",
      "  Rating Precision  Recall F1-Score Support\n",
      "0      A    0.9242  0.9112   0.9176     214\n",
      "1     AA    0.8947  0.8095   0.8500      42\n",
      "2    AAA    0.9231  0.8889   0.9057      27\n",
      "3      B    0.9362  0.9565   0.9462     138\n",
      "4     BB    0.9701  0.9799   0.9750     298\n",
      "5    BBB    0.9548  0.9635   0.9592     329\n",
      "6      C    1.0000  1.0000   1.0000       7\n",
      "7     CC    0.0000  0.0000   0.0000       0\n",
      "8    CCC    0.9688  0.9118   0.9394      34\n",
      "9      D    1.0000  1.0000   1.0000       3\n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load classificiation report from pickle\n",
    "    classification_report = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_classification_report.pkl')\n",
    "    print(classification_report)\n",
    "\n",
    "    # Convert classification report string to dataframe\n",
    "    classification_report_lines = classification_report.split('\\n')\n",
    "    # split on spaces within and drop blanks\n",
    "    classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "    # drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "    classification_report_data = [line for line in classification_report_data if line[0] not in ['precision', 'accuracy', 'macro', 'weighted']]\n",
    "    # Stack list of rows into dataframe\n",
    "    classification_report_data = pd.DataFrame(classification_report_data)\n",
    "    # Set columns to \"Rating\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"\n",
    "    classification_report_data.columns = ['Rating', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "    print(classification_report_data)\n",
    "\n",
    "    # Export to Excel\n",
    "    classification_report_data.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Classification_Report.xlsx', index=False)\n",
    "\n",
    "    # Export to Latex\n",
    "    #classification_report_data.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Classification_Report.tex', index=False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in classification_report_data.columns:\n",
    "        classification_report_data[col] = classification_report_data[col].apply(lambda x: f'{x:.2f}' if isinstance(x, float) else x)\n",
    "    # Center all columns\n",
    "    lt_string = classification_report_data.to_latex(index=False, column_format='c' * 5, escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Classification_Report.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'class_weight': None, 'l1_ratio': 0.0, 'multi_class': 'multinomial', 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'l1_ratio': 1.0, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "   Previous Ratings    C Class Weighting Strategy  L1 Ratio  \\\n",
      "0  Exclude Previous  1.0                     None       0.0   \n",
      "0  Include Previous  0.1                 Balanced       1.0   \n",
      "\n",
      "  Multi-Class Strategy      Penalty Solver  \n",
      "0          Multinomial  Elastic Net   SAGA  \n",
      "0          One vs Rest  Elastic Net   SAGA  \n"
     ]
    }
   ],
   "source": [
    "# List to store best parameters dfs\n",
    "best_params_dfs = []\n",
    "\n",
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load pickle\n",
    "    best_params = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_best_params.pkl')\n",
    "    print(best_params)\n",
    "\n",
    "    # Convert to dataframe\n",
    "    best_params = pd.DataFrame(best_params, index=[0])\n",
    "    # Set columns to \"C\", \"Class Weighting Strategy\", \"L1 Ratio\", \"Multi-Class Strategy\", \"Penalty\", \"Solver\"\n",
    "    best_params.columns = ['C', 'Class Weighting Strategy', 'L1 Ratio', 'Multi-Class Strategy', 'Penalty', 'Solver']\n",
    "    # Replace 'Multi-Class Strategy' values\n",
    "    best_params['Multi-Class Strategy'] = best_params['Multi-Class Strategy'].replace({'ovr': 'One vs Rest', 'multinomial': 'Multinomial'})\n",
    "    # Replace 'Penalty' values\n",
    "    best_params['Penalty'] = best_params['Penalty'].replace({'l1': 'L1', 'l2': 'L2', 'elasticnet': 'Elastic Net', 'none': 'None'})\n",
    "    # Replace 'Solver' values\n",
    "    best_params['Solver'] = best_params['Solver'].replace({'newton-cg': 'Newton Conjugate Gradient', 'lbfgs': 'Limited Memory Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno', 'liblinear': 'Library for Large Linear Classification', 'sag': 'Stochastic Average Gradient', 'saga': 'SAGA'})\n",
    "    # Replace Class Weighting Strategy values\n",
    "    best_params['Class Weighting Strategy'] = best_params['Class Weighting Strategy'].replace({'balanced': 'Balanced', None: 'None'})\n",
    "    \n",
    "    # Column at the front for whether previous ratings are included or excluded\n",
    "    best_params.insert(0, 'Previous Ratings', include_exclude_previous[:-1].replace('_', ' ').title())\n",
    "\n",
    "    # Append to best_params_dfs\n",
    "    best_params_dfs.append(best_params)\n",
    "\n",
    "# Concatenate best_params_dfs\n",
    "best_params = pd.concat(best_params_dfs)\n",
    "print(best_params)\n",
    "\n",
    "# Export to Excel\n",
    "best_params.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/Most_Complex_Models_Best_Params.xlsx', index=False)\n",
    "\n",
    "# Export to Latex\n",
    "#best_params.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Best_Params.tex', index=False)\n",
    "\n",
    "# Export to LaTeX\n",
    "for col in ['C', 'L1 Ratio']:\n",
    "    best_params[col] = best_params[col].apply(lambda x: '{:,.2f}'.format(x))\n",
    "# Center all columns\n",
    "lt_string = best_params.to_latex(index=False, column_format='c' * len(best_params.columns), escape=False)\n",
    "latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "with open('../../../../Output/Modelling/' + classifier_name + '/Tables/Most_Complex_Models_Best_Params.tex', 'w') as f:\n",
    "    f.write(latex_with_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Permuted Feature  Mean Accuracy Drop  \\\n",
      "0                                            Ratio E            0.070625   \n",
      "1                                       Passive Tone            0.056786   \n",
      "2                                  Sector: Utilities            0.043208   \n",
      "3                                   Interest Expense            0.043019   \n",
      "4                                            Ratio D            0.041765   \n",
      "5                                            Ratio C            0.040578   \n",
      "6   Depreciation and Amortization (Income Statement)            0.038593   \n",
      "7                                    Net Receivables            0.036435   \n",
      "8                                         Word Count            0.035743   \n",
      "9                                     Long-Term Debt            0.035463   \n",
      "10                             Market Capitalization            0.031103   \n",
      "11                    Goodwill and Intangible Assets            0.030084   \n",
      "12                                      Gross Profit            0.027059   \n",
      "13                                        Total Debt            0.026485   \n",
      "14                                          Net Debt            0.025156   \n",
      "\n",
      "    Standard Deviation  \n",
      "0             0.009156  \n",
      "1             0.007741  \n",
      "2             0.005661  \n",
      "3             0.007802  \n",
      "4             0.007607  \n",
      "5             0.008042  \n",
      "6             0.007163  \n",
      "7             0.007130  \n",
      "8             0.007747  \n",
      "9             0.007198  \n",
      "10            0.006867  \n",
      "11            0.007430  \n",
      "12            0.006837  \n",
      "13            0.007413  \n",
      "14            0.007661  \n",
      "                                 Permuted Feature  Mean Accuracy Drop  \\\n",
      "0        Rating on Previous Fixed Quarter Date BB            0.256178   \n",
      "1       Rating on Previous Fixed Quarter Date BBB            0.233306   \n",
      "2         Rating on Previous Fixed Quarter Date A            0.111181   \n",
      "3         Rating on Previous Fixed Quarter Date B            0.064464   \n",
      "4       Rating on Previous Fixed Quarter Date CCC            0.013557   \n",
      "5        Rating on Previous Fixed Quarter Date AA            0.010714   \n",
      "6         Rating on Previous Fixed Quarter Date D            0.001829   \n",
      "7                                         Ratio D            0.000866   \n",
      "8   Weighted Average Shares Outstanding (Diluted)            0.000849   \n",
      "9                                  Other Expenses            0.000840   \n",
      "10                               Net Income Ratio            0.000713   \n",
      "11                           Numeric Transparency            0.000703   \n",
      "12                                         EBITDA            0.000681   \n",
      "13                                        Ratio C            0.000412   \n",
      "14                                        Ratio B            0.000130   \n",
      "\n",
      "    Standard Deviation  \n",
      "0             0.009675  \n",
      "1             0.008979  \n",
      "2             0.006236  \n",
      "3             0.003919  \n",
      "4             0.001143  \n",
      "5             0.001722  \n",
      "6             0.000050  \n",
      "7             0.000799  \n",
      "8             0.000249  \n",
      "9             0.000262  \n",
      "10            0.000779  \n",
      "11            0.000566  \n",
      "12            0.000428  \n",
      "13            0.000538  \n",
      "14            0.000340  \n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load data\n",
    "    permutation_importance = pd.read_parquet('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_permutation_importance.parquet')\n",
    "    permutation_importance = permutation_importance.sort_values('mean',ascending=False)\n",
    "    # Set columns to \"Feature\", \"Mean\", \"Standard Deviation\"\n",
    "    permutation_importance.columns = ['Feature', 'Mean', 'Standard Deviation']\n",
    "     # Strip 'cat__' and 'num__' from Feature\n",
    "    permutation_importance['Feature'] = permutation_importance['Feature'].str.replace('cat__', '').str.replace('num__', '')\n",
    "    # Use variable_index to get feature names\n",
    "    permutation_importance = permutation_importance.merge(variable_index[['column_name', 'Clean Column Name']], left_on='Feature', right_on='column_name', how='left')\n",
    "    # Set Clean_Column_Name to Feature if no match\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].fillna(permutation_importance['Feature'])\n",
    "    # Drop Feature and column_name\n",
    "    permutation_importance = permutation_importance.drop(columns=['Feature', 'column_name'])\n",
    "    # Clean up names for categorical columns\n",
    "    previous_rating_mapping = {'rating_on_previous_fixed_quarter_date_AAA': 'Rating on Previous Fixed Quarter Date AAA',\n",
    "                                'rating_on_previous_fixed_quarter_date_AA': 'Rating on Previous Fixed Quarter Date AA',\n",
    "                                'rating_on_previous_fixed_quarter_date_A': 'Rating on Previous Fixed Quarter Date A',\n",
    "                                'rating_on_previous_fixed_quarter_date_BBB': 'Rating on Previous Fixed Quarter Date BBB',\n",
    "                                'rating_on_previous_fixed_quarter_date_BB': 'Rating on Previous Fixed Quarter Date BB',\n",
    "                                'rating_on_previous_fixed_quarter_date_B': 'Rating on Previous Fixed Quarter Date B',\n",
    "                                'rating_on_previous_fixed_quarter_date_CCC': 'Rating on Previous Fixed Quarter Date CCC',\n",
    "                                'rating_on_previous_fixed_quarter_date_CC': 'Rating on Previous Fixed Quarter Date CC',\n",
    "                                'rating_on_previous_fixed_quarter_date_C': 'Rating on Previous Fixed Quarter Date C',\n",
    "                                'rating_on_previous_fixed_quarter_date_D': 'Rating on Previous Fixed Quarter Date D'}\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].replace(previous_rating_mapping)\n",
    "    # Replace 'Sector_' with 'Sector: '\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].str.replace('Sector_', 'Sector: ')\n",
    "    # Rename Clean Column Name to Feature\n",
    "    permutation_importance = permutation_importance.rename(columns={'Clean Column Name': 'Feature'})\n",
    "    # Reorder columns to put Feature first\n",
    "    permutation_importance = permutation_importance[['Feature', 'Mean', 'Standard Deviation']]\n",
    "    # Rename Mean to 'Mean Accuracy Drop'\n",
    "    permutation_importance = permutation_importance.rename(columns={'Mean': 'Mean Accuracy Drop'})\n",
    "    # Rename Feature to 'Permuted Feature'\n",
    "    permutation_importance = permutation_importance.rename(columns={'Feature': 'Permuted Feature'})\n",
    "    # Get top 15\n",
    "    pi_top_15 = permutation_importance.head(15)\n",
    "\n",
    "    # Export to Excel\n",
    "    pi_top_15.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Permutation_Importance_Top_15.xlsx', index=False)\n",
    "\n",
    "    # Export to Latex\n",
    "    #pi_top_15.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Permutation_Importance_Top_15.tex', index=False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Center all columns\n",
    "    lt_string = pi_top_15.to_latex(index=False, column_format='c' * len(pi_top_15.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\tiny\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Permutation_Importance_Top_15.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(pi_top_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact predictions share == accuracy: True\n",
      "  Model/Baseline  Accuracy Weighted Average Precision Weighted Average Recall  \\\n",
      "0   Change Model    0.9556                       0.91                    0.96   \n",
      "\n",
      "   F1 Score  Share 1 Rating Or Less From Actual  \n",
      "0     0.934                                 1.0  \n",
      "0.9556\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Weighted Average Precision</th>\n",
       "      <th>Weighted Average Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Majority Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accuracy Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
       "0     0.96                       0.91                    0.96     0.93   \n",
       "\n",
       "  Majority Baseline  \n",
       "0              0.96  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can start with output of get_model_comparison_row\n",
    "starter_row, maj_baseline = get_model_comparison_row('change_model', 'Change Model')\n",
    "print(starter_row)\n",
    "print(maj_baseline)\n",
    "\n",
    "# Drop Model/Baseline, Share Less Than 1 Rating From Actual\n",
    "changes_table = starter_row.drop(columns=['Model/Baseline', 'Share 1 Rating Or Less From Actual'])\n",
    "# Add column for maj_baseline\n",
    "changes_table['Majority Baseline'] = maj_baseline\n",
    "\n",
    "# Output to Excel\n",
    "changes_table.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/changes_table.xlsx', index=False)\n",
    "\n",
    "# Output to Latex\n",
    "#changes_table.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/changes_table.tex', index=False)\n",
    "\n",
    "# Export to LaTeX\n",
    "for col in ['Accuracy', 'F1 Score', 'Majority Baseline']:\n",
    "    changes_table[col] = changes_table[col].apply(lambda x: '{:,.2f}'.format(x))\n",
    "# Center all columns\n",
    "lt_string = changes_table.to_latex(index=False, column_format='c' * len(changes_table.columns), escape=False)\n",
    "latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "with open('../../../../Output/Modelling/' + classifier_name + '/Tables/changes_table.tex', 'w') as f:\n",
    "    f.write(latex_with_font_size)\n",
    "\n",
    "changes_table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
