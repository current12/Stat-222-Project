{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import dataframe_image as dfi # NOTE: YOU MUST HAVE GOOGLE CHROME INSTALLED FOR THIS TO WORK CORRECTLY\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Classifier Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name = 'Logistic Regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Rating Models and Most Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['rating_model_1', 'rating_model_2', 'rating_model_3']\n",
    "clean_model_names = [\"Altman's Z\", 'Financial Variables and Sector', 'Financial Variables, Sector, and NLP Features']\n",
    "# set most_complex_model \n",
    "most_complex_model = 'rating_model_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>Clean Column Name</th>\n",
       "      <th>Variable Type</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Ratio?</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Rating Model 1</th>\n",
       "      <th>Rating Model 2</th>\n",
       "      <th>Rating Model 3</th>\n",
       "      <th>Change Model 1</th>\n",
       "      <th>Change Model 2</th>\n",
       "      <th>Change Model 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Altman_Z</td>\n",
       "      <td>Altman's Z Score</td>\n",
       "      <td>Altman's Z Score</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBIT</td>\n",
       "      <td>EBIT</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_plus_preferred_stock</td>\n",
       "      <td>Common Plus Preferred Stock</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>workingCapital</td>\n",
       "      <td>Working Capital</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ratio_A</td>\n",
       "      <td>Ratio A</td>\n",
       "      <td>Constructed for Altman's Z</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>operatingCashFlowPerShare_diff</td>\n",
       "      <td>Difference in Operating Cash Flow Per Share fr...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>freeCashFlowPerShare_diff</td>\n",
       "      <td>Difference in Free Cash Flow Per Share from pr...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>cashPerShare_diff</td>\n",
       "      <td>Difference in Cash Per Share from prior fixed ...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>operatingCashFlowToSales_diff</td>\n",
       "      <td>Difference in Operating Cash Flow to Sales fro...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>freeCashFlowToOperatingCashFlow_diff</td>\n",
       "      <td>Difference in Free Cash Flow to Operating Cash...</td>\n",
       "      <td>Additional Change Ratios</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primarily for changes models, but can be used ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              column_name  \\\n",
       "0                                Altman_Z   \n",
       "1                                    EBIT   \n",
       "2             common_plus_preferred_stock   \n",
       "3                          workingCapital   \n",
       "4                                 Ratio_A   \n",
       "..                                    ...   \n",
       "200        operatingCashFlowPerShare_diff   \n",
       "201             freeCashFlowPerShare_diff   \n",
       "202                     cashPerShare_diff   \n",
       "203         operatingCashFlowToSales_diff   \n",
       "204  freeCashFlowToOperatingCashFlow_diff   \n",
       "\n",
       "                                     Clean Column Name  \\\n",
       "0                                     Altman's Z Score   \n",
       "1                                                 EBIT   \n",
       "2                          Common Plus Preferred Stock   \n",
       "3                                      Working Capital   \n",
       "4                                              Ratio A   \n",
       "..                                                 ...   \n",
       "200  Difference in Operating Cash Flow Per Share fr...   \n",
       "201  Difference in Free Cash Flow Per Share from pr...   \n",
       "202  Difference in Cash Per Share from prior fixed ...   \n",
       "203  Difference in Operating Cash Flow to Sales fro...   \n",
       "204  Difference in Free Cash Flow to Operating Cash...   \n",
       "\n",
       "                  Variable Type Data Type Ratio?  \\\n",
       "0              Altman's Z Score   Numeric      Y   \n",
       "1    Constructed for Altman's Z   Numeric    NaN   \n",
       "2    Constructed for Altman's Z   Numeric    NaN   \n",
       "3    Constructed for Altman's Z   Numeric    NaN   \n",
       "4    Constructed for Altman's Z   Numeric      Y   \n",
       "..                          ...       ...    ...   \n",
       "200    Additional Change Ratios   Numeric    NaN   \n",
       "201    Additional Change Ratios   Numeric    NaN   \n",
       "202    Additional Change Ratios   Numeric    NaN   \n",
       "203    Additional Change Ratios   Numeric    NaN   \n",
       "204    Additional Change Ratios   Numeric    NaN   \n",
       "\n",
       "                                                 Notes Rating Model 1  \\\n",
       "0                                                  NaN              X   \n",
       "1                                                  NaN            NaN   \n",
       "2                                                  NaN            NaN   \n",
       "3                                                  NaN            NaN   \n",
       "4                                                  NaN            NaN   \n",
       "..                                                 ...            ...   \n",
       "200  Primarily for changes models, but can be used ...            NaN   \n",
       "201  Primarily for changes models, but can be used ...            NaN   \n",
       "202  Primarily for changes models, but can be used ...            NaN   \n",
       "203  Primarily for changes models, but can be used ...            NaN   \n",
       "204  Primarily for changes models, but can be used ...            NaN   \n",
       "\n",
       "    Rating Model 2 Rating Model 3 Change Model 1 Change Model 2 Change Model 3  \n",
       "0              NaN            NaN              X            NaN            NaN  \n",
       "1                X              X            NaN              X              X  \n",
       "2                X              X            NaN              X              X  \n",
       "3                X              X            NaN              X              X  \n",
       "4                X              X            NaN              X              X  \n",
       "..             ...            ...            ...            ...            ...  \n",
       "200            NaN            NaN            NaN              X              X  \n",
       "201            NaN            NaN            NaN              X              X  \n",
       "202            NaN            NaN            NaN              X              X  \n",
       "203            NaN            NaN            NaN              X              X  \n",
       "204            NaN            NaN            NaN              X              X  \n",
       "\n",
       "[205 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load variable index\n",
    "variable_index = pd.read_excel('../../../../Variable Index.xlsx')\n",
    "variable_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_comparison_row(model_name, clean_model_name):\n",
    "    '''\n",
    "    Given the model name and clean model name, this function returns the model comparison row.\n",
    "    '''\n",
    "\n",
    "    # Load close_exact_dict\n",
    "    close_exact_dict = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_close_exact_dict.pkl')\n",
    "    # Version with each item rounded to 4 decimal places\n",
    "    close_exact_dict_rounded = {k: round(v, 4) for k, v in close_exact_dict.items()}\n",
    "    # Unpack\n",
    "    exact_predictions_share = close_exact_dict_rounded['exact_predictions_share']\n",
    "    close_predictions_share = close_exact_dict_rounded['close_predictions_share']\n",
    "\n",
    "    # Load acc_f1_majority\n",
    "    acc_f1_majority = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_acc_f1_majority.pkl')\n",
    "    # Version with each item rounded to 2 decimal places\n",
    "    acc_f1_majority_rounded = {k: round(v, 4) for k, v in acc_f1_majority.items()}\n",
    "    # Unpack\n",
    "    accuracy = acc_f1_majority_rounded['accuracy']\n",
    "    f1 = acc_f1_majority_rounded['f1_score']\n",
    "    majority_baseline = acc_f1_majority_rounded['majority_baseline']\n",
    "\n",
    "    # Check exact_predictions_share == accuracy\n",
    "    print('exact predictions share == accuracy:', exact_predictions_share == accuracy)\n",
    "\n",
    "    # Get weighted average precision and recall from classification report\n",
    "    classification_report = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + model_name + '/' + model_name + '_classification_report.pkl')\n",
    "    # Convert classification report string to dataframe\n",
    "    classification_report_lines = classification_report.split('\\n')\n",
    "    # split on spaces within and drop blanks\n",
    "    classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "    # drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "    classification_report_data = [line for line in classification_report_data if line[0] in ['weighted']]\n",
    "    # Unpack\n",
    "    weighted_avg_precision = classification_report_data[0][2]\n",
    "    weighted_avg_recall = classification_report_data[0][3]\n",
    "\n",
    "    # Create dataframe row\n",
    "    model_comparison_row = pd.DataFrame({\n",
    "        'Model/Baseline': [clean_model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Weighted Average Precision': [weighted_avg_precision],\n",
    "        'Weighted Average Recall': [weighted_avg_recall],\n",
    "        'F1 Score': [f1],\n",
    "        'Share 1 Rating Or Less From Actual': [close_predictions_share]\n",
    "    })\n",
    "\n",
    "    # Return row\n",
    "    return model_comparison_row, majority_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Table - Include and Exclude Previous Rating Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.1923   \n",
      "0                 Financial Variables and Sector   0.6225   \n",
      "0  Financial Variables, Sector, and NLP Features   0.6333   \n",
      "0                     Most Common Class Baseline   0.3247   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
      "0                     0.3231                  0.1923   0.2266   \n",
      "0                     0.6295                  0.6225   0.6223   \n",
      "0                     0.6389                  0.6333   0.6329   \n",
      "0                                                               \n",
      "\n",
      "  Share $\\le$ 1 Rating From Actual  \n",
      "0                           0.4633  \n",
      "0                           0.9186  \n",
      "0                           0.9267  \n",
      "0                                   \n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.7442   \n",
      "0                 Financial Variables and Sector   0.9508   \n",
      "0  Financial Variables, Sector, and NLP Features   0.9508   \n",
      "0                     Most Common Class Baseline   0.3247   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \\\n",
      "0                     0.8377                  0.7442   0.7723   \n",
      "0                     0.9518                  0.9508   0.9510   \n",
      "0                     0.9518                  0.9508   0.9510   \n",
      "0                                                               \n",
      "\n",
      "  Share $\\le$ 1 Rating From Actual  \n",
      "0                           0.7746  \n",
      "0                           0.9946  \n",
      "0                           0.9946  \n",
      "0                                   \n",
      "     ticker fixed_quarter_date Change Direction Since Last Fixed Quarter Date  \\\n",
      "0      AAPL         2016-07-01                Same As Last Fixed Quarter Date   \n",
      "1      ABBV         2015-04-01                Same As Last Fixed Quarter Date   \n",
      "2      ABBV         2016-04-01                Same As Last Fixed Quarter Date   \n",
      "3       ABC         2012-04-01                Same As Last Fixed Quarter Date   \n",
      "4       ABC         2013-01-01                Same As Last Fixed Quarter Date   \n",
      "...     ...                ...                                            ...   \n",
      "1113    XOM         2016-01-01                Same As Last Fixed Quarter Date   \n",
      "1114    YUM         2015-04-01                Same As Last Fixed Quarter Date   \n",
      "1115   ZBRA         2016-10-01                Same As Last Fixed Quarter Date   \n",
      "1116    ZTS         2013-10-01                Same As Last Fixed Quarter Date   \n",
      "1117    ZTS         2014-04-01                Same As Last Fixed Quarter Date   \n",
      "\n",
      "     rating_change_model_1_predictions  \n",
      "0      Same As Last Fixed Quarter Date  \n",
      "1      Same As Last Fixed Quarter Date  \n",
      "2      Same As Last Fixed Quarter Date  \n",
      "3      Same As Last Fixed Quarter Date  \n",
      "4      Same As Last Fixed Quarter Date  \n",
      "...                                ...  \n",
      "1113   Same As Last Fixed Quarter Date  \n",
      "1114   Same As Last Fixed Quarter Date  \n",
      "1115   Same As Last Fixed Quarter Date  \n",
      "1116   Same As Last Fixed Quarter Date  \n",
      "1117   Same As Last Fixed Quarter Date  \n",
      "\n",
      "[1118 rows x 4 columns]\n",
      "same share\n",
      "0.9535\n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Create list of df rows\n",
    "    model_comparison_rows = []\n",
    "    majority_baselines = []\n",
    "    for model_name, clean_model_name in zip(model_names, clean_model_names):\n",
    "        model_comparison_row, majority_baseline = get_model_comparison_row(include_exclude_previous + model_name, clean_model_name)\n",
    "        model_comparison_rows.append(model_comparison_row)\n",
    "        majority_baselines.append(majority_baseline)\n",
    "\n",
    "    # Concatenate rows\n",
    "    model_comparison_df = pd.concat(model_comparison_rows)\n",
    "\n",
    "    # Check majority baselines are the same\n",
    "    print('Majority baselines are the same:', all([majority_baseline == majority_baselines[0] for majority_baseline in majority_baselines]))\n",
    "    # Add row with Model/Baseline = 'Most Common Class Baseline' and Accuracy = majority_baseline[0]\n",
    "    model_comparison_df = pd.concat([model_comparison_df, pd.DataFrame({\n",
    "        'Model/Baseline': ['Most Common Class Baseline'],\n",
    "        'Accuracy': [majority_baselines[0]],\n",
    "        'Weighted Average Precision': [''],\n",
    "        'Weighted Average Recall': [''],\n",
    "        'F1 Score': [''],\n",
    "        'Share 1 Rating Or Less From Actual': ['']\n",
    "    })])\n",
    "\n",
    "    # Export to Excel\n",
    "    model_comparison_df.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df.xlsx', index = False)\n",
    "\n",
    "    if include_exclude_previous == 'exclude_previous_':\n",
    "        exclude_previous_model_comparison_df = model_comparison_df\n",
    "    else:\n",
    "        include_previous_model_comparison_df = model_comparison_df\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in model_comparison_df.columns:\n",
    "        model_comparison_df[col] = model_comparison_df[col].apply(lambda x: f'{x:.4f}' if isinstance(x, float) else x)\n",
    "    # Rename 'Share 1 Rating Or Less From Actual' to 'Share $le$ Rating From Actual'\n",
    "    model_comparison_df.rename(columns={'Share 1 Rating Or Less From Actual': 'Share $\\\\le$ 1 Rating From Actual'}, inplace=True)\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df.to_latex(index=False, column_format='c' * len(model_comparison_df.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    # Middle version latex - keep only columns 'Model/Baseline', 'Accuracy', 'Share $\\\\le$ 1 Rating From Actual'\n",
    "    model_comparison_df_middle = model_comparison_df[['Model/Baseline', 'Accuracy', 'Share $\\\\le$ 1 Rating From Actual']]\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df_middle.to_latex(index=False, column_format='c' * len(model_comparison_df_middle.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df_middle.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    # Smaller version latex - keep only columns 'Model/Baseline', 'Accuracy'\n",
    "    model_comparison_df_smaller = model_comparison_df[['Model/Baseline', 'Accuracy']]\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df_smaller.to_latex(index=False, column_format='c' * len(model_comparison_df_smaller.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df_smaller.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(model_comparison_df)\n",
    "\n",
    "    # If include_previous, add a row that is the share of items with \"Same\" in test data\n",
    "    if include_exclude_previous == 'include_previous_':\n",
    "        test_data_example = pd.read_excel('../../../../Data/Predictions/Logistic Regression/rating_change_model_1/rating_change_model_1_predictions.xlsx')\n",
    "        print(test_data_example)\n",
    "        same_share = test_data_example[test_data_example['Change Direction Since Last Fixed Quarter Date'] == 'Same As Last Fixed Quarter Date'].shape[0] / test_data_example.shape[0]\n",
    "        # round to 4 decimal places\n",
    "        same_share = round(same_share, 4)\n",
    "        print('same share')\n",
    "        print(same_share)\n",
    "        # Create dataframe row\n",
    "        same_share_row = pd.DataFrame({\n",
    "            'Model/Baseline': ['Previous Rating'],\n",
    "            'Accuracy': [same_share],\n",
    "            'Weighted Average Precision': [''],\n",
    "            'Weighted Average Recall': [''],\n",
    "            'F1 Score': [''],\n",
    "        })\n",
    "        # Concatenate rows\n",
    "        model_comparison_df_ss = pd.concat([model_comparison_df, same_share_row])\n",
    "        # Export to Excel\n",
    "        model_comparison_df_ss.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'model_comparison_df_ss.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Styled DFI Versions for Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "#print(exclude_previous_model_comparison_df)\n",
    "exclude_previous_model_comparison_sty = (exclude_previous_model_comparison_df.reset_index(drop=True)[['Model/Baseline', 'Accuracy']]\n",
    "                            .style\n",
    "                            .format(precision=2, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(exclude_previous_model_comparison_sty, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'exclude_previous_' + 'model_comparison_df.png')\n",
    "#exclude_previous_model_comparison_sty\n",
    "\n",
    "include_previous_model_comparison_sty = (include_previous_model_comparison_df.reset_index(drop=True)[['Model/Baseline', 'Accuracy']]\n",
    "                            .style\n",
    "                            .format(precision=2, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(include_previous_model_comparison_sty, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'include_previous_' + 'model_comparison_df.png')\n",
    "#include_previous_model_comparison_sty\n",
    "\n",
    "model_comparison_df_ss = (model_comparison_df_ss.reset_index(drop=True)[['Model/Baseline', 'Accuracy']]\n",
    "                            .style\n",
    "                            .format(precision=4, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(model_comparison_df_ss, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'include_previous_' + 'model_comparison_df_ss.png')\n",
    "#model_comparison_df_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Classification Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.5874    0.6298    0.6079       208\n",
      "          AA     0.6316    0.6923    0.6606        52\n",
      "         AAA     0.8261    0.7917    0.8085        24\n",
      "           B     0.5864    0.7273    0.6493       154\n",
      "          BB     0.6275    0.5458    0.5838       284\n",
      "         BBB     0.6909    0.6281    0.6580       363\n",
      "           C     1.0000    1.0000    1.0000         4\n",
      "          CC     0.3333    1.0000    0.5000         2\n",
      "         CCC     0.5556    0.7692    0.6452        26\n",
      "           D     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.6333      1118\n",
      "   macro avg     0.6839    0.7784    0.7113      1118\n",
      "weighted avg     0.6389    0.6333    0.6329      1118\n",
      "\n",
      "  Rating Precision  Recall F1-Score Support\n",
      "2    AAA    0.8261  0.7917   0.8085      24\n",
      "1     AA    0.6316  0.6923   0.6606      52\n",
      "0      A    0.5874  0.6298   0.6079     208\n",
      "5    BBB    0.6909  0.6281   0.6580     363\n",
      "4     BB    0.6275  0.5458   0.5838     284\n",
      "3      B    0.5864  0.7273   0.6493     154\n",
      "8    CCC    0.5556  0.7692   0.6452      26\n",
      "7     CC    0.3333  1.0000   0.5000       2\n",
      "6      C    1.0000  1.0000   1.0000       4\n",
      "9      D    1.0000  1.0000   1.0000       1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.9604    0.9327    0.9463       208\n",
      "          AA     0.9412    0.9231    0.9320        52\n",
      "         AAA     0.8519    0.9583    0.9020        24\n",
      "           B     0.9359    0.9481    0.9419       154\n",
      "          BB     0.9573    0.9472    0.9522       284\n",
      "         BBB     0.9669    0.9669    0.9669       363\n",
      "           C     1.0000    1.0000    1.0000         4\n",
      "          CC     1.0000    1.0000    1.0000         2\n",
      "         CCC     0.8065    0.9615    0.8772        26\n",
      "           D     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         0.9508      1118\n",
      "   macro avg     0.9420    0.9638    0.9519      1118\n",
      "weighted avg     0.9518    0.9508    0.9510      1118\n",
      "\n",
      "  Rating Precision  Recall F1-Score Support\n",
      "2    AAA    0.8519  0.9583   0.9020      24\n",
      "1     AA    0.9412  0.9231   0.9320      52\n",
      "0      A    0.9604  0.9327   0.9463     208\n",
      "5    BBB    0.9669  0.9669   0.9669     363\n",
      "4     BB    0.9573  0.9472   0.9522     284\n",
      "3      B    0.9359  0.9481   0.9419     154\n",
      "8    CCC    0.8065  0.9615   0.8772      26\n",
      "7     CC    1.0000  1.0000   1.0000       2\n",
      "6      C    1.0000  1.0000   1.0000       4\n",
      "9      D    1.0000  1.0000   1.0000       1\n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load classificiation report from pickle\n",
    "    classification_report = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_classification_report.pkl')\n",
    "    print(classification_report)\n",
    "\n",
    "    # Convert classification report string to dataframe\n",
    "    classification_report_lines = classification_report.split('\\n')\n",
    "    # split on spaces within and drop blanks\n",
    "    classification_report_data = [line.split() for line in classification_report_lines if line]\n",
    "    # drop lists begining with 'precision', 'accuracy', 'macro', 'weighted'\n",
    "    classification_report_data = [line for line in classification_report_data if line[0] not in ['precision', 'accuracy', 'macro', 'weighted']]\n",
    "    # Stack list of rows into dataframe\n",
    "    classification_report_data = pd.DataFrame(classification_report_data)\n",
    "    # Set columns to \"Rating\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"\n",
    "    classification_report_data.columns = ['Rating', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "    # Sort by Rating in correct order: AAA, AA, A, BBB, BB, B, CCC, CC, C, D\n",
    "    rating_map = {'AAA': 0, 'AA': 1, 'A': 2, 'BBB': 3, 'BB': 4, 'B': 5, 'CCC': 6, 'CC': 7, 'C': 8, 'D': 9}\n",
    "    classification_report_data['Rating Num'] = classification_report_data['Rating'].map(rating_map)\n",
    "    classification_report_data = classification_report_data.sort_values(by='Rating Num').drop(columns='Rating Num')\n",
    "    print(classification_report_data)\n",
    "\n",
    "    # Export to Excel\n",
    "    classification_report_data.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Classification_Report.xlsx', index=False)\n",
    "\n",
    "    # Export to Latex\n",
    "    #classification_report_data.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Classification_Report.tex', index=False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in classification_report_data.columns:\n",
    "        classification_report_data[col] = classification_report_data[col].apply(lambda x: f'{x:.2f}' if isinstance(x, float) else x)\n",
    "    # Center all columns\n",
    "    lt_string = classification_report_data.to_latex(index=False, column_format='c' * 5, escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Classification_Report.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'class_weight': 'balanced', 'l1_ratio': 1.0, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'l1_ratio': 1.0, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "   Previous Ratings    C Class Weighting Strategy  L1 Ratio  \\\n",
      "0  Exclude Previous  0.1                 Balanced       1.0   \n",
      "0  Include Previous  0.1                 Balanced       1.0   \n",
      "\n",
      "  Multi-Class Strategy      Penalty Solver  \n",
      "0          One vs Rest  Elastic Net   SAGA  \n",
      "0          One vs Rest  Elastic Net   SAGA  \n"
     ]
    }
   ],
   "source": [
    "# List to store best parameters dfs\n",
    "best_params_dfs = []\n",
    "\n",
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load pickle\n",
    "    best_params = pd.read_pickle('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_best_params.pkl')\n",
    "    print(best_params)\n",
    "\n",
    "    # Convert to dataframe\n",
    "    best_params = pd.DataFrame(best_params, index=[0])\n",
    "    # Set columns to \"C\", \"Class Weighting Strategy\", \"L1 Ratio\", \"Multi-Class Strategy\", \"Penalty\", \"Solver\"\n",
    "    best_params.columns = ['C', 'Class Weighting Strategy', 'L1 Ratio', 'Multi-Class Strategy', 'Penalty', 'Solver']\n",
    "    # Replace 'Multi-Class Strategy' values\n",
    "    best_params['Multi-Class Strategy'] = best_params['Multi-Class Strategy'].replace({'ovr': 'One vs Rest', 'multinomial': 'Multinomial'})\n",
    "    # Replace 'Penalty' values\n",
    "    best_params['Penalty'] = best_params['Penalty'].replace({'l1': 'L1', 'l2': 'L2', 'elasticnet': 'Elastic Net', 'none': 'None'})\n",
    "    # Replace 'Solver' values\n",
    "    best_params['Solver'] = best_params['Solver'].replace({'newton-cg': 'Newton Conjugate Gradient', 'lbfgs': 'Limited Memory Broyden–Fletcher–Goldfarb–Shanno', 'liblinear': 'Library for Large Linear Classification', 'sag': 'Stochastic Average Gradient', 'saga': 'SAGA'})\n",
    "    # Replace Class Weighting Strategy values\n",
    "    best_params['Class Weighting Strategy'] = best_params['Class Weighting Strategy'].replace({'balanced': 'Balanced', None: 'None'})\n",
    "    \n",
    "    # Column at the front for whether previous ratings are included or excluded\n",
    "    best_params.insert(0, 'Previous Ratings', include_exclude_previous[:-1].replace('_', ' ').title())\n",
    "\n",
    "    # Export smaller version to Excel\n",
    "    # drop first col\n",
    "    bp_small = best_params.drop(columns='Previous Ratings')\n",
    "    bp_small.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Best_Params.xlsx', index=False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    for col in ['C', 'L1 Ratio']:\n",
    "        bp_small[col] = bp_small[col].apply(lambda x: '{:,.2f}'.format(x))\n",
    "    # Center all columns\n",
    "    lt_string = bp_small.to_latex(index=False, column_format='c' * len(bp_small.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Models_Best_Params.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size) \n",
    "\n",
    "    # Append to best_params_dfs\n",
    "    best_params_dfs.append(best_params)\n",
    "\n",
    "# Concatenate best_params_dfs\n",
    "best_params = pd.concat(best_params_dfs)\n",
    "print(best_params)\n",
    "\n",
    "# Export to Excel\n",
    "best_params.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/Most_Complex_Models_Best_Params.xlsx', index=False)\n",
    "\n",
    "# Export to Latex\n",
    "#best_params.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Best_Params.tex', index=False)\n",
    "\n",
    "# Export to LaTeX\n",
    "for col in ['C', 'L1 Ratio']:\n",
    "   best_params[col] = best_params[col].apply(lambda x: '{:,.2f}'.format(x))\n",
    "# Center all columns\n",
    "lt_string = best_params.to_latex(index=False, column_format='c' * len(best_params.columns), escape=False)\n",
    "latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "with open('../../../../Output/Modelling/' + classifier_name + '/Tables/Most_Complex_Models_Best_Params.tex', 'w') as f:\n",
    "    f.write(latex_with_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Complex Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Permuted Feature  Mean Accuracy Drop  \\\n",
      "0                                            Ratio E            0.070625   \n",
      "1                                       Passive Tone            0.056786   \n",
      "2                                  Sector: Utilities            0.043208   \n",
      "3                                   Interest Expense            0.043019   \n",
      "4                                            Ratio D            0.041765   \n",
      "5                                            Ratio C            0.040578   \n",
      "6   Depreciation and Amortization (Income Statement)            0.038593   \n",
      "7                                    Net Receivables            0.036435   \n",
      "8                                         Word Count            0.035743   \n",
      "9                                     Long-Term Debt            0.035463   \n",
      "10                             Market Capitalization            0.031103   \n",
      "11                    Goodwill and Intangible Assets            0.030084   \n",
      "12                                      Gross Profit            0.027059   \n",
      "13                                        Total Debt            0.026485   \n",
      "14                                          Net Debt            0.025156   \n",
      "\n",
      "    Standard Deviation  \n",
      "0             0.009156  \n",
      "1             0.007741  \n",
      "2             0.005661  \n",
      "3             0.007802  \n",
      "4             0.007607  \n",
      "5             0.008042  \n",
      "6             0.007163  \n",
      "7             0.007130  \n",
      "8             0.007747  \n",
      "9             0.007198  \n",
      "10            0.006867  \n",
      "11            0.007430  \n",
      "12            0.006837  \n",
      "13            0.007413  \n",
      "14            0.007661  \n",
      "                                 Permuted Feature  Mean Accuracy Drop  \\\n",
      "0        Rating on Previous Fixed Quarter Date BB            0.256178   \n",
      "1       Rating on Previous Fixed Quarter Date BBB            0.233306   \n",
      "2         Rating on Previous Fixed Quarter Date A            0.111181   \n",
      "3         Rating on Previous Fixed Quarter Date B            0.064464   \n",
      "4       Rating on Previous Fixed Quarter Date CCC            0.013557   \n",
      "5        Rating on Previous Fixed Quarter Date AA            0.010714   \n",
      "6         Rating on Previous Fixed Quarter Date D            0.001829   \n",
      "7                                         Ratio D            0.000866   \n",
      "8   Weighted Average Shares Outstanding (Diluted)            0.000849   \n",
      "9                                  Other Expenses            0.000840   \n",
      "10                               Net Income Ratio            0.000713   \n",
      "11                           Numeric Transparency            0.000703   \n",
      "12                                         EBITDA            0.000681   \n",
      "13                                        Ratio C            0.000412   \n",
      "14                                        Ratio B            0.000130   \n",
      "\n",
      "    Standard Deviation  \n",
      "0             0.009675  \n",
      "1             0.008979  \n",
      "2             0.006236  \n",
      "3             0.003919  \n",
      "4             0.001143  \n",
      "5             0.001722  \n",
      "6             0.000050  \n",
      "7             0.000799  \n",
      "8             0.000249  \n",
      "9             0.000262  \n",
      "10            0.000779  \n",
      "11            0.000566  \n",
      "12            0.000428  \n",
      "13            0.000538  \n",
      "14            0.000340  \n"
     ]
    }
   ],
   "source": [
    "# Iterate over include_exclude_previous\n",
    "for include_exclude_previous in ['exclude_previous_', 'include_previous_']:\n",
    "\n",
    "    # Load data\n",
    "    permutation_importance = pd.read_parquet('../../../../Output/Modelling/' + classifier_name + '/' + include_exclude_previous + most_complex_model + '/' + include_exclude_previous + most_complex_model + '_permutation_importance.parquet')\n",
    "    permutation_importance = permutation_importance.sort_values('mean',ascending=False)\n",
    "    # Set columns to \"Feature\", \"Mean\", \"Standard Deviation\"\n",
    "    permutation_importance.columns = ['Feature', 'Mean', 'Standard Deviation']\n",
    "     # Strip 'cat__' and 'num__' from Feature\n",
    "    permutation_importance['Feature'] = permutation_importance['Feature'].str.replace('cat__', '').str.replace('num__', '')\n",
    "    # Use variable_index to get feature names\n",
    "    permutation_importance = permutation_importance.merge(variable_index[['column_name', 'Clean Column Name']], left_on='Feature', right_on='column_name', how='left')\n",
    "    # Set Clean_Column_Name to Feature if no match\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].fillna(permutation_importance['Feature'])\n",
    "    # Drop Feature and column_name\n",
    "    permutation_importance = permutation_importance.drop(columns=['Feature', 'column_name'])\n",
    "    # Clean up names for categorical columns\n",
    "    previous_rating_mapping = {'rating_on_previous_fixed_quarter_date_AAA': 'Rating on Previous Fixed Quarter Date AAA',\n",
    "                                'rating_on_previous_fixed_quarter_date_AA': 'Rating on Previous Fixed Quarter Date AA',\n",
    "                                'rating_on_previous_fixed_quarter_date_A': 'Rating on Previous Fixed Quarter Date A',\n",
    "                                'rating_on_previous_fixed_quarter_date_BBB': 'Rating on Previous Fixed Quarter Date BBB',\n",
    "                                'rating_on_previous_fixed_quarter_date_BB': 'Rating on Previous Fixed Quarter Date BB',\n",
    "                                'rating_on_previous_fixed_quarter_date_B': 'Rating on Previous Fixed Quarter Date B',\n",
    "                                'rating_on_previous_fixed_quarter_date_CCC': 'Rating on Previous Fixed Quarter Date CCC',\n",
    "                                'rating_on_previous_fixed_quarter_date_CC': 'Rating on Previous Fixed Quarter Date CC',\n",
    "                                'rating_on_previous_fixed_quarter_date_C': 'Rating on Previous Fixed Quarter Date C',\n",
    "                                'rating_on_previous_fixed_quarter_date_D': 'Rating on Previous Fixed Quarter Date D'}\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].replace(previous_rating_mapping)\n",
    "    # Replace 'Sector_' with 'Sector: '\n",
    "    permutation_importance['Clean Column Name'] = permutation_importance['Clean Column Name'].str.replace('Sector_', 'Sector: ')\n",
    "    # Rename Clean Column Name to Feature\n",
    "    permutation_importance = permutation_importance.rename(columns={'Clean Column Name': 'Feature'})\n",
    "    # Reorder columns to put Feature first\n",
    "    permutation_importance = permutation_importance[['Feature', 'Mean', 'Standard Deviation']]\n",
    "    # Rename Mean to 'Mean Accuracy Drop'\n",
    "    permutation_importance = permutation_importance.rename(columns={'Mean': 'Mean Accuracy Drop'})\n",
    "    # Rename Feature to 'Permuted Feature'\n",
    "    permutation_importance = permutation_importance.rename(columns={'Feature': 'Permuted Feature'})\n",
    "    # Get top 15\n",
    "    pi_top_15 = permutation_importance.head(15)\n",
    "\n",
    "    if include_exclude_previous == 'exclude_previous_':\n",
    "        exclude_previous_pi_top_15 = pi_top_15\n",
    "    else:\n",
    "        include_previous_pi_top_15 = pi_top_15\n",
    "\n",
    "    # Export to Excel\n",
    "    pi_top_15.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Permutation_Importance_Top_15.xlsx', index=False)\n",
    "\n",
    "    # Export to Latex\n",
    "    #pi_top_15.to_latex('../../../../Output/Modelling/Logistic Regression/Tables/Most_Complex_Model_Permutation_Importance_Top_15.tex', index=False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Center all columns\n",
    "    lt_string = pi_top_15.to_latex(index=False, column_format='c' * len(pi_top_15.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\tiny\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/' + include_exclude_previous + 'Most_Complex_Model_Permutation_Importance_Top_15.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(pi_top_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_previous_pi_top_15 = (include_previous_pi_top_15.reset_index(drop=True)\n",
    "                            .style\n",
    "                            .format(precision=6, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(include_previous_pi_top_15, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'include_previous_' + 'Most_Complex_Model_Permutation_Importance_Top_15.png')\n",
    "#include_previous_pi_top_15\n",
    "\n",
    "exclude_previous_pi_top_15 = (exclude_previous_pi_top_15.reset_index(drop=True)\n",
    "                            .style\n",
    "                            .format(precision=6, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(exclude_previous_pi_top_15, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'exclude_previous_' + 'Most_Complex_Model_Permutation_Importance_Top_15.png')\n",
    "#exclude_previous_pi_top_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Model Comparison Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.9535   \n",
      "0                 Financial Variables and Sector   0.0286   \n",
      "0  Financial Variables, Sector, and NLP Features   0.5984   \n",
      "0                     Most Common Class Baseline   0.9535   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \n",
      "0                     0.9091                  0.9535   0.9308  \n",
      "0                     0.0008                  0.0286   0.0016  \n",
      "0                     0.9063                  0.5984   0.7189  \n",
      "0                                                              \n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "exact predictions share == accuracy: True\n",
      "Majority baselines are the same: True\n",
      "                                  Model/Baseline Accuracy  \\\n",
      "0                                     Altman's Z   0.5742   \n",
      "0                 Financial Variables and Sector   0.7004   \n",
      "0  Financial Variables, Sector, and NLP Features   0.7165   \n",
      "0                     Most Common Class Baseline   0.9535   \n",
      "\n",
      "  Weighted Average Precision Weighted Average Recall F1 Score  \n",
      "0                     0.9115                  0.5742   0.6961  \n",
      "0                     0.9075                  0.7004   0.7895  \n",
      "0                     0.9154                  0.7165   0.8017  \n",
      "0                                                              \n"
     ]
    }
   ],
   "source": [
    "# Iterate over just models '_' versus _smote_\n",
    "for spec in ['', \n",
    "             'smote_']:\n",
    "\n",
    "    # Create list of df rows\n",
    "    model_comparison_rows = []\n",
    "    majority_baselines = []\n",
    "    for mn, clean_model_name in zip(['rating_change_model_1', 'rating_change_model_2', 'rating_change_model_3'], [\"Altman's Z\", 'Financial Variables and Sector', 'Financial Variables, Sector, and NLP Features']):\n",
    "        model_comparison_row, majority_baseline = get_model_comparison_row(spec + mn, clean_model_name)\n",
    "        model_comparison_rows.append(model_comparison_row)\n",
    "        majority_baselines.append(majority_baseline)\n",
    "\n",
    "    # Concatenate rows\n",
    "    model_comparison_df = pd.concat(model_comparison_rows)\n",
    "\n",
    "    # Check majority baselines are the same\n",
    "    print('Majority baselines are the same:', all([majority_baseline == majority_baselines[0] for majority_baseline in majority_baselines]))\n",
    "    # Add row with Model/Baseline = 'Most Common Class Baseline' and Accuracy = majority_baseline[0]\n",
    "    model_comparison_df = pd.concat([model_comparison_df, pd.DataFrame({\n",
    "        'Model/Baseline': ['Most Common Class Baseline'],\n",
    "        'Accuracy': [majority_baselines[0]],\n",
    "        'Weighted Average Precision': [''],\n",
    "        'Weighted Average Recall': [''],\n",
    "        'F1 Score': [''],\n",
    "        'Share 1 Rating Or Less From Actual': ['']\n",
    "    })])\n",
    "    # Drop 'Share 1 Rating Or Less From Actual' column\n",
    "    model_comparison_df = model_comparison_df.drop(columns=['Share 1 Rating Or Less From Actual'])\n",
    "\n",
    "    if spec == '':\n",
    "        change_model_comparison_df = model_comparison_df\n",
    "    else:\n",
    "        change_smote_model_comparison_df = model_comparison_df\n",
    "\n",
    "    # Export to Excel\n",
    "    model_comparison_df.to_excel('../../../../Output/Modelling/' + classifier_name + '/Tables/change_' + spec + 'model_comparison_df.xlsx', index = False)\n",
    "\n",
    "    # Export to LaTeX\n",
    "    # Format columns\n",
    "    for col in model_comparison_df.columns:\n",
    "        model_comparison_df[col] = model_comparison_df[col].apply(lambda x: f'{x:.4f}' if isinstance(x, float) else x)\n",
    "    # Rename 'Share 1 Rating Or Less From Actual' to 'Share $le$ Rating From Actual'\n",
    "    #model_comparison_df.rename(columns={'Share 1 Rating Or Less From Actual': 'Share $\\\\le$ 1 Rating From Actual'}, inplace=True)\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df.to_latex(index=False, column_format='c' * len(model_comparison_df.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/change_' + spec + 'model_comparison_df.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    # Smaller version latex - keep only columns 'Model/Baseline', 'Accuracy'\n",
    "    model_comparison_df_smaller = model_comparison_df[['Model/Baseline', 'Accuracy']]\n",
    "    # Center all columns\n",
    "    lt_string = model_comparison_df_smaller.to_latex(index=False, column_format='c' * len(model_comparison_df_smaller.columns), escape=False)\n",
    "    latex_with_font_size = \"\\\\footnotesize\\n\" + lt_string + \"\\n\\\\normalsize\"\n",
    "    with open('../../../../Output/Modelling/' + classifier_name + '/Tables/change_' + spec + 'model_comparison_df_smaller.tex', 'w') as f:\n",
    "        f.write(latex_with_font_size)\n",
    "\n",
    "    print(model_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "#print(exclude_previous_model_comparison_df)\n",
    "change_model_comparison_df = (change_model_comparison_df.reset_index(drop=True)[['Model/Baseline', 'Accuracy']]\n",
    "                            .style\n",
    "                            .format(precision=2, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(change_model_comparison_df, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'change_model_comparison_df.png')\n",
    "#change_model_comparison_df\n",
    "\n",
    "change_smote_model_comparison_df = (change_smote_model_comparison_df.reset_index(drop=True)[['Model/Baseline', 'Accuracy']]\n",
    "                            .style\n",
    "                            .format(precision=2, thousands=\",\", decimal=\".\")\n",
    "                            .set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "                            .hide()\n",
    "                            .set_properties(**{'text-align': 'center'}))\n",
    "\n",
    "dfi.export(change_smote_model_comparison_df, '../../../../Output/Modelling/' + classifier_name + '/Tables/' + 'change_smote_model_comparison_df.png')\n",
    "#change_smote_model_comparison_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
