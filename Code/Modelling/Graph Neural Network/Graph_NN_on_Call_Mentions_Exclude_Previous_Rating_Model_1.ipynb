{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Graph NN on Call Mentions\n",
    "\n",
    "Considering direct mentions of companies in calls, construct a network of calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from Inductive_Graph_NN_Functions import *\n",
    "model_name = 'exclude_previous_rating_model_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Feature and Class Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>fixed_quarter_date</th>\n",
       "      <th>earnings_call_date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>rating_date</th>\n",
       "      <th>Next Rating</th>\n",
       "      <th>Next Rating Date</th>\n",
       "      <th>Previous Rating</th>\n",
       "      <th>Previous Rating Date</th>\n",
       "      <th>next_rating_date_or_end_of_data</th>\n",
       "      <th>...</th>\n",
       "      <th>Undrst</th>\n",
       "      <th>PN</th>\n",
       "      <th>SW</th>\n",
       "      <th>AP</th>\n",
       "      <th>OU</th>\n",
       "      <th>TONE1</th>\n",
       "      <th>num_q_by_len</th>\n",
       "      <th>pos_score_finbert</th>\n",
       "      <th>train_test_80_20</th>\n",
       "      <th>node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>2014-07-22</td>\n",
       "      <td>AA</td>\n",
       "      <td>2014-05-27</td>\n",
       "      <td>AA</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2014-04-24</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.518519</td>\n",
       "      <td>15.261905</td>\n",
       "      <td>2.661290</td>\n",
       "      <td>2.778626</td>\n",
       "      <td>3.188264</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.765917</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2014-10-20</td>\n",
       "      <td>AA</td>\n",
       "      <td>2014-05-27</td>\n",
       "      <td>AA</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>AAA</td>\n",
       "      <td>2014-04-24</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>5.348485</td>\n",
       "      <td>15.934783</td>\n",
       "      <td>3.296482</td>\n",
       "      <td>3.059211</td>\n",
       "      <td>3.681858</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.731819</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>AA</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>AA</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>AA</td>\n",
       "      <td>2014-05-27</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>...</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.927711</td>\n",
       "      <td>8.113636</td>\n",
       "      <td>2.841346</td>\n",
       "      <td>3.099338</td>\n",
       "      <td>1.307366</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.690750</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-04-27</td>\n",
       "      <td>AA</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>AA</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>AA</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>9.142857</td>\n",
       "      <td>2.640187</td>\n",
       "      <td>3.074074</td>\n",
       "      <td>2.025933</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.822168</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2015-07-21</td>\n",
       "      <td>AA</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>AA</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>AA</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>4.209877</td>\n",
       "      <td>10.442857</td>\n",
       "      <td>2.579909</td>\n",
       "      <td>3.033784</td>\n",
       "      <td>1.815531</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.808114</td>\n",
       "      <td>test</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5484</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2015-08-04</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>3.611650</td>\n",
       "      <td>15.634615</td>\n",
       "      <td>2.911215</td>\n",
       "      <td>2.013514</td>\n",
       "      <td>1.744657</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.895791</td>\n",
       "      <td>train</td>\n",
       "      <td>5484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5485</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>...</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.766917</td>\n",
       "      <td>15.848101</td>\n",
       "      <td>2.791667</td>\n",
       "      <td>1.779279</td>\n",
       "      <td>1.596294</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.929419</td>\n",
       "      <td>train</td>\n",
       "      <td>5485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5486</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>...</td>\n",
       "      <td>217.0</td>\n",
       "      <td>3.565517</td>\n",
       "      <td>17.506849</td>\n",
       "      <td>2.926829</td>\n",
       "      <td>2.161290</td>\n",
       "      <td>2.287146</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.585873</td>\n",
       "      <td>test</td>\n",
       "      <td>5486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5487</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0</td>\n",
       "      <td>3.572650</td>\n",
       "      <td>15.235294</td>\n",
       "      <td>3.023715</td>\n",
       "      <td>2.088372</td>\n",
       "      <td>1.739992</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.666177</td>\n",
       "      <td>train</td>\n",
       "      <td>5487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5488</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>2016-08-03</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>BBB</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>...</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2.858896</td>\n",
       "      <td>12.395349</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>2.288557</td>\n",
       "      <td>0.976340</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.748188</td>\n",
       "      <td>train</td>\n",
       "      <td>5488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5489 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker fixed_quarter_date earnings_call_date Rating rating_date  \\\n",
       "0      AAPL         2014-10-01         2014-07-22     AA  2014-05-27   \n",
       "1      AAPL         2015-01-01         2014-10-20     AA  2014-05-27   \n",
       "2      AAPL         2015-04-01         2015-01-27     AA  2015-02-18   \n",
       "3      AAPL         2015-07-01         2015-04-27     AA  2015-06-02   \n",
       "4      AAPL         2015-10-01         2015-07-21     AA  2015-08-25   \n",
       "...     ...                ...                ...    ...         ...   \n",
       "5484    ZTS         2015-10-01         2015-08-04    BBB  2015-01-30   \n",
       "5485    ZTS         2016-01-01         2015-11-03    BBB  2015-11-03   \n",
       "5486    ZTS         2016-04-01         2016-02-16    BBB  2016-01-22   \n",
       "5487    ZTS         2016-07-01         2016-05-04    BBB  2016-01-22   \n",
       "5488    ZTS         2016-10-01         2016-08-03    BBB  2016-01-22   \n",
       "\n",
       "     Next Rating Next Rating Date Previous Rating Previous Rating Date  \\\n",
       "0             AA       2015-02-18             AAA           2014-04-24   \n",
       "1             AA       2015-02-18             AAA           2014-04-24   \n",
       "2             AA       2015-05-28              AA           2014-05-27   \n",
       "3             AA       2015-08-25              AA           2015-05-28   \n",
       "4             AA       2016-05-20              AA           2015-06-02   \n",
       "...          ...              ...             ...                  ...   \n",
       "5484         BBB       2015-11-03             BBB           2014-01-31   \n",
       "5485         BBB       2016-01-22             BBB           2015-01-30   \n",
       "5486         BBB       2016-12-23             BBB           2015-11-03   \n",
       "5487         BBB       2016-12-23             BBB           2015-11-03   \n",
       "5488         BBB       2016-12-23             BBB           2015-11-03   \n",
       "\n",
       "     next_rating_date_or_end_of_data  ...  Undrst        PN         SW  \\\n",
       "0                         2015-02-18  ...   131.0  5.518519  15.261905   \n",
       "1                         2015-02-18  ...   152.0  5.348485  15.934783   \n",
       "2                         2015-05-28  ...   151.0  3.927711   8.113636   \n",
       "3                         2015-08-25  ...   135.0  5.250000   9.142857   \n",
       "4                         2016-05-20  ...   148.0  4.209877  10.442857   \n",
       "...                              ...  ...     ...       ...        ...   \n",
       "5484                      2015-11-03  ...   148.0  3.611650  15.634615   \n",
       "5485                      2016-01-22  ...   222.0  3.766917  15.848101   \n",
       "5486                      2016-12-23  ...   217.0  3.565517  17.506849   \n",
       "5487                      2016-12-23  ...   215.0  3.572650  15.235294   \n",
       "5488                      2016-12-23  ...   201.0  2.858896  12.395349   \n",
       "\n",
       "            AP        OU     TONE1 num_q_by_len pos_score_finbert  \\\n",
       "0     2.661290  2.778626  3.188264     0.003822          0.765917   \n",
       "1     3.296482  3.059211  3.681858     0.002766          0.731819   \n",
       "2     2.841346  3.099338  1.307366     0.004628          0.690750   \n",
       "3     2.640187  3.074074  2.025933     0.003861          0.822168   \n",
       "4     2.579909  3.033784  1.815531     0.003915          0.808114   \n",
       "...        ...       ...       ...          ...               ...   \n",
       "5484  2.911215  2.013514  1.744657     0.001458          0.895791   \n",
       "5485  2.791667  1.779279  1.596294     0.003859          0.929419   \n",
       "5486  2.926829  2.161290  2.287146     0.003928          0.585873   \n",
       "5487  3.023715  2.088372  1.739992     0.003182          0.666177   \n",
       "5488  2.840000  2.288557  0.976340     0.002697          0.748188   \n",
       "\n",
       "     train_test_80_20  node  \n",
       "0                test     0  \n",
       "1                test     1  \n",
       "2               train     2  \n",
       "3               train     3  \n",
       "4                test     4  \n",
       "...               ...   ...  \n",
       "5484            train  5484  \n",
       "5485            train  5485  \n",
       "5486             test  5486  \n",
       "5487            train  5487  \n",
       "5488            train  5488  \n",
       "\n",
       "[5489 rows x 173 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load feature and class data\n",
    "feature_and_class_df = load_feature_and_class_data()\n",
    "feature_and_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load column names\n",
    "numeric_feature_columns, cat_feature_columns, target_column, custom_mapping = get_column_names_and_mapping(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names: \n",
      "['num__Altman_Z']\n"
     ]
    }
   ],
   "source": [
    "# Prepare matrices\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, feature_names, train_ticker_by_fixed_quarter_date, test_ticker_by_fixed_quarter_date = prepare_matrices(feature_and_class_df, numeric_feature_columns, cat_feature_columns, target_column, custom_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      num__Altman_Z\n",
      "0          1.685950\n",
      "1          3.174735\n",
      "2          3.007245\n",
      "3          3.150117\n",
      "4          3.036072\n",
      "...             ...\n",
      "4392       1.311536\n",
      "4393       1.295700\n",
      "4394       1.056366\n",
      "4395       0.899041\n",
      "4396       1.056903\n",
      "\n",
      "[4397 rows x 1 columns]\n",
      "finalized dfs\n",
      "      num__Altman_Z  Rating  node\n",
      "0          1.685950       1     2\n",
      "1          3.174735       1     3\n",
      "2          3.007245       1     5\n",
      "3          3.150117       1     6\n",
      "4          3.036072       1     7\n",
      "...             ...     ...   ...\n",
      "4392       1.311536       3  5483\n",
      "4393       1.295700       3  5484\n",
      "4394       1.056366       3  5485\n",
      "4395       0.899041       3  5487\n",
      "4396       1.056903       3  5488\n",
      "\n",
      "[4397 rows x 3 columns]\n",
      "      num__Altman_Z  Rating  node\n",
      "0          1.949561       1     0\n",
      "1          3.061766       1     1\n",
      "2          3.051469       1     4\n",
      "3         -0.092929       2    12\n",
      "4         -0.446969       2    24\n",
      "...             ...     ...   ...\n",
      "1087       0.931329       3  5461\n",
      "1088       0.275978       4  5470\n",
      "1089      -0.483129       5  5473\n",
      "1090       0.647424       3  5480\n",
      "1091       0.726634       3  5486\n",
      "\n",
      "[1092 rows x 3 columns]\n",
      "missing values of target_column in train_and_val_df or test_df?\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Assemble back into dataframes\n",
    "\n",
    "# Train and val\n",
    "train_and_val_df = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "print(train_and_val_df)\n",
    "# Add y_train\n",
    "train_and_val_df[target_column] = y_train.reset_index(drop=True)\n",
    "# Add ticker by fixed quarter date\n",
    "train_and_val_df = pd.concat([train_ticker_by_fixed_quarter_date.reset_index(drop=True).sort_values(['ticker', 'fixed_quarter_date']), train_and_val_df], axis=1)\n",
    "# Add node by merging with feature_and_class_df (inner join)\n",
    "train_and_val_df = train_and_val_df.merge(feature_and_class_df[['ticker', 'fixed_quarter_date', 'node']], on=['ticker', 'fixed_quarter_date'], how='inner')\n",
    "# Drop ticker and fixed_quarter_date\n",
    "train_and_val_df = train_and_val_df.drop(['ticker', 'fixed_quarter_date'], axis=1)\n",
    "\n",
    "# Test\n",
    "test_df = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "# Add y_test\n",
    "test_df[target_column] = y_test.reset_index(drop=True)\n",
    "# Add ticker by fixed quarter date\n",
    "test_df = pd.concat([test_ticker_by_fixed_quarter_date.reset_index(drop=True).sort_values(['ticker', 'fixed_quarter_date']), test_df], axis=1)\n",
    "# Add node by merging with feature_and_class_df (inner join)\n",
    "test_df = test_df.merge(feature_and_class_df[['ticker', 'fixed_quarter_date', 'node']], on=['ticker', 'fixed_quarter_date'], how='inner')\n",
    "# Drop ticker and fixed_quarter_date\n",
    "test_df = test_df.drop(['ticker', 'fixed_quarter_date'], axis=1)\n",
    "\n",
    "print('finalized dfs')\n",
    "print(train_and_val_df)\n",
    "print(test_df)\n",
    "print('missing values of target_column in train_and_val_df or test_df?')\n",
    "print(train_and_val_df[target_column].isnull().sum() > 0)\n",
    "print(test_df[target_column].isnull().sum() > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pairwise Mentions Data\n",
    "\n",
    "Note: it's OK if we lose observations here, because on some fixed quarter dates we don't have data for both companies in a mention link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num obs\n",
      "2725\n",
      "num obs\n",
      "2725\n",
      "num obs\n",
      "1782\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3413</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4066</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3414</td>\n",
       "      <td>2771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3421</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>2657</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>2660</td>\n",
       "      <td>2110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>2673</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>2680</td>\n",
       "      <td>3544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>2681</td>\n",
       "      <td>3545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1782 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       src   dst\n",
       "0     3413  2935\n",
       "1     4066  2935\n",
       "2      103  2935\n",
       "3     3414  2771\n",
       "4     3421  2943\n",
       "...    ...   ...\n",
       "1777  2657   943\n",
       "1778  2660  2110\n",
       "1779  2673  1654\n",
       "1780  2680  3544\n",
       "1781  2681  3545\n",
       "\n",
       "[1782 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_dst_df = load_src_dst_data()\n",
    "print('num obs')\n",
    "print(len(src_dst_df))\n",
    "# Convert fixed_quarter_date to a string\n",
    "src_dst_df['fixed_quarter_date'] = src_dst_df['fixed_quarter_date'].astype(str)\n",
    "feature_and_class_df['fixed_quarter_date'] = feature_and_class_df['fixed_quarter_date'].astype(str)\n",
    "# Join with feature_and_class_df to get node for src_ticker and dst_ticker\n",
    "src_dst_df = src_dst_df.merge(feature_and_class_df[['ticker', 'fixed_quarter_date', 'node']], left_on=['src_ticker', 'fixed_quarter_date'], right_on=['ticker', 'fixed_quarter_date'], how='inner').rename(columns={'node': 'src_node'})\n",
    "print('num obs')\n",
    "print(len(src_dst_df))\n",
    "src_dst_df = src_dst_df.merge(feature_and_class_df[['ticker', 'fixed_quarter_date', 'node']], left_on=['dst_ticker', 'fixed_quarter_date'], right_on=['ticker', 'fixed_quarter_date'], how='inner').rename(columns={'node': 'dst_node'})\n",
    "print('num obs')\n",
    "print(len(src_dst_df))\n",
    "# Limit columns to just src_node and dst_node, rename to src and dst\n",
    "src_dst_df = src_dst_df[['src_node', 'dst_node']].rename(columns={'src_node': 'src', 'dst_node': 'dst'})\n",
    "src_dst_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edits to train and val and test dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keeping only items that are connected/have a node in src or dst in src_dst_df\n",
      "drop items in classes with only one node\n",
      "length of train_and_val_df\n",
      "1574\n",
      "new length of train_and_val_df\n",
      "1573\n",
      "keeping only src and dst that are in train_and_val_df or test_df\n",
      "length of src_dst_df\n",
      "1782\n",
      "new length of src_dst_df\n",
      "1781\n",
      "keeping only items that are connected/have a node in src or dst in src_dst_df again\n",
      "length of train_and_val_df\n",
      "1573\n",
      "length of test_df\n",
      "376\n",
      "new length of train_and_val_df\n",
      "1573\n",
      "new length of test_df\n",
      "376\n"
     ]
    }
   ],
   "source": [
    "# Limit train_and_val_df and test_df to just items with a node in one of the src or dst columns\n",
    "print('keeping only items that are connected/have a node in src or dst in src_dst_df')\n",
    "train_and_val_df = train_and_val_df[train_and_val_df['node'].isin(src_dst_df['src']) | train_and_val_df['node'].isin(src_dst_df['dst'])]\n",
    "test_df = test_df[test_df['node'].isin(src_dst_df['src']) | test_df['node'].isin(src_dst_df['dst'])]\n",
    "\n",
    "# Drop any items that belong to target_column values with only one node\n",
    "print('drop items in classes with only one node')\n",
    "print('length of train_and_val_df')\n",
    "print(len(train_and_val_df))\n",
    "train_and_val_df = train_and_val_df.groupby(target_column).filter(lambda x: len(x) > 1).reset_index(drop=True)\n",
    "print('new length of train_and_val_df')\n",
    "print(len(train_and_val_df))\n",
    "\n",
    "# Limit src and dst to just nodes in train_and_val_df or test_df\n",
    "print('keeping only src and dst that are in train_and_val_df or test_df')\n",
    "print('length of src_dst_df')\n",
    "print(len(src_dst_df))\n",
    "src_dst_df = src_dst_df[src_dst_df['src'].isin(train_and_val_df['node']) | src_dst_df['src'].isin(test_df['node'])]\n",
    "src_dst_df = src_dst_df[src_dst_df['dst'].isin(train_and_val_df['node']) | src_dst_df['dst'].isin(test_df['node'])]\n",
    "print('new length of src_dst_df')\n",
    "print(len(src_dst_df))\n",
    "\n",
    "# Limit train_and_val_df and test_df to just items with a node in one of the src or dst columns\n",
    "print('keeping only items that are connected/have a node in src or dst in src_dst_df again')\n",
    "print('length of train_and_val_df')\n",
    "print(len(train_and_val_df))\n",
    "print('length of test_df')\n",
    "print(len(test_df))\n",
    "train_and_val_df = train_and_val_df[train_and_val_df['node'].isin(src_dst_df['src']) | train_and_val_df['node'].isin(src_dst_df['dst'])]\n",
    "test_df = test_df[test_df['node'].isin(src_dst_df['src']) | test_df['node'].isin(src_dst_df['dst'])]\n",
    "print('new length of train_and_val_df')\n",
    "print(len(train_and_val_df))\n",
    "print('new length of test_df')\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Inductive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Further slice the train dataset into train and validation datasets.\n",
      "The training data has shape: (1258, 3).\n",
      "The validation data has shape: (315, 3).\n",
      "The test data has shape: (376, 3).\n",
      "Generate train, validation, and test masks.\n",
      "Number of nodes = 1949\n",
      "Number of features for each node = 1\n",
      "Number of classes = 9.\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "Expect number of features to match number of nodes (len(u)). Got 1949 and 5483 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_inductive_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_and_val_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_and_val_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msrc_dst_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msrc_dst_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../../Output/Modelling/Graph Neural Network/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mprediction_file_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../../Data/Predictions/Graph Neural Network/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_predictions.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mn_hidden\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                          \u001b[49m\u001b[43maggregator_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpool\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\repo\\Stat-222-Project\\Code\\Modelling\\Graph Neural Network\\Inductive_Graph_NN_Functions.py:439\u001b[0m, in \u001b[0;36mrun_inductive_model\u001b[1;34m(train_and_val_df, test_df, src_dst_df, model_dir, prediction_file_path, target_column, n_hidden, n_layers, dropout, weight_decay, n_epochs, lr, aggregator_type)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    438\u001b[0m \u001b[38;5;66;03m# Add features to graph\u001b[39;00m\n\u001b[1;32m--> 439\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m# Initialize model\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\miniforge3\\envs\\capstone\\Lib\\site-packages\\dgl\\view.py:99\u001b[0m, in \u001b[0;36mHeteroNodeDataView.__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, (\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe HeteroNodeDataView has only one node type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease pass a tensor directly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     )\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_n_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ntid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ijyli\\miniforge3\\envs\\capstone\\Lib\\site-packages\\dgl\\heterograph.py:4344\u001b[0m, in \u001b[0;36mDGLGraph._set_n_repr\u001b[1;34m(self, ntid, u, data)\u001b[0m\n\u001b[0;32m   4342\u001b[0m nfeats \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mshape(val)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   4343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nfeats \u001b[38;5;241m!=\u001b[39m num_nodes:\n\u001b[1;32m-> 4344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\n\u001b[0;32m   4345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpect number of features to match number of nodes (len(u)).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4346\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (nfeats, num_nodes)\n\u001b[0;32m   4347\u001b[0m     )\n\u001b[0;32m   4348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcontext(val) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[0;32m   4349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\n\u001b[0;32m   4350\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot assign node feature \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m on device \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to a graph on\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   4351\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m device \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Call DGLGraph.to() to copy the graph to the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4352\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m same device.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key, F\u001b[38;5;241m.\u001b[39mcontext(val), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   4353\u001b[0m     )\n",
      "\u001b[1;31mDGLError\u001b[0m: Expect number of features to match number of nodes (len(u)). Got 1949 and 5483 instead."
     ]
    }
   ],
   "source": [
    "run_inductive_model(train_and_val_df = train_and_val_df,\n",
    "                          test_df = test_df,\n",
    "                          src_dst_df = src_dst_df,\n",
    "                          model_dir = '../../../Output/Modelling/Graph Neural Network/' + model_name + '/',\n",
    "                          prediction_file_path = '../../../Data/Predictions/Graph Neural Network/' + model_name + '_predictions.xlsx',\n",
    "                          target_column = target_column,\n",
    "                          n_hidden = 64,\n",
    "                          n_layers = 2,\n",
    "                          dropout = 0.0,\n",
    "                          weight_decay = 5e-4,\n",
    "                          n_epochs = 100,\n",
    "                          lr = 0.01,\n",
    "                          aggregator_type = \"pool\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
